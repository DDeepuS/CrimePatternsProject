{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import altair as alt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from prettytable import PrettyTable, TableStyle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, perform imputation and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(option: str = \"1985-2023\") -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    if option == \"1985-2023\":\n",
    "        df = pd.read_excel(\"../data/tentative_final_with_NaN.xlsx\")\n",
    "    if option == \"2010-2023\":\n",
    "        df = pd.read_excel(\"../data/tentative_final.xlsx\")\n",
    "    return df\n",
    "\n",
    "tentative_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>Population</th>\n",
       "      <th>clearance_rate</th>\n",
       "      <th>population_density</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>adjusted_income</th>\n",
       "      <th>poverty_rate</th>\n",
       "      <th>rent_burden</th>\n",
       "      <th>home_ownership_rate</th>\n",
       "      <th>mobile_home_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>house_affordability</th>\n",
       "      <th>uninsured_rate</th>\n",
       "      <th>high_school_rate</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>public_school_rate</th>\n",
       "      <th>social_vs_security</th>\n",
       "      <th>security_vs_social</th>\n",
       "      <th>Category_Rural</th>\n",
       "      <th>Category_Suburban</th>\n",
       "      <th>Category_Urban</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alameda</th>\n",
       "      <th>1985</th>\n",
       "      <td>0.009809</td>\n",
       "      <td>1185500</td>\n",
       "      <td>0.466890</td>\n",
       "      <td>1606.368564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.010353</td>\n",
       "      <td>1206900</td>\n",
       "      <td>0.445778</td>\n",
       "      <td>1635.365854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.009588</td>\n",
       "      <td>1220600</td>\n",
       "      <td>0.538580</td>\n",
       "      <td>1653.929539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.008825</td>\n",
       "      <td>1242300</td>\n",
       "      <td>0.520660</td>\n",
       "      <td>1683.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.008375</td>\n",
       "      <td>1261200</td>\n",
       "      <td>0.497018</td>\n",
       "      <td>1708.943089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              crime_rate  Population  clearance_rate  population_density  \\\n",
       "County  Year                                                               \n",
       "Alameda 1985    0.009809     1185500        0.466890         1606.368564   \n",
       "        1986    0.010353     1206900        0.445778         1635.365854   \n",
       "        1987    0.009588     1220600        0.538580         1653.929539   \n",
       "        1988    0.008825     1242300        0.520660         1683.333333   \n",
       "        1989    0.008375     1261200        0.497018         1708.943089   \n",
       "\n",
       "              unemployment_rate  adjusted_income  poverty_rate  rent_burden  \\\n",
       "County  Year                                                                  \n",
       "Alameda 1985                NaN              NaN           NaN          NaN   \n",
       "        1986                NaN              NaN           NaN          NaN   \n",
       "        1987                NaN              NaN           NaN          NaN   \n",
       "        1988                NaN              NaN           NaN          NaN   \n",
       "        1989                NaN              NaN           NaN          NaN   \n",
       "\n",
       "              home_ownership_rate  mobile_home_ratio  ...  \\\n",
       "County  Year                                          ...   \n",
       "Alameda 1985                  NaN                NaN  ...   \n",
       "        1986                  NaN                NaN  ...   \n",
       "        1987                  NaN                NaN  ...   \n",
       "        1988                  NaN                NaN  ...   \n",
       "        1989                  NaN                NaN  ...   \n",
       "\n",
       "              house_affordability  uninsured_rate  high_school_rate  \\\n",
       "County  Year                                                          \n",
       "Alameda 1985                  NaN             NaN               NaN   \n",
       "        1986                  NaN             NaN               NaN   \n",
       "        1987                  NaN             NaN               NaN   \n",
       "        1988                  NaN             NaN               NaN   \n",
       "        1989                  NaN             NaN               NaN   \n",
       "\n",
       "              dropout_rate  public_school_rate  social_vs_security  \\\n",
       "County  Year                                                         \n",
       "Alameda 1985           NaN                 NaN                 NaN   \n",
       "        1986           NaN                 NaN                 NaN   \n",
       "        1987           NaN                 NaN                 NaN   \n",
       "        1988           NaN                 NaN                 NaN   \n",
       "        1989           NaN                 NaN                 NaN   \n",
       "\n",
       "              security_vs_social  Category_Rural  Category_Suburban  \\\n",
       "County  Year                                                          \n",
       "Alameda 1985                 NaN               0                  0   \n",
       "        1986                 NaN               0                  0   \n",
       "        1987                 NaN               0                  0   \n",
       "        1988                 NaN               0                  0   \n",
       "        1989                 NaN               0                  0   \n",
       "\n",
       "              Category_Urban  \n",
       "County  Year                  \n",
       "Alameda 1985               1  \n",
       "        1986               1  \n",
       "        1987               1  \n",
       "        1988               1  \n",
       "        1989               1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tentative_df[\"social_vs_security\"]=(tentative_df['adj_education_budget']+tentative_df['adj_welfare_budget']+tentative_df['adj_health_budget'])/(tentative_df['adj_police_budget']+tentative_df['adj_judiciary_budget']+tentative_df['adj_prison_budget'])\n",
    "tentative_df[\"security_vs_social\"]=(tentative_df['adj_police_budget']+tentative_df['adj_judiciary_budget']+tentative_df['adj_prison_budget'])/(tentative_df['adj_education_budget']+tentative_df['adj_welfare_budget']+tentative_df['adj_health_budget'])\n",
    "feature_0=['Population','clearance_rate',\n",
    "       'population_density', 'unemployment_rate', 'adjusted_income',\n",
    "       'poverty_rate', 'rent_burden', 'home_ownership_rate',\n",
    "       'mobile_home_ratio', 'vacancy_rate', 'Number_of_Persons_per_HseHld',\n",
    "       'renter_ratio', 'median_age', 'adj_police_budget',\n",
    "       'adj_education_budget', 'adj_welfare_budget',\n",
    "       'adj_mental_health_budget', 'adj_rehab_budget', 'adj_health_budget',\n",
    "       'adj_judiciary_budget', 'adj_prison_budget', 'median_house_value',\n",
    "       'house_affordability', 'uninsured_rate',\n",
    "       'high_school_rate', 'dropout_rate', 'public_school_rate',\n",
    "        \"social_vs_security\", \"security_vs_social\"] #'adherent_rate', 'rdm',\n",
    "feature_cat=['Category_Rural', 'Category_Suburban', 'Category_Urban']\n",
    "crime_dataframe=tentative_df[['County', 'Year',  'crime_rate']+feature_0+feature_cat]\n",
    "crime_dataframe=crime_dataframe.set_index(['County', 'Year'])\n",
    "crime_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2262 entries, ('Alameda', 1985) to ('Yuba', 2023)\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   crime_rate                    2262 non-null   float64\n",
      " 1   Population                    2262 non-null   int64  \n",
      " 2   clearance_rate                2262 non-null   float64\n",
      " 3   population_density            2262 non-null   float64\n",
      " 4   unemployment_rate             1914 non-null   float64\n",
      " 5   adjusted_income               928 non-null    float64\n",
      " 6   poverty_rate                  870 non-null    float64\n",
      " 7   rent_burden                   812 non-null    float64\n",
      " 8   home_ownership_rate           812 non-null    float64\n",
      " 9   mobile_home_ratio             812 non-null    float64\n",
      " 10  vacancy_rate                  812 non-null    float64\n",
      " 11  Number_of_Persons_per_HseHld  812 non-null    float64\n",
      " 12  renter_ratio                  812 non-null    float64\n",
      " 13  median_age                    812 non-null    float64\n",
      " 14  adj_police_budget             852 non-null    float64\n",
      " 15  adj_education_budget          844 non-null    float64\n",
      " 16  adj_welfare_budget            852 non-null    float64\n",
      " 17  adj_mental_health_budget      834 non-null    float64\n",
      " 18  adj_rehab_budget              779 non-null    float64\n",
      " 19  adj_health_budget             852 non-null    float64\n",
      " 20  adj_judiciary_budget          852 non-null    float64\n",
      " 21  adj_prison_budget             852 non-null    float64\n",
      " 22  median_house_value            798 non-null    float64\n",
      " 23  house_affordability           798 non-null    float64\n",
      " 24  uninsured_rate                776 non-null    float64\n",
      " 25  high_school_rate              812 non-null    float64\n",
      " 26  dropout_rate                  754 non-null    float64\n",
      " 27  public_school_rate            754 non-null    float64\n",
      " 28  social_vs_security            844 non-null    float64\n",
      " 29  security_vs_social            844 non-null    float64\n",
      " 30  Category_Rural                2262 non-null   int64  \n",
      " 31  Category_Suburban             2262 non-null   int64  \n",
      " 32  Category_Urban                2262 non-null   int64  \n",
      "dtypes: float64(29), int64(4)\n",
      "memory usage: 591.5+ KB\n"
     ]
    }
   ],
   "source": [
    "crime_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final={}\n",
    "Final[\"dropna\"]=crime_dataframe.dropna()\n",
    "Final[\"dropna\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Copy your original DataFrame and set a MultiIndex\n",
    "df = crime_dataframe.copy()\n",
    "#df = df.set_index(['County', 'Year'])\n",
    "\n",
    "def fill_missing_with_linear_regression(group):\n",
    "    \"\"\"\n",
    "    For a single county (group), fit a simple linear regression model\n",
    "    Year vs. each numeric column. Use that model to fill missing values.\n",
    "    \"\"\"\n",
    "    # Sort by Year for clarity\n",
    "    group = group.sort_index(level='Year')\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for col in group.columns:\n",
    "        # Only process numeric columns\n",
    "        if pd.api.types.is_numeric_dtype(group[col]):\n",
    "            # Extract the known data points (drop missing)\n",
    "            valid_data = group[col].dropna()\n",
    "            \n",
    "            # If there aren't at least two valid points, we can't fit a regression\n",
    "            if len(valid_data) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Prepare X (Year) and y (column values)\n",
    "            X = valid_data.index.get_level_values('Year').values.reshape(-1, 1)\n",
    "            y = valid_data.values\n",
    "            \n",
    "            # Fit the linear regression model\n",
    "            model = LinearRegression().fit(X, y)\n",
    "            \n",
    "            # Predict for all years in this county\n",
    "            X_all = group.index.get_level_values('Year').values.reshape(-1, 1)\n",
    "            y_pred = model.predict(X_all)\n",
    "            \n",
    "            # Fill only missing values with the predictions\n",
    "            missing_mask = group[col].isna()\n",
    "            group.loc[missing_mask, col] = y_pred[missing_mask]\n",
    "        else:\n",
    "            print(f\"Skipping non-numeric column: {col}\")\n",
    "    \n",
    "    return group\n",
    "\n",
    "# 2. Group by County and apply the regression-based filling\n",
    "df_reg_filled = (\n",
    "    df.groupby(level='County', group_keys=False)\n",
    "      .apply(fill_missing_with_linear_regression)\n",
    ")\n",
    "\n",
    "#df_reg_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2262, 33)\n",
      "(2108, 33)\n"
     ]
    }
   ],
   "source": [
    "final_dataframe = df_reg_filled\n",
    "#print(final_dataframe.isna().sum())\n",
    "print(final_dataframe.shape)\n",
    "final_dataframe=final_dataframe.dropna()\n",
    "print(final_dataframe.shape)\n",
    "Final[\"imputed\"]=final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.163726529166426e-06\n",
      "Average variance of crime_rate by county: 3.7796157807726586e-06\n",
      "Average variance of crime_rate by year: 5.260953083223783e-06\n"
     ]
    }
   ],
   "source": [
    "print(np.var(final_dataframe['crime_rate']))\n",
    "# Group by county and compute the variance of crime_rate for each county,\n",
    "# then compute the average variance across all counties.\n",
    "county_variances = final_dataframe.groupby(level=\"County\")[\"crime_rate\"].var()\n",
    "avg_county_variance = county_variances.mean()\n",
    "print(\"Average variance of crime_rate by county:\", avg_county_variance)\n",
    "\n",
    "# Group by year and compute the variance of crime_rate for each year,\n",
    "# then compute the average variance across all years.\n",
    "year_variances = final_dataframe.groupby(level=\"Year\")[\"crime_rate\"].var()\n",
    "avg_year_variance = year_variances.mean()\n",
    "print(\"Average variance of crime_rate by year:\", avg_year_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poly_df_function(df0):\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    Poly_data = poly.fit_transform(df0)\n",
    "    feature_names = poly.get_feature_names_out(input_features=df0.columns)\n",
    "    Poly_df = pd.DataFrame(Poly_data, columns=feature_names, index=df0.index)\n",
    "    return Poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionaries.\n",
    "X_train_dt = {}\n",
    "X_test_dt = {}\n",
    "y_train_dt = {}\n",
    "y_test_dt = {}\n",
    "X_train_Poly_dt = {}\n",
    "X_test_Poly_dt = {}\n",
    "\n",
    "X_train_log_dt = {}\n",
    "X_test_log_dt = {}\n",
    "X_train_Poly_log_dt = {}\n",
    "X_test_Poly_log_dt = {}\n",
    "y_train_clean_dt = {}\n",
    "y_test_clean_dt = {}\n",
    "\n",
    "# Iterate over the keys and the different categories.\n",
    "for key in Final.keys():\n",
    "    for key1 in [\"All\", \"Urban\", \"Suburban\", \"Rural\"]:\n",
    "        if key1 == \"All\":\n",
    "            df = Final[key]\n",
    "        else:\n",
    "            df = Final[key][Final[key][\"Category_\" + key1] == 1]\n",
    "\n",
    "        # Split the data into features (using feature_0 columns) and target (\"crime_rate\").\n",
    "        X = df[feature_0]\n",
    "        y = df[\"crime_rate\"]\n",
    "        PolyX = Poly_df_function(X)\n",
    "\n",
    "        # Split the data into training and testing sets.\n",
    "        X_train, X_test, y_train, y_test, X_train_Poly, X_test_Poly = train_test_split(\n",
    "            X, y, PolyX, test_size=0.15, random_state=35, shuffle=True\n",
    "        )\n",
    "\n",
    "        # Store original splits.\n",
    "        X_train_dt[(key, key1)] = X_train\n",
    "        X_test_dt[(key, key1)] = X_test\n",
    "        y_train_dt[(key, key1)] = y_train\n",
    "        y_test_dt[(key, key1)] = y_test\n",
    "        X_train_Poly_dt[(key, key1)] = X_train_Poly\n",
    "        X_test_Poly_dt[(key, key1)] = X_test_Poly\n",
    "\n",
    "        # Create a log-transformed version.\n",
    "        # Drop rows with nonpositive entries in any of the base features.\n",
    "        X_clean = X[(X > 0).all(axis=1)].copy()\n",
    "        # Add log-transformed columns for each feature in feature_0.\n",
    "        for col in feature_0:\n",
    "            X_clean[\"log_\" + col] = np.log(X_clean[col])\n",
    "        \n",
    "        # We need to match the target y for the rows we kept.\n",
    "        y_clean = y.loc[X_clean.index]\n",
    "\n",
    "        # Split the log-data into training and testing sets using the same parameters.\n",
    "        X_train_log, X_test_log, y_train_clean, y_test_clean = train_test_split(\n",
    "            X_clean, y_clean, test_size=0.15, random_state=35, shuffle=True\n",
    "        )\n",
    "        # Apply the polynomial expansion to the log-data.\n",
    "        X_train_Poly_log = Poly_df_function(X_train_log)\n",
    "        X_test_Poly_log = Poly_df_function(X_test_log)\n",
    "\n",
    "        # Store the log-splits in the new dictionaries.\n",
    "        X_train_log_dt[(key, key1)] = X_train_log\n",
    "        X_test_log_dt[(key, key1)] = X_test_log\n",
    "        X_train_Poly_log_dt[(key, key1)] = X_train_Poly_log\n",
    "        X_test_Poly_log_dt[(key, key1)] = X_test_Poly_log\n",
    "        y_train_clean_dt[(key, key1)] = y_train_clean\n",
    "        y_test_clean_dt[(key, key1)] = y_test_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not using this\n",
    "\n",
    "def train_test_split_by_county(X, y, X_poly, test_size=0.15, random_state=42):\n",
    "    # Extract unique counties from the MultiIndex (assumed to have level \"County\")\n",
    "    counties = np.array(X.index.get_level_values(\"County\").unique())\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle and split counties\n",
    "    n_counties = len(counties)\n",
    "    n_test = int(np.floor(test_size * n_counties))\n",
    "    shuffled = np.random.permutation(counties)\n",
    "    test_counties = shuffled[:n_test]\n",
    "    train_counties = shuffled[n_test:]\n",
    "    \n",
    "    # Create masks for train and test based on counties\n",
    "    train_mask = X.index.get_level_values(\"County\").isin(train_counties)\n",
    "    test_mask = X.index.get_level_values(\"County\").isin(test_counties)\n",
    "    \n",
    "    # Subset the data using the masks\n",
    "    X_train = X[train_mask]\n",
    "    X_test  = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test  = y[test_mask]\n",
    "    X_poly_train = X_poly[train_mask]\n",
    "    X_poly_test  = X_poly[test_mask]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_poly_train, X_poly_test\n",
    "\n",
    "# Now apply the function for each dataset:\n",
    "#X_train_Urban, X_test_Urban, y_train_Urban, y_test_Urban, X_train_Poly_Urban, X_test_Poly_Urban = train_test_split_by_county(\n",
    "#    X_Urban, y_Urban, X_Poly_Urban, test_size=0.15, random_state=42\n",
    "#)\n",
    "\n",
    "#X_train_Suburban, X_test_Suburban, y_train_Suburban, y_test_Suburban, X_train_Poly_Suburban, X_test_Poly_Suburban = train_test_split_by_county(\n",
    "#    X_Suburban, y_Suburban, X_Poly_Suburban, test_size=0.15, random_state=42\n",
    "#)\n",
    "\n",
    "#X_train_Rural, X_test_Rural, y_train_Rural, y_test_Rural, X_train_Poly_Rural, X_test_Poly_Rural = train_test_split_by_county(\n",
    "#    X_Rural, y_Rural, X_Poly_Rural, test_size=0.15, random_state=42\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train_Urban.index.get_level_values('County').unique())\n",
    "#print(X_test_Urban.index.get_level_values('County').unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(model_stats):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Model\", \"Type\", \"MSE\", \"RMSE\", \"r2 Score\", \"MR2\"]\n",
    "    \n",
    "    for model_name, stats in model_stats.items():\n",
    "        first_row = True\n",
    "        for cv_type, metrics in stats.items():\n",
    "            if len(metrics) == 3:\n",
    "                mse, rmse, r2 = metrics\n",
    "                mr2 = \"\"\n",
    "            elif len(metrics) == 4:\n",
    "                mse, rmse, r2, mr2 = metrics\n",
    "            else:\n",
    "                mse, rmse, r2, mr2 = metrics[0], metrics[1], metrics[2], metrics[3] if len(metrics) > 3 else \"\"\n",
    "            \n",
    "            if first_row:\n",
    "                table.add_row([model_name, cv_type, mse, rmse, r2, mr2])\n",
    "                first_row = False\n",
    "            else:\n",
    "                table.add_row([\"\", cv_type, mse, rmse, r2, mr2])\n",
    "        # Divider row between models\n",
    "        table.add_row([\"\"] * 6)\n",
    "    \n",
    "    table.set_style(TableStyle.DOUBLE_BORDER)\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_PCA(fitted_models, features, size, plot=True, models_to_use=None):\n",
    "    \"\"\"\n",
    "    Compute and optionally plot feature importances (or effective coefficients) for different models.\n",
    "    \n",
    "    Parameters:\n",
    "      fitted_models (dict): Dictionary containing fitted models.\n",
    "      features (list): List of original feature names.\n",
    "      size (tuple): Figure size for the plots.\n",
    "      plot (bool): If True, plot the bar charts; if False, only print the top features.\n",
    "      models_to_use (iterable): List or set of model names to consider. \n",
    "                                Defaults to all [\"mlr\", \"ridge\", \"xgb\", \"random_forest\"].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if models_to_use is None:\n",
    "        models_to_use = {\"mlr\", \"ridge\", \"xgb\", \"random_forest\"}\n",
    "    else:\n",
    "        models_to_use = set(models_to_use)\n",
    "        \n",
    "    # For MLR (Linear Regression) with PCA\n",
    "    if \"mlr\" in models_to_use:\n",
    "        scaler_mlr = fitted_models[\"mlr\"].named_steps[\"scale\"]\n",
    "        pca_mlr = fitted_models[\"mlr\"].named_steps[\"pca\"]\n",
    "        lin_mlr = fitted_models[\"mlr\"].named_steps[\"Lin\"]\n",
    "        # Back-transform coefficients: effective_coef = (PCA.components_.T @ coef) / scaler.scale_\n",
    "        eff_coef_mlr = (pca_mlr.components_.T.dot(lin_mlr.coef_)) / scaler_mlr.scale_\n",
    "        sorted_indices_mlr = np.argsort(eff_coef_mlr)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_mlr], eff_coef_mlr[sorted_indices_mlr])\n",
    "            plt.title(\"MLR Effective Coefficients (Original Features)\")\n",
    "            plt.xlabel(\"Coefficient\")\n",
    "            plt.show()\n",
    "        ll = [(abs(eff_coef_mlr[i]), features[i]) for i in sorted_indices_mlr]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in mlr are:\")\n",
    "        for importance, feat in ll[:4]:\n",
    "            print(feat)\n",
    "    \n",
    "    # For Ridge Regression with PCA\n",
    "    if \"ridge\" in models_to_use:\n",
    "        scaler_ridge = fitted_models[\"ridge\"].named_steps[\"scale\"]\n",
    "        pca_ridge = fitted_models[\"ridge\"].named_steps[\"pca\"]\n",
    "        ridge_model = fitted_models[\"ridge\"].named_steps[\"ridge\"]\n",
    "        eff_coef_ridge = (pca_ridge.components_.T.dot(ridge_model.coef_)) / scaler_ridge.scale_\n",
    "        sorted_indices_ridge = np.argsort(eff_coef_ridge)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_ridge], eff_coef_ridge[sorted_indices_ridge])\n",
    "            plt.title(\"Ridge Effective Coefficients (Original Features)\")\n",
    "            plt.xlabel(\"Coefficient\")\n",
    "            plt.show()\n",
    "        ll = [(abs(eff_coef_ridge[i]), features[i]) for i in sorted_indices_ridge]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in ridge are:\")\n",
    "        for importance, feat in ll[:4]:\n",
    "            print(feat)\n",
    "    \n",
    "    # For XGB (assumed to be trained on original features)\n",
    "    if \"xgb\" in models_to_use:\n",
    "        importance_xgb = fitted_models[\"xgb\"].feature_importances_\n",
    "        sorted_indices_xgb = np.argsort(importance_xgb)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_xgb], importance_xgb[sorted_indices_xgb])\n",
    "            plt.title(\"XGB Feature Importance\")\n",
    "            plt.xlabel(\"Importance\")\n",
    "            plt.show()\n",
    "        ll = [(importance_xgb[i], features[i]) for i in sorted_indices_xgb]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in xgb are:\")\n",
    "        for imp, feat in ll[:4]:\n",
    "            print(feat)\n",
    "    \n",
    "    # For RandomForest with PCA in a pipeline:\n",
    "    if \"random_forest\" in models_to_use:\n",
    "        scaler_rf = fitted_models[\"random_forest\"].named_steps[\"scale\"]\n",
    "        pca_rf = fitted_models[\"random_forest\"].named_steps[\"pca\"]\n",
    "        rf_model = fitted_models[\"random_forest\"].named_steps[\"randomforest\"]\n",
    "        # Heuristic: effective importance = abs(PCA.components_.T) dot tree_importances\n",
    "        eff_importance_rf = np.abs(pca_rf.components_.T).dot(rf_model.feature_importances_)\n",
    "        sorted_indices_rf = np.argsort(eff_importance_rf)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_rf], eff_importance_rf[sorted_indices_rf])\n",
    "            plt.title(\"RandomForest Effective Feature Importance (Original Features)\")\n",
    "            plt.xlabel(\"Importance\")\n",
    "            plt.show()\n",
    "        ll = [(eff_importance_rf[i], features[i]) for i in sorted_indices_rf]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in random forest are:\")\n",
    "        for imp, feat in ll[:4]:\n",
    "            print(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_MR2(S, X, y, model):\n",
    "    \"\"\"\n",
    "    Computes the average modified R² (MR2) over leave-one-county-out splits.\n",
    "    \n",
    "    In each fold, MR2 is defined as:\n",
    "         MR2 = 1 - (MSE of model predictions on validation set) / (Baseline MSE),\n",
    "    where Baseline MSE is computed by predicting the mean of y in the training set for that fold.\n",
    "         \n",
    "    Parameters:\n",
    "      S : set\n",
    "          Set of feature names.\n",
    "      X : pd.DataFrame\n",
    "          DataFrame with a MultiIndex (County, Year) containing features.\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "      float\n",
    "          The average MR2 over all LOCO splits.\n",
    "    \"\"\"\n",
    "    if not S:\n",
    "        return -np.inf  # if no features, MR2 is worst\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = X.index.get_level_values(\"County\")\n",
    "    mr2_scores = []\n",
    "    XX = X[list(S)]\n",
    "    \n",
    "    for train_idx, val_idx in logo.split(X, y, groups):\n",
    "        X_tt, X_val = XX.iloc[train_idx], XX.iloc[val_idx]\n",
    "        y_tt, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_tt, y_tt)\n",
    "        y_pred = model_clone.predict(X_val)\n",
    "        \n",
    "        mse_model = mean_squared_error(y_val, y_pred)\n",
    "        # Baseline: predict mean of y_tt for all validation instances.\n",
    "        baseline_pred = np.mean(y_tt)\n",
    "        baseline_y = np.full(shape=y_val.shape, fill_value=baseline_pred)\n",
    "        mse_baseline = mean_squared_error(y_val, baseline_y)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if mse_baseline == 0:\n",
    "            mr2 = -np.inf\n",
    "        else:\n",
    "            mr2 = 1 - mse_model / mse_baseline\n",
    "        mr2_scores.append(mr2)\n",
    "    \n",
    "    return np.mean(mr2_scores)\n",
    "\n",
    "def compute_avg_MR2_fast(S, X, y, model, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Computes the average modified R² (MR2) over folds where the counties are divided\n",
    "    into n_splits groups. In each fold, the model is trained on four of the groups (counties)\n",
    "    and validated on the remaining group.\n",
    "    \n",
    "    MR2 is defined as:\n",
    "         MR2 = 1 - (MSE of model predictions on validation set)/(Baseline MSE),\n",
    "    where Baseline MSE is computed by predicting the mean of y on the training counties.\n",
    "    \n",
    "    Parameters:\n",
    "      S : set\n",
    "          Set of feature names.\n",
    "      X : pd.DataFrame\n",
    "          DataFrame with a MultiIndex (County, Year) containing features.\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model (or pipeline) to use for evaluation.\n",
    "      n_splits : int, default=5\n",
    "          The number of splits (groups) to create from the unique counties.\n",
    "      random_state : int, default=42\n",
    "          For reproducibility when shuffling counties.\n",
    "    \n",
    "    Returns:\n",
    "      float\n",
    "          The average MR2 over all folds.\n",
    "    \"\"\"\n",
    "    if not S:\n",
    "        return -np.inf  # if no features, MR2 is worst\n",
    "\n",
    "    # Extract unique counties\n",
    "    counties = np.array(X.index.get_level_values(\"County\").unique())\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    mr2_scores = []\n",
    "    XX = X[list(S)]\n",
    "    \n",
    "    for train_county_idx, val_county_idx in kf.split(counties):\n",
    "        train_counties = counties[train_county_idx]\n",
    "        val_counties = counties[val_county_idx]\n",
    "        \n",
    "        # Generate boolean masks for training and validation samples based on counties\n",
    "        train_mask = X.index.get_level_values(\"County\").isin(train_counties)\n",
    "        val_mask   = X.index.get_level_values(\"County\").isin(val_counties)\n",
    "        \n",
    "        X_tt, X_val = XX[train_mask], XX[val_mask]\n",
    "        y_tt, y_val = y[train_mask], y[val_mask]\n",
    "        \n",
    "        # Clone and fit the model on the current training fold\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_tt, y_tt)\n",
    "        y_pred = model_clone.predict(X_val)\n",
    "        mse_model = mean_squared_error(y_val, y_pred)\n",
    "        \n",
    "        # Baseline: predict the mean of y in the training fold\n",
    "        baseline_pred = np.mean(y_tt)\n",
    "        baseline_y = np.full(shape=y_val.shape, fill_value=baseline_pred)\n",
    "        mse_baseline = mean_squared_error(y_val, baseline_y)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if mse_baseline == 0:\n",
    "            mr2 = -np.inf\n",
    "        else:\n",
    "            mr2 = 1 - mse_model / mse_baseline\n",
    "        mr2_scores.append(mr2)\n",
    "        \n",
    "    return np.mean(mr2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features(S, X, y, model, threshold=0.005, min_features=1):\n",
    "    \"\"\"\n",
    "    Recursively removes one feature at a time from set S if doing so does not reduce the average MR2 \n",
    "    by more than the given threshold. It will never remove features if that would result in fewer \n",
    "    than min_features remaining.\n",
    "    \n",
    "    Uses DFS to search through the removal space and employs a fast version of MR2 computation \n",
    "    (which divides the counties into groups instead of leaving one county out at a time).\n",
    "    \n",
    "    Parameters:\n",
    "      S : set\n",
    "          Current set of features.\n",
    "      X : pd.DataFrame\n",
    "          DataFrame with a MultiIndex (County, Year) containing features.\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use for evaluation.\n",
    "      threshold : float, default=0.005\n",
    "          The maximum allowed drop in average MR2 for a feature to be removed.\n",
    "      min_features : int, default=1\n",
    "          The minimum number of features allowed to remain.\n",
    "          \n",
    "    Returns:\n",
    "      set\n",
    "          The subset of S that yields an average MR2 that is not reduced by more than the threshold,\n",
    "          while never going below min_features.\n",
    "    \"\"\"\n",
    "    # If current feature set is already at or below min_features, return S unchanged.\n",
    "    if len(S) <= min_features:\n",
    "        return S\n",
    "\n",
    "    current_avg = compute_avg_MR2_fast(S, X, y, model)\n",
    "    best = S.copy()\n",
    "    \n",
    "    for feat in list(S):\n",
    "        # Check that removing feat won't drop feature count below min_features.\n",
    "        if len(S) - 1 < min_features:\n",
    "            continue\n",
    "        new_set = S - {feat}\n",
    "        new_avg = compute_avg_MR2_fast(new_set, X, y, model)\n",
    "        # Accept removal if the drop in average MR2 is less than or equal to the threshold.\n",
    "        if new_avg >= current_avg - threshold:\n",
    "            candidate = remove_features(new_set, X, y, model, threshold, min_features=min_features)\n",
    "            candidate_avg = compute_avg_MR2_fast(candidate, X, y, model)\n",
    "            if candidate_avg >= current_avg - threshold:\n",
    "                best = candidate\n",
    "                current_avg = candidate_avg\n",
    "    return best\n",
    "\n",
    "\n",
    "def add_features(S1, S2, X, y, model, threshold=0.005):\n",
    "    \"\"\"\n",
    "    Recursively adds one feature at a time from S2 into S1 if doing so increases the average MR2 \n",
    "    by at least the specified threshold.\n",
    "    \n",
    "    Uses DFS to search through the addition space and employs a fast version of MR2 computation \n",
    "    (which divides the counties into groups instead of leaving one county out at a time).\n",
    "    \n",
    "    Parameters:\n",
    "      S1 : set\n",
    "          Current selected features.\n",
    "      S2 : set\n",
    "          Potential features to add.\n",
    "      X : pd.DataFrame\n",
    "          DataFrame with a MultiIndex (County, Year) containing features.\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use for evaluation.\n",
    "      threshold : float, default=0.005\n",
    "          The minimum increase in average MR2 required to add a new feature.\n",
    "      \n",
    "    Returns:\n",
    "      set\n",
    "          The augmented feature set that yields a higher average MR2.\n",
    "    \"\"\"\n",
    "    current_avg = compute_avg_MR2_fast(S1, X, y, model)\n",
    "    best = S1.copy()\n",
    "    for feat in list(S2):\n",
    "        new_set = S1 | {feat}\n",
    "        new_avg = compute_avg_MR2_fast(new_set, X, y, model)\n",
    "        if new_avg >= current_avg + threshold:\n",
    "            remaining = S2 - {feat}\n",
    "            candidate = add_features(new_set, remaining, X, y, model, threshold)\n",
    "            candidate_avg = compute_avg_MR2_fast(candidate, X, y, model)\n",
    "            if candidate_avg >= current_avg + threshold:\n",
    "                best = candidate\n",
    "                current_avg = candidate_avg\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poly_feature_selection(S, X, y, model, threshold_addition=0.002, threshold_removal=0.002, dd=25,min_features=1):\n",
    "    \"\"\"\n",
    "    Performs feature selection on a large set of polynomial features S by gradually adding\n",
    "    features in blocks and refining via removal.\n",
    "    \n",
    "    The procedure is:\n",
    "      1) Initialize S0 as the base set 'feature_0' and remove any non-contributing features.\n",
    "      2) Iterate over S in blocks of dd features. For each block:\n",
    "            - Use add_features (with threshold_addition) to add the block features to S0.\n",
    "            - Then, use remove_features (with threshold_removal) to remove features that do not contribute.\n",
    "      3) After processing all blocks, add back feature_0 using add_features and then run one final removal.\n",
    "    \n",
    "    Parameters:\n",
    "      S : iterable\n",
    "          The large set of candidate feature names (e.g. from polynomial expansion).\n",
    "      X : pd.DataFrame\n",
    "          DataFrame with features (MultiIndex with levels \"County\" and \"Year\").\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          The target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model (or pipeline) to use for evaluation.\n",
    "      threshold_addition : float, default=0.002\n",
    "          The minimum increase in average MR2 required to add a new feature.\n",
    "      threshold_removal : float, default=0.002\n",
    "          The maximum permitted drop in average MR2 when removing a feature.\n",
    "      dd : int, default=25\n",
    "          Block size to process features incrementally.\n",
    "          \n",
    "    Returns:\n",
    "      set\n",
    "          The final optimal subset of features.\n",
    "      \n",
    "    Note:\n",
    "      It is assumed that 'feature_0' is defined globally and represents your initial base features.\n",
    "    \"\"\"\n",
    "    ll = list(S)\n",
    "    N = len(ll)\n",
    "    \n",
    "    # Start with the base features, and remove any non-contributing features.\n",
    "    S0 = set(feature_0)\n",
    "    \n",
    "    # Process candidate features in blocks of dd.\n",
    "    for i in range(0, N, dd):\n",
    "        print(f\"Processing block {i} to {i+dd}\")\n",
    "        block = set(ll[i:i+dd])\n",
    "        # Use add_features (DFS) to try to add the features in this block.\n",
    "        S0 = add_features(S0, block, X, y, model, threshold=threshold_addition)\n",
    "        # Then run removal on the updated S0 to prune any redundant features.\n",
    "        S0 = remove_features(S0, X, y, model, threshold=threshold_removal,min_features=min_features)\n",
    "    print('finished blocks')\n",
    "    # After processing all blocks, ensure that the base features remain if beneficial.\n",
    "    S0 = add_features(S0, set(feature_0), X, y, model, threshold=threshold_addition)\n",
    "    S0 = remove_features(S0, X, y, model, threshold=threshold_removal,min_features=min_features)\n",
    "    \n",
    "    return S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def compute_MR2(y_true, y_pred, baseline_value):\n",
    "    \"\"\"\n",
    "    Computes the modified R² (MR2) metric given true values, model predictions,\n",
    "    and a baseline value. The baseline prediction is a constant equal to baseline_value.\n",
    "    \n",
    "    MR2 = 1 - (MSE(model predictions))/(MSE(baseline predictions))\n",
    "    \n",
    "    Parameters:\n",
    "      y_true : array-like\n",
    "          True target values.\n",
    "      y_pred : array-like\n",
    "          Predictions from the model.\n",
    "      baseline_value : float\n",
    "          The constant value used as baseline (typically the mean from the training fold).\n",
    "    \n",
    "    Returns:\n",
    "      float\n",
    "          The computed MR2. If the baseline MSE is zero, returns -np.inf.\n",
    "    \"\"\"\n",
    "    mse_model = mean_squared_error(y_true, y_pred)\n",
    "    baseline_pred = np.full(shape=y_true.shape, fill_value=baseline_value)\n",
    "    mse_baseline = mean_squared_error(y_true, baseline_pred)\n",
    "    if mse_baseline == 0:\n",
    "        return -np.inf\n",
    "    return 1 - mse_model / mse_baseline\n",
    "\n",
    "def deep_cross_fit1(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    **models\n",
    ") -> tuple[dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    Fit models and compute performance statistics using several cross-validation schemes:\n",
    "      - Regular (KFold) CV on the training set.\n",
    "      - County-based CV using leave-one-county-out (splitting by the 'County' level of the index).\n",
    "      - Time-series CV (using data until 2018 for training and data after 2018 for validation).\n",
    "      - Test set performance (after fitting on the full training data).\n",
    "    \n",
    "    Modified R² (MR2) is defined as:\n",
    "         MR2 = 1 - (MSE of model predictions)/(MSE of baseline predictions),\n",
    "    where the baseline predictions are computed using the mean of y from the training fold \n",
    "    (for CV) or the mean of y_train (for the test set).\n",
    "    \n",
    "    Parameters:\n",
    "      X_train (pd.DataFrame): Training features (MultiIndex with levels \"County\" and \"Year\")\n",
    "      X_test (pd.DataFrame): Test features (MultiIndex with levels \"County\" and \"Year\")\n",
    "      y_train (pd.DataFrame or pd.Series): Training targets (indexed similarly)\n",
    "      y_test (pd.DataFrame or pd.Series): Test targets\n",
    "      models: Keyword arguments mapping model names to scikit-learn estimator instances.\n",
    "      \n",
    "    Returns:\n",
    "      tuple:\n",
    "         fitted_models: dict mapping model name to fitted model (trained on X_train)\n",
    "         model_stats: dict mapping model name to a dictionary with keys:\n",
    "             \"Reg train\", \"Reg val\", \"County train\", \"County val\", \"Time train\", \"Time val\", \"Test\"\n",
    "             For each, the value is a list: [MSE, RMSE, r2, MR2]\n",
    "         predictions: dict mapping model name to a dict with keys:\n",
    "             \"train\": predictions on X_train,\n",
    "             \"test\": predictions on X_test.\n",
    "    \"\"\"\n",
    "    fitted_models = {}\n",
    "    model_stats = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    # 1. Regular KFold CV on training data\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        stats = {}\n",
    "        \n",
    "        # Initialize lists to store metrics for regular splits.\n",
    "        reg_train_mse, reg_train_rmse, reg_train_r2, reg_train_mr2 = [], [], [], []\n",
    "        reg_val_mse, reg_val_rmse, reg_val_r2, reg_val_mr2 = [], [], [], []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_tt, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tt, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_tt, y_tt)\n",
    "            train_preds = model_clone.predict(X_tt)\n",
    "            val_preds = model_clone.predict(X_val)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_tt, train_preds)\n",
    "            reg_train_mse.append(mse_train)\n",
    "            reg_train_rmse.append(root_mean_squared_error(y_tt, train_preds))\n",
    "            reg_train_r2.append(r2_score(y_tt, train_preds))\n",
    "            # Use compute_MR2 with baseline equal to mean of y_tt\n",
    "            reg_train_mr2.append(compute_MR2(y_tt, train_preds, np.mean(y_tt)))\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val, val_preds)\n",
    "            reg_val_mse.append(mse_val)\n",
    "            reg_val_rmse.append(root_mean_squared_error(y_val, val_preds))\n",
    "            reg_val_r2.append(r2_score(y_val, val_preds))\n",
    "            # For validation, baseline is computed using the mean of y_tt from training fold.\n",
    "            reg_val_mr2.append(compute_MR2(y_val, val_preds, np.mean(y_tt)))\n",
    "            \n",
    "        stats[\"Reg train\"] = [np.mean(reg_train_mse), np.mean(reg_train_rmse), np.mean(reg_train_r2), np.mean(reg_train_mr2)]\n",
    "        stats[\"Reg val\"]   = [np.mean(reg_val_mse), np.mean(reg_val_rmse), np.mean(reg_val_r2), np.mean(reg_val_mr2)]\n",
    "        \n",
    "        # 2. County cross-validation using Leave-One-County-Out\n",
    "        logo = LeaveOneGroupOut()\n",
    "        groups = X_train.index.get_level_values(\"County\")\n",
    "        county_train_mse, county_train_rmse, county_train_r2, county_train_mr2 = [], [], [], []\n",
    "        county_val_mse, county_val_rmse, county_val_r2, county_val_mr2 = [], [], [], []\n",
    "        \n",
    "        for train_idx, val_idx in logo.split(X_train, y_train, groups):\n",
    "            X_train_county = X_train.iloc[train_idx]\n",
    "            y_train_county = y_train.iloc[train_idx]\n",
    "            X_val_county   = X_train.iloc[val_idx]\n",
    "            y_val_county   = y_train.iloc[val_idx]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_county, y_train_county)\n",
    "            train_preds = model_clone.predict(X_train_county)\n",
    "            val_preds   = model_clone.predict(X_val_county)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_train_county, train_preds)\n",
    "            county_train_mse.append(mse_train)\n",
    "            county_train_rmse.append(root_mean_squared_error(y_train_county, train_preds))\n",
    "            if len(y_train_county) < 2:\n",
    "                county_train_r2.append(np.nan)\n",
    "                county_train_mr2.append(np.nan)\n",
    "            else:\n",
    "                county_train_r2.append(r2_score(y_train_county, train_preds))\n",
    "                county_train_mr2.append(compute_MR2(y_train_county, train_preds, np.mean(y_train_county)))\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val_county, val_preds)\n",
    "            county_val_mse.append(mse_val)\n",
    "            county_val_rmse.append(root_mean_squared_error(y_val_county, val_preds))\n",
    "            if len(y_val_county) < 2:\n",
    "                county_val_r2.append(np.nan)\n",
    "                county_val_mr2.append(np.nan)\n",
    "            else:\n",
    "                county_val_r2.append(r2_score(y_val_county, val_preds))\n",
    "                # For validation, use training fold's mean\n",
    "                county_val_mr2.append(compute_MR2(y_val_county, val_preds, np.mean(y_train_county)))\n",
    "                \n",
    "        stats[\"County train\"] = [\n",
    "            np.nanmean(county_train_mse),\n",
    "            np.nanmean(county_train_rmse),\n",
    "            np.nanmean(county_train_r2),\n",
    "            np.nanmean(county_train_mr2)\n",
    "        ]\n",
    "        stats[\"County val\"] = [\n",
    "            np.nanmean(county_val_mse),\n",
    "            np.nanmean(county_val_rmse),\n",
    "            np.nanmean(county_val_r2),\n",
    "            np.nanmean(county_val_mr2)\n",
    "        ]\n",
    "        \n",
    "        # 3. Time series CV: train on years <= 2018, validate on years > 2018.\n",
    "        cutoff_year = 2018\n",
    "        train_mask = X_train.index.get_level_values(\"Year\") <= cutoff_year\n",
    "        val_mask   = X_train.index.get_level_values(\"Year\") > cutoff_year\n",
    "        \n",
    "        if train_mask.sum() > 0 and val_mask.sum() > 0:\n",
    "            X_train_time = X_train[train_mask]\n",
    "            y_train_time = y_train[train_mask]\n",
    "            X_val_time   = X_train[val_mask]\n",
    "            y_val_time   = y_train[val_mask]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_time, y_train_time)\n",
    "            train_preds = model_clone.predict(X_train_time)\n",
    "            val_preds   = model_clone.predict(X_val_time)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_train_time, train_preds)\n",
    "            time_train_mse = mse_train\n",
    "            time_train_rmse = root_mean_squared_error(y_train_time, train_preds)\n",
    "            time_train_r2 = r2_score(y_train_time, train_preds)\n",
    "            time_train_mr2 = compute_MR2(y_train_time, train_preds, np.mean(y_train_time))\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val_time, val_preds)\n",
    "            time_val_mse = mse_val\n",
    "            time_val_rmse = root_mean_squared_error(y_val_time, val_preds)\n",
    "            time_val_r2 = r2_score(y_val_time, val_preds)\n",
    "            # Baseline for validation uses training subset mean.\n",
    "            time_val_mr2 = compute_MR2(y_val_time, val_preds, np.mean(y_train_time))\n",
    "            \n",
    "            stats[\"Time train\"] = [time_train_mse, time_train_rmse, time_train_r2, time_train_mr2]\n",
    "            stats[\"Time val\"]   = [time_val_mse, time_val_rmse, time_val_r2, time_val_mr2]\n",
    "        else:\n",
    "            stats[\"Time train\"] = [np.nan, np.nan, np.nan, np.nan]\n",
    "            stats[\"Time val\"]   = [np.nan, np.nan, np.nan, np.nan]\n",
    "        \n",
    "        # 4. Test set evaluation: train on full X_train, then predict on X_test.\n",
    "        model.fit(X_train, y_train)\n",
    "        fitted_models[key] = model\n",
    "        test_preds = model.predict(X_test)\n",
    "        test_mse   = mean_squared_error(y_test, test_preds)\n",
    "        test_rmse  = root_mean_squared_error(y_test, test_preds)\n",
    "        test_r2    = r2_score(y_test, test_preds)\n",
    "        # For test set, the baseline is the constant prediction using the mean of y_train.\n",
    "        test_mr2   = compute_MR2(y_test, test_preds, np.mean(y_train))\n",
    "        stats[\"Test\"] = [test_mse, test_rmse, test_r2, test_mr2]\n",
    "        \n",
    "        model_stats[key] = stats\n",
    "        \n",
    "        # Also store predictions on training and test sets.\n",
    "        predictions[key] = {\n",
    "            \"train\": model.predict(X_train),\n",
    "            \"test\": test_preds\n",
    "        }\n",
    "        \n",
    "    return fitted_models, model_stats, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_fit(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    **models\n",
    ") -> tuple[dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    Fit models and compute performance statistics using several cross-validation schemes,\n",
    "    modeling log(y) as a linear function of the features but evaluating metrics on the original scale.\n",
    "    \n",
    "    In this function:\n",
    "      - y_train and y_test are log-transformed (using natural log) for model fitting.\n",
    "      - Predictions (which are in log-scale) are exponentiated to compute errors on the original scale.\n",
    "      - Modified R² (MR2) is computed as:\n",
    "             MR2 = 1 - (MSE(model predictions))/(MSE(baseline predictions)),\n",
    "        where the baseline is a constant equal to the mean of the exponentiated training log-targets.\n",
    "        \n",
    "    CV schemes used:\n",
    "      - Regular (KFold) CV.\n",
    "      - County-based CV using leave-one-county-out.\n",
    "      - Time-series CV: training on years <= 2018, validation on years > 2018.\n",
    "      - Test set evaluation (full training on log-scale, then predictions exponentiated).\n",
    "    \n",
    "    Returns:\n",
    "      tuple:\n",
    "         fitted_models: dict mapping model name to fitted model (trained on X_train)\n",
    "         model_stats: dict mapping model name to a dictionary with keys:\n",
    "             \"Reg train\", \"Reg val\", \"County train\", \"County val\", \"Time train\", \"Time val\", \"Test\"\n",
    "             Each value is a list: [MSE, RMSE, r2, MR2] (computed on the original y scale).\n",
    "         predictions: dict mapping model name to a dict with keys:\n",
    "             \"train\": predictions on X_train (in original scale),\n",
    "             \"test\": predictions on X_test (in original scale).\n",
    "    \"\"\"\n",
    "    fitted_models = {}\n",
    "    model_stats = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    # Transform targets to log-scale for model fitting.\n",
    "    y_train_log = np.log(y_train)\n",
    "    y_test_log = np.log(y_test)\n",
    "    \n",
    "    # 1. Regular KFold CV on training data.\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        stats = {}\n",
    "        \n",
    "        reg_train_mse, reg_train_rmse, reg_train_r2, reg_train_mr2 = [], [], [], []\n",
    "        reg_val_mse, reg_val_rmse, reg_val_r2, reg_val_mr2 = [], [], [], []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_tt, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tt_log, y_val_log = y_train_log.iloc[train_idx], y_train_log.iloc[val_idx]\n",
    "            \n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_tt, y_tt_log)\n",
    "            \n",
    "            # Predictions in log-scale.\n",
    "            train_preds_log = model_clone.predict(X_tt)\n",
    "            val_preds_log = model_clone.predict(X_val)\n",
    "            # Convert predictions and true values back to original scale.\n",
    "            y_tt_orig = np.exp(y_tt_log)\n",
    "            y_val_orig = np.exp(y_val_log)\n",
    "            train_preds_orig = np.exp(train_preds_log)\n",
    "            val_preds_orig = np.exp(val_preds_log)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_tt_orig, train_preds_orig)\n",
    "            reg_train_mse.append(mse_train)\n",
    "            reg_train_rmse.append(root_mean_squared_error(y_tt_orig, train_preds_orig))\n",
    "            reg_train_r2.append(r2_score(y_tt_orig, train_preds_orig))\n",
    "            baseline_train = np.mean(y_tt_orig)\n",
    "            reg_train_mr2.append(compute_MR2(y_tt_orig, train_preds_orig, baseline_train))\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val_orig, val_preds_orig)\n",
    "            reg_val_mse.append(mse_val)\n",
    "            reg_val_rmse.append(root_mean_squared_error(y_val_orig, val_preds_orig))\n",
    "            reg_val_r2.append(r2_score(y_val_orig, val_preds_orig))\n",
    "            # For validation, use the training fold's baseline (from y_tt_orig).\n",
    "            reg_val_mr2.append(compute_MR2(y_val_orig, val_preds_orig, baseline_train))\n",
    "            \n",
    "        stats[\"Reg train\"] = [np.mean(reg_train_mse), np.mean(reg_train_rmse), np.mean(reg_train_r2), np.mean(reg_train_mr2)]\n",
    "        stats[\"Reg val\"]   = [np.mean(reg_val_mse), np.mean(reg_val_rmse), np.mean(reg_val_r2), np.mean(reg_val_mr2)]\n",
    "        \n",
    "        # 2. County cross-validation using Leave-One-County-Out.\n",
    "        logo = LeaveOneGroupOut()\n",
    "        groups = X_train.index.get_level_values(\"County\")\n",
    "        county_train_mse, county_train_rmse, county_train_r2, county_train_mr2 = [], [], [], []\n",
    "        county_val_mse, county_val_rmse, county_val_r2, county_val_mr2 = [], [], [], []\n",
    "        \n",
    "        for train_idx, val_idx in logo.split(X_train, y_train_log, groups):\n",
    "            X_train_county = X_train.iloc[train_idx]\n",
    "            X_val_county = X_train.iloc[val_idx]\n",
    "            y_train_county_log = y_train_log.iloc[train_idx]\n",
    "            y_val_county_log = y_train_log.iloc[val_idx]\n",
    "            \n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_county, y_train_county_log)\n",
    "            \n",
    "            train_preds_log = model_clone.predict(X_train_county)\n",
    "            val_preds_log = model_clone.predict(X_val_county)\n",
    "            \n",
    "            y_train_county_orig = np.exp(y_train_county_log)\n",
    "            y_val_county_orig = np.exp(y_val_county_log)\n",
    "            train_preds_orig = np.exp(train_preds_log)\n",
    "            val_preds_orig = np.exp(val_preds_log)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_train_county_orig, train_preds_orig)\n",
    "            county_train_mse.append(mse_train)\n",
    "            county_train_rmse.append(root_mean_squared_error(y_train_county_orig, train_preds_orig))\n",
    "            if len(y_train_county_orig) < 2:\n",
    "                county_train_r2.append(np.nan)\n",
    "                county_train_mr2.append(np.nan)\n",
    "            else:\n",
    "                county_train_r2.append(r2_score(y_train_county_orig, train_preds_orig))\n",
    "                baseline_county_train = np.mean(y_train_county_orig)\n",
    "                county_train_mr2.append(compute_MR2(y_train_county_orig, train_preds_orig, baseline_county_train))\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val_county_orig, val_preds_orig)\n",
    "            county_val_mse.append(mse_val)\n",
    "            county_val_rmse.append(root_mean_squared_error(y_val_county_orig, val_preds_orig))\n",
    "            if len(y_val_county_orig) < 2:\n",
    "                county_val_r2.append(np.nan)\n",
    "                county_val_mr2.append(np.nan)\n",
    "            else:\n",
    "                county_val_r2.append(r2_score(y_val_county_orig, val_preds_orig))\n",
    "                # Baseline for validation from training fold:\n",
    "                county_val_mr2.append(compute_MR2(y_val_county_orig, val_preds_orig, np.mean(y_train_county_orig)))\n",
    "                \n",
    "        stats[\"County train\"] = [\n",
    "            np.nanmean(county_train_mse),\n",
    "            np.nanmean(county_train_rmse),\n",
    "            np.nanmean(county_train_r2),\n",
    "            np.nanmean(county_train_mr2)\n",
    "        ]\n",
    "        stats[\"County val\"] = [\n",
    "            np.nanmean(county_val_mse),\n",
    "            np.nanmean(county_val_rmse),\n",
    "            np.nanmean(county_val_r2),\n",
    "            np.nanmean(county_val_mr2)\n",
    "        ]\n",
    "        \n",
    "        # 3. Time series CV: train on years <= 2018, validate on years > 2018.\n",
    "        cutoff_year = 2018\n",
    "        train_mask = X_train.index.get_level_values(\"Year\") <= cutoff_year\n",
    "        val_mask = X_train.index.get_level_values(\"Year\") > cutoff_year\n",
    "        \n",
    "        if train_mask.sum() > 0 and val_mask.sum() > 0:\n",
    "            X_train_time = X_train[train_mask]\n",
    "            X_val_time = X_train[val_mask]\n",
    "            y_train_time_log = y_train_log[train_mask]\n",
    "            y_val_time_log = y_train_log[val_mask]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_time, y_train_time_log)\n",
    "            train_preds_log = model_clone.predict(X_train_time)\n",
    "            val_preds_log = model_clone.predict(X_val_time)\n",
    "            \n",
    "            y_train_time_orig = np.exp(y_train_time_log)\n",
    "            y_val_time_orig = np.exp(y_val_time_log)\n",
    "            train_preds_orig = np.exp(train_preds_log)\n",
    "            val_preds_orig = np.exp(val_preds_log)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_train_time_orig, train_preds_orig)\n",
    "            time_train_mse = mse_train\n",
    "            time_train_rmse = root_mean_squared_error(y_train_time_orig, train_preds_orig)\n",
    "            time_train_r2 = r2_score(y_train_time_orig, train_preds_orig)\n",
    "            time_train_mr2 = compute_MR2(y_train_time_orig, train_preds_orig, np.mean(y_train_time_orig))\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val_time_orig, val_preds_orig)\n",
    "            time_val_mse = mse_val\n",
    "            time_val_rmse = root_mean_squared_error(y_val_time_orig, val_preds_orig)\n",
    "            time_val_r2 = r2_score(y_val_time_orig, val_preds_orig)\n",
    "            time_val_mr2 = compute_MR2(y_val_time_orig, val_preds_orig, np.mean(y_train_time_orig))\n",
    "            \n",
    "            stats[\"Time train\"] = [time_train_mse, time_train_rmse, time_train_r2, time_train_mr2]\n",
    "            stats[\"Time val\"] = [time_val_mse, time_val_rmse, time_val_r2, time_val_mr2]\n",
    "        else:\n",
    "            stats[\"Time train\"] = [np.nan, np.nan, np.nan, np.nan]\n",
    "            stats[\"Time val\"] = [np.nan, np.nan, np.nan, np.nan]\n",
    "        \n",
    "        # 4. Test set evaluation: train on full X_train (log-scale) and predict on X_test.\n",
    "        model.fit(X_train, y_train_log)\n",
    "        fitted_models[key] = model\n",
    "        test_preds_log = model.predict(X_test)\n",
    "        test_preds_orig = np.exp(test_preds_log)\n",
    "        # y_test is in original scale.\n",
    "        test_mse = mean_squared_error(y_test, test_preds_orig)\n",
    "        test_rmse = root_mean_squared_error(y_test, test_preds_orig)\n",
    "        test_r2 = r2_score(y_test, test_preds_orig)\n",
    "        # For test set baseline, use mean of y_train (original scale)\n",
    "        test_baseline = np.mean(np.exp(y_train_log))\n",
    "        test_mr2 = compute_MR2(y_test, test_preds_orig, test_baseline)\n",
    "        stats[\"Test\"] = [test_mse, test_rmse, test_r2, test_mr2]\n",
    "        \n",
    "        model_stats[key] = stats\n",
    "        \n",
    "        # Also store predictions (on original scale) for inspection.\n",
    "        predictions[key] = {\n",
    "            \"train\": np.exp(model.predict(X_train)),  # fitted on log-scale, transformed back\n",
    "            \"test\": test_preds_orig\n",
    "        }\n",
    "        \n",
    "    return fitted_models, model_stats, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment this to recompute the best features\n",
    "#Best_features={}\n",
    "\n",
    "#Uncomment this to load the best features from the file\n",
    "Best_features = joblib.load(\"best_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urban model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We regress log(y) =Ridge(features)\n",
    "\n",
    "i.e. y=exp(Ridge(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Urban model\n",
      "Optimal subset of features:\n",
      "11 ['uninsured_rate', 'adjusted_income', 'log_median_age', 'clearance_rate log_Population', 'log_mobile_home_ratio log_renter_ratio', 'adjusted_income mobile_home_ratio', 'log_poverty_rate log_vacancy_rate', 'security_vs_social', 'home_ownership_rate log_dropout_rate', 'log_clearance_rate^2', 'clearance_rate log_mobile_home_ratio']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║        MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 4.2516394502810894e-07 ║ 0.0006510867024536446 ║  0.8844399536139853 ║ 0.8844399536139853 ║\n",
      "║       ║   Reg val    ║ 4.3386684950407715e-07 ║ 0.0006494442753316565 ║  0.8687199816324668 ║ 0.8802326531221351 ║\n",
      "║       ║ County train ║ 4.053612342863489e-07  ║ 0.0006356257061149141 ║  0.8891771908532872 ║ 0.8891771908532872 ║\n",
      "║       ║  County val  ║ 5.603943869013076e-07  ║ 0.0006290433213542412 ║ -1.8120028501669647 ║ 0.7955594234381759 ║\n",
      "║       ║  Time train  ║ 3.3491707845114216e-07 ║ 0.0005787202073983094 ║  0.8974785963688785 ║ 0.8974785963688785 ║\n",
      "║       ║   Time val   ║ 5.765767264547608e-07  ║ 0.0007593264952935337 ║  0.8747229259970577 ║ 0.8810417485237999 ║\n",
      "║       ║     Test     ║ 6.106277431606741e-07  ║ 0.0007814267356321218 ║  0.8005542257170412 ║ 0.8072704624977401 ║\n",
      "║       ║              ║                        ║                       ║                     ║                    ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "log_median_age\n",
      "uninsured_rate\n",
      "security_vs_social\n",
      "home_ownership_rate log_dropout_rate\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Urban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 8\n",
    "alpha=20\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.002\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "#Best_features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,min_features=n_components))\n",
    "\n",
    "ff=Best_features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models, models_stats, models_pred = log_fit(\n",
    "    X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models)\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats)\n",
    "feature_importance_PCA(fitted_models,ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suburban Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=Ridge(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Suburban model\n",
      "Optimal subset of features:\n",
      "19 ['poverty_rate adj_rehab_budget', 'Population unemployment_rate', 'poverty_rate adj_judiciary_budget', 'mobile_home_ratio vacancy_rate', 'vacancy_rate^2', 'mobile_home_ratio dropout_rate', 'uninsured_rate security_vs_social', 'adj_judiciary_budget house_affordability', 'poverty_rate', 'unemployment_rate adj_mental_health_budget', 'clearance_rate Number_of_Persons_per_HseHld', 'Population adj_welfare_budget', 'Population mobile_home_ratio', 'house_affordability high_school_rate', 'population_density poverty_rate', 'adj_health_budget security_vs_social', 'public_school_rate', 'adjusted_income median_age', 'uninsured_rate^2']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦══════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score       ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬══════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.600756957182654e-06  ║ 0.0012647934831588356 ║ 0.49683071350614966  ║ 0.49683071350614966 ║\n",
      "║       ║   Reg val    ║ 1.6544842115461296e-06 ║  0.001278914431196033 ║  0.4803930099022765  ║ 0.48398050298584244 ║\n",
      "║       ║ County train ║ 1.5962708436767335e-06 ║ 0.0012628664981838619 ║  0.4971513673100565  ║  0.4971513673100565 ║\n",
      "║       ║  County val  ║  1.76203299111618e-06  ║  0.00122981738745484  ║ -0.12889889139744537 ║ 0.46004284046909755 ║\n",
      "║       ║  Time train  ║ 1.6198992108493054e-06 ║ 0.0012727526118021936 ║  0.4990883389057018  ║  0.4990883389057018 ║\n",
      "║       ║   Time val   ║ 1.453791909287929e-06  ║ 0.0012057329344792441 ║  0.2848282884454856  ║  0.5108257783956485 ║\n",
      "║       ║     Test     ║ 1.6478260898749342e-06 ║  0.001283676785594775 ║  0.4474629431925061  ║ 0.44983158106906873 ║\n",
      "║       ║              ║                        ║                       ║                      ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩══════════════════════╩═════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "alpha=50\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha=alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.002\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "Best_features[(key,key1)]=['poverty_rate adj_rehab_budget', 'Population unemployment_rate', 'poverty_rate adj_judiciary_budget', 'mobile_home_ratio vacancy_rate', 'vacancy_rate^2', 'mobile_home_ratio dropout_rate', 'uninsured_rate security_vs_social', 'adj_judiciary_budget house_affordability', 'poverty_rate', 'unemployment_rate adj_mental_health_budget', 'clearance_rate Number_of_Persons_per_HseHld', 'Population adj_welfare_budget', 'Population mobile_home_ratio', 'house_affordability high_school_rate', 'population_density poverty_rate', 'adj_health_budget security_vs_social', 'public_school_rate', 'adjusted_income median_age', 'uninsured_rate^2']\n",
    "\n",
    "ff=Best_features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models, models_stats, models_pred = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rural model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We regress log(y) =Ridge(features)\n",
    "\n",
    "i.e. y=exp(Ridge(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Rural model\n",
      "Optimal subset of features:\n",
      "15 ['adjusted_income log_high_school_rate', 'adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'clearance_rate log_house_affordability', 'security_vs_social log_population_density', 'adj_health_budget uninsured_rate', 'adj_judiciary_budget median_house_value', 'log_home_ownership_rate log_adj_education_budget', 'log_poverty_rate log_dropout_rate', 'poverty_rate', 'vacancy_rate adj_welfare_budget', 'median_house_value log_mobile_home_ratio', 'adj_judiciary_budget log_Population', 'adj_mental_health_budget uninsured_rate', 'vacancy_rate log_clearance_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.3403134273800463e-06 ║ 0.0011573210759599003 ║ 0.48217683381222665 ║ 0.48217683381222665 ║\n",
      "║       ║   Reg val    ║ 1.3691255244319874e-06 ║ 0.0011655914946028328 ║  0.4567080784416707 ║ 0.47024686444975117 ║\n",
      "║       ║ County train ║ 1.2958197978464714e-06 ║ 0.0011381315512309564 ║  0.4991091980301296 ║  0.4991091980301296 ║\n",
      "║       ║  County val  ║ 1.610736036926655e-06  ║  0.00114239469315705  ║  -0.987836631360128 ║  0.3621399586475821 ║\n",
      "║       ║  Time train  ║ 1.2577786095655426e-06 ║  0.001121507293585531 ║  0.4325387351140705 ║  0.4325387351140705 ║\n",
      "║       ║   Time val   ║ 2.193381985698989e-06  ║ 0.0014810070849590792 ║  0.3451520718473978 ║  0.3835000687356098 ║\n",
      "║       ║     Test     ║ 4.255677972399297e-06  ║  0.002062929463747924 ║ 0.14376733571392097 ║ 0.18499457612329695 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "clearance_rate dropout_rate\n",
      "adj_prison_budget uninsured_rate\n",
      "vacancy_rate log_clearance_rate\n",
      "adj_mental_health_budget uninsured_rate\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 7\n",
    "alpha=100\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.002\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "#Best_features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_clean_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,min_features=n_components,dd=25))\n",
    "\n",
    "ff=Best_features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "    X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_clean_dt[(key,key1)],y_test_clean_dt[(key,key1)], **models)\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])\n",
    "feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_features.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save the dictionary\n",
    "joblib.dump(Best_features, \"best_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unused, extra codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_selection(S, X, y, model, threshold_removal=0.005, threshold_addition=0.005):\n",
    "    \"\"\"\n",
    "    Selects an optimal subset of features using a three-step DFS process:\n",
    "      1) Removal: Remove features from S if doing so does not reduce MR2 by more than threshold_removal.\n",
    "      2) Addition: From the originally removed features, DFS to add features back if they improve MR2 by at least threshold_addition.\n",
    "      3) Final Removal: Run the removal process again on the augmented set using threshold_removal.\n",
    "    \n",
    "    Parameters:\n",
    "      S : iterable\n",
    "          The initial set (or list) of feature names.\n",
    "      X : pd.DataFrame\n",
    "          Training features with a MultiIndex (County, Year).\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Training target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use for evaluation.\n",
    "      threshold_removal : float, default=0.005\n",
    "          The maximum permitted drop in average MR2 when removing a feature.\n",
    "      threshold_addition : float, default=0.005\n",
    "          The minimum increase in average MR2 required to add a new feature.\n",
    "    \n",
    "    Returns:\n",
    "      set\n",
    "          The final optimal subset of features.\n",
    "    \"\"\"\n",
    "    # Convert S to a set\n",
    "    S_initial = set(S)\n",
    "    # Step 1: Removal phase\n",
    "    S_removed = remove_features(S_initial, X, y, model, threshold=threshold_removal)\n",
    "    # Determine the features that were removed\n",
    "    removed_features = S_initial - S_removed\n",
    "    # Step 2: Addition phase\n",
    "    S_added = add_features(S_removed, removed_features, X, y, model, threshold=threshold_addition)\n",
    "    # Step 3: Final removal phase\n",
    "    S_final = remove_features(S_added, X, y, model, threshold=threshold_removal)\n",
    "    return S_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def PCA_feature_selection(S, X, y, model, max_components=10):\n",
    "    \"\"\"\n",
    "    Finds the optimal number of PCA components and optimal feature subset.\n",
    "    \n",
    "    For each n_components (starting at 1), it creates a pipeline:\n",
    "         Pipeline([(\"scale\", StandardScaler()), (\"pca\", PCA(n_components=n_components)), (\"mod\", model)])\n",
    "    Then it calls Feature_selection(S, X, y, model_pipe) to select the best features\n",
    "    and computes the average MR2 using leave-one-county-out CV (via compute_avg_MR2).\n",
    "    \n",
    "    It increases n_components by 1 until the average MR2 decreases; then, the previous\n",
    "    setting is returned.\n",
    "    \n",
    "    Parameters:\n",
    "      S : iterable\n",
    "          The initial set of feature names.\n",
    "      X : pd.DataFrame\n",
    "          Training features with a MultiIndex (County, Year).\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Training target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use (e.g., LinearRegression()).\n",
    "      max_components : int, optional\n",
    "          Maximum number of PCA components to try (default is 10).\n",
    "    \n",
    "    Returns:\n",
    "      tuple: (best_n_components, best_feature_subset, best_avg_MR2)\n",
    "    \"\"\"\n",
    "    best_mr2 = -np.inf\n",
    "    best_n = None\n",
    "    best_features = None\n",
    "    \n",
    "    # Loop over increasing PCA dimensions.\n",
    "    for n in range(1, max_components + 1):\n",
    "        # Create a pipeline with n_components in the PCA step.\n",
    "        model_pipe = Pipeline([\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=n)),\n",
    "            (\"mod\", model)\n",
    "        ])\n",
    "        \n",
    "        # Run DFS-based feature selection with the current pipeline.\n",
    "        selected_features = Feature_selection(S, X, y, model_pipe)\n",
    "        # Compute average MR2 using leave-one-county-out CV.\n",
    "        avg_mr2 = compute_avg_MR2(selected_features, X, y, model_pipe)\n",
    "        print(f\"n_components = {n}, selected features = {selected_features}, MR2 = {avg_mr2}\")\n",
    "        \n",
    "        # If MR2 improves, update best values; if it drops, stop and return the previous best.\n",
    "        if avg_mr2 > best_mr2:\n",
    "            best_mr2 = avg_mr2\n",
    "            best_n = n\n",
    "            best_features = selected_features\n",
    "        else:\n",
    "            # MR2 has decreased; we assume the previous configuration was optimal.\n",
    "            break\n",
    "            \n",
    "    return best_n, best_features#, best_mr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(fitted_models,features,size):\n",
    "    coeffs_mlr = fitted_models[\"mlr\"].named_steps[\"Lin\"].coef_\n",
    "    sorted_indices_mlr = np.argsort(coeffs_mlr)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_mlr], coeffs_mlr[sorted_indices_mlr])\n",
    "    plt.title(\"Linear Regression Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(coeffs_mlr[i]),features[i]) for i in sorted_indices_mlr]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in mlr is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])\n",
    "\n",
    "    coeffs_ridge = fitted_models[\"ridge\"].named_steps['ridge'].coef_\n",
    "    sorted_indices_ridge = np.argsort(coeffs_ridge)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_ridge], coeffs_ridge[sorted_indices_ridge])\n",
    "    plt.title(\"Ridge Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(coeffs_ridge[i]),features[i]) for i in sorted_indices_ridge]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in ridge is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])\n",
    "\n",
    "    importance_xgb = fitted_models[\"xgb\"].feature_importances_\n",
    "    sorted_indices_xgb = np.argsort(importance_xgb)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_xgb], importance_xgb[sorted_indices_xgb])\n",
    "    plt.title(\"XGB Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(importance_xgb[i]),features[i]) for i in sorted_indices_xgb]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in xgb is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])\n",
    "\n",
    "\n",
    "    importance_randomforest = fitted_models[\"random_forest\"].named_steps[\"randomforest\"].feature_importances_\n",
    "    sorted_indices_randomforest = np.argsort(importance_randomforest)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_randomforest], importance_randomforest[sorted_indices_randomforest])\n",
    "    plt.title(\"RandomForest Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(importance_randomforest[i]),features[i]) for i in sorted_indices_randomforest]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in randomforest is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models={}\n",
    "models_stats={}\n",
    "models_pred={}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features={}\n",
    "\n",
    "#Load selected features:\n",
    "features = joblib.load(\"features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urban Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Urban model\n",
      "Optimal subset of features:\n",
      "13 ['uninsured_rate^2', 'clearance_rate home_ownership_rate', 'home_ownership_rate', 'Population vacancy_rate', 'adjusted_income renter_ratio', 'adj_welfare_budget house_affordability', 'rent_burden median_age', 'unemployment_rate uninsured_rate', 'adj_prison_budget', 'clearance_rate public_school_rate', 'security_vs_social', 'unemployment_rate median_house_value', 'Population adj_rehab_budget']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦══════════════════════╦════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score       ║        MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬══════════════════════╬════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 2.651116551922819e-06  ║ 0.0016267122211047695 ║  0.6976419989748679  ║ 0.6976419989748679 ║\n",
      "║       ║   Reg val    ║ 2.7276884859081606e-06 ║  0.001633079666280068 ║  0.6930126621128654  ║ 0.6937825474539668 ║\n",
      "║       ║ County train ║ 2.575394992679449e-06  ║ 0.0016032472911000873 ║  0.7048216940470949  ║ 0.7048216940470949 ║\n",
      "║       ║  County val  ║ 3.3555137674716148e-06 ║ 0.0016496019649077415 ║ -0.02590283948357495 ║ 0.6709310107651281 ║\n",
      "║       ║  Time train  ║ 2.6573705383471842e-06 ║ 0.0016301443305263446 ║  0.7085281376055985  ║ 0.7085281376055985 ║\n",
      "║       ║   Time val   ║ 1.8816258769444396e-06 ║ 0.0013717236882639446 ║  0.5060368912906078  ║ 0.7237922989625489 ║\n",
      "║       ║     Test     ║  2.11174452585442e-06  ║ 0.0014531842711282077 ║  0.7022046807594864  ║ 0.7022086956381992 ║\n",
      "║       ║              ║                        ║                       ║                      ║                    ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩══════════════════════╩════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "uninsured_rate^2\n",
      "home_ownership_rate\n",
      "clearance_rate home_ownership_rate\n",
      "security_vs_social\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Urban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "alpha=100\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.0005\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])\n",
    "feature_importance_PCA(fitted_models[(key,key1)],features[(key,key1)],(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Urban model\n",
      "Optimal subset of features:\n",
      "15 ['adjusted_income uninsured_rate', 'adjusted_income^2', 'dropout_rate', 'adjusted_income', 'rent_burden adj_judiciary_budget', 'mobile_home_ratio high_school_rate', 'home_ownership_rate adj_police_budget', 'median_age', 'clearance_rate poverty_rate', 'adj_prison_budget', 'median_age adj_judiciary_budget', 'security_vs_social', 'median_age^2', 'clearance_rate', 'unemployment_rate adj_police_budget']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║        MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 7.020646040085065e-07  ║ 0.0008374428616650357 ║  0.8092759078304479 ║ 0.8092759078304479 ║\n",
      "║       ║   Reg val    ║ 7.849230281538913e-07  ║ 0.0008661888045140403 ║  0.785338594876212  ║ 0.7994874319600869 ║\n",
      "║       ║ County train ║ 6.775822633213537e-07  ║  0.000821719142023402 ║  0.8147392447435137 ║ 0.8147392447435137 ║\n",
      "║       ║  County val  ║ 9.301068301176784e-07  ║  0.000779746240212533 ║ -15.275101699389129 ║ 0.7290764823118494 ║\n",
      "║       ║  Time train  ║ 6.040523762629619e-07  ║ 0.0007772080649755006 ║  0.8150936411854932 ║ 0.8150936411854932 ║\n",
      "║       ║   Time val   ║ 1.3274546162530571e-06 ║ 0.0011521521671433235 ║  0.7115741538538674 ║ 0.7261220010831222 ║\n",
      "║       ║     Test     ║ 7.403439550255455e-07  ║ 0.0008604324232765439 ║  0.7581857768507503 ║ 0.7663287499743975 ║\n",
      "║       ║              ║                        ║                       ║                     ║                    ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "dropout_rate\n",
      "clearance_rate\n",
      "security_vs_social\n",
      "home_ownership_rate adj_police_budget\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Urban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "alpha=30\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha=alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.0005\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,dd=35))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])\n",
    "feature_importance_PCA(fitted_models[(key,key1)],features[(key,key1)],(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suburban models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Suburban model\n",
      "Optimal subset of features:\n",
      "18 ['unemployment_rate mobile_home_ratio', 'Population', 'mobile_home_ratio adj_welfare_budget', 'adj_education_budget social_vs_security', 'uninsured_rate', 'adjusted_income high_school_rate', 'rent_burden mobile_home_ratio', 'median_house_value', 'public_school_rate', 'adjusted_income^2', 'home_ownership_rate median_house_value', 'mobile_home_ratio', 'poverty_rate adj_police_budget', 'clearance_rate Number_of_Persons_per_HseHld', 'poverty_rate median_age', 'adjusted_income median_house_value', 'clearance_rate', 'population_density']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦══════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score       ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬══════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.5950361766145837e-06 ║  0.001262691999487455 ║ 0.49847480581490283  ║  0.4984748058149028 ║\n",
      "║       ║   Reg val    ║ 1.642425673802448e-06  ║ 0.0012763669006410896 ║ 0.48348130022217556  ║ 0.48702739857744926 ║\n",
      "║       ║ County train ║ 1.592353592394988e-06  ║ 0.0012614863772549226 ║  0.4979971023018957  ║  0.4979971023018957 ║\n",
      "║       ║  County val  ║ 1.8678542638363135e-06 ║ 0.0012954037654193634 ║ -0.30324836810410893 ║ 0.35463721323007735 ║\n",
      "║       ║  Time train  ║ 1.6717499941527545e-06 ║ 0.0012929617141094142 ║  0.4830548339693336  ║  0.4830548339693337 ║\n",
      "║       ║   Time val   ║ 1.719858246598131e-06  ║ 0.0013114336607690574 ║ 0.15394083706712502  ║ 0.42129935262774887 ║\n",
      "║       ║     Test     ║ 1.7618765596669607e-06 ║ 0.0013273569827544362 ║  0.4092203693592559  ║  0.4117529470254899 ║\n",
      "║       ║              ║                        ║                       ║                      ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩══════════════════════╩═════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "alpha=30\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha=alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.0005\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "features[(key,key1)]=['poverty_rate adj_rehab_budget', 'Population unemployment_rate', 'poverty_rate adj_judiciary_budget', 'mobile_home_ratio vacancy_rate', 'vacancy_rate^2', 'mobile_home_ratio dropout_rate', 'uninsured_rate security_vs_social', 'adj_judiciary_budget house_affordability', 'poverty_rate', 'unemployment_rate adj_mental_health_budget', 'clearance_rate Number_of_Persons_per_HseHld', 'Population adj_welfare_budget', 'Population mobile_home_ratio', 'house_affordability high_school_rate', 'population_density poverty_rate', 'adj_health_budget security_vs_social', 'public_school_rate', 'adjusted_income median_age', 'uninsured_rate^2']\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Suburban model\n",
      "Processing block 0 to 35\n",
      "Processing block 35 to 70\n",
      "Processing block 70 to 105\n",
      "Processing block 105 to 140\n",
      "Processing block 140 to 175\n",
      "Processing block 175 to 210\n",
      "Processing block 210 to 245\n",
      "Processing block 245 to 280\n",
      "Processing block 280 to 315\n",
      "Processing block 315 to 350\n",
      "Processing block 350 to 385\n",
      "Processing block 385 to 420\n",
      "Processing block 420 to 455\n",
      "Processing block 455 to 490\n",
      "Optimal subset of features:\n",
      "13 ['median_age adj_welfare_budget', 'adj_mental_health_budget public_school_rate', 'Population adj_mental_health_budget', 'mobile_home_ratio security_vs_social', 'Population^2', 'adj_police_budget dropout_rate', 'adjusted_income mobile_home_ratio', 'Population median_house_value', 'vacancy_rate adj_rehab_budget', 'clearance_rate adjusted_income', 'Number_of_Persons_per_HseHld adj_health_budget', 'vacancy_rate', 'mobile_home_ratio median_age']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.084827520840657e-06  ║ 0.0010407826494649483 ║  0.4254611480503951 ║  0.4254611480503951 ║\n",
      "║       ║   Reg val    ║ 1.118499863437804e-06  ║ 0.0010469014739057322 ║ 0.40966936802221865 ║  0.4189537803497417 ║\n",
      "║       ║ County train ║ 1.0513864176499912e-06 ║  0.001024199507634745 ║ 0.44139183764083195 ║  0.4413918376408319 ║\n",
      "║       ║  County val  ║ 1.2168130185264114e-06 ║ 0.0009534549426164902 ║  -4.634447392434016 ║  0.1765425216677351 ║\n",
      "║       ║  Time train  ║  9.71473617560713e-07  ║ 0.0009856336122316006 ║ 0.45920895898709213 ║ 0.45920895898709213 ║\n",
      "║       ║   Time val   ║ 1.4305999863957478e-06 ║ 0.0011960769149163225 ║  0.3054422535583967 ║  0.3182430851745971 ║\n",
      "║       ║     Test     ║ 1.119098078236703e-06  ║ 0.0010578743206244789 ║ 0.23524573533903037 ║ 0.23538683748699119 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 6\n",
    "alpha=100\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha=alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.0005\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,dd=35))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rural models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Rural model\n",
      "Optimal subset of features:\n",
      "16 ['adjusted_income public_school_rate', 'vacancy_rate', 'adj_rehab_budget', 'rent_burden social_vs_security', 'social_vs_security security_vs_social', 'adj_judiciary_budget public_school_rate', 'Population mobile_home_ratio', 'adj_education_budget^2', 'rent_burden uninsured_rate', 'adj_rehab_budget adj_prison_budget', 'rent_burden', 'population_density home_ownership_rate', 'population_density rent_burden', 'Number_of_Persons_per_HseHld', 'unemployment_rate median_house_value', 'poverty_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦══════════════════════╦══════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score       ║         MR2          ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬══════════════════════╬══════════════════════╣\n",
      "║ ridge ║  Reg train   ║  4.81996363546391e-06  ║  0.002193668851644663 ║  0.2611994289221312  ║  0.2611994289221312  ║\n",
      "║       ║   Reg val    ║ 5.224222379886138e-06  ║ 0.0022465421517318665 ║  0.1825907981115706  ║ 0.18833567588431982  ║\n",
      "║       ║ County train ║ 4.848706430401969e-06  ║ 0.0022011930544482746 ║  0.2600170405937869  ║  0.2600170405937869  ║\n",
      "║       ║  County val  ║ 1.6479522175148504e-05 ║ 0.0024396207555533703 ║ -0.7766516834652393  ║ -0.07779208611380845 ║\n",
      "║       ║  Time train  ║ 5.037044550837244e-06  ║  0.002244336104694937 ║  0.2723865006632088  ║  0.2723865006632088  ║\n",
      "║       ║   Time val   ║ 3.779309299167595e-06  ║ 0.0019440445723201913 ║ 0.059588163734013766 ║ 0.05964974795092637  ║\n",
      "║       ║     Test     ║ 4.927641703800084e-06  ║ 0.0022198292059976334 ║ 0.12792756978472564  ║  0.1280896799085166  ║\n",
      "║       ║              ║                        ║                       ║                      ║                      ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩══════════════════════╩══════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "alpha=100\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha=alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.0005\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,dd=35))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Rural model\n",
      "Optimal subset of features:\n",
      "21 ['Number_of_Persons_per_HseHld^2', 'clearance_rate house_affordability', 'renter_ratio^2', 'adjusted_income uninsured_rate', 'uninsured_rate security_vs_social', 'adjusted_income poverty_rate', 'uninsured_rate', 'mobile_home_ratio adj_prison_budget', 'mobile_home_ratio median_house_value', 'adj_judiciary_budget median_house_value', 'home_ownership_rate adj_judiciary_budget', 'adj_judiciary_budget public_school_rate', 'Population mobile_home_ratio', 'adj_education_budget^2', 'median_house_value', 'median_house_value security_vs_social', 'adjusted_income median_age', 'poverty_rate Number_of_Persons_per_HseHld', 'dropout_rate', 'adjusted_income mobile_home_ratio', 'Number_of_Persons_per_HseHld']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.7340051536174468e-06 ║ 0.0013155271267657974 ║  0.5174897723371974 ║  0.5174897723371974 ║\n",
      "║       ║   Reg val    ║ 1.913771181320401e-06  ║  0.001355259076376184 ║ 0.41243210705670996 ║  0.4706264771464994 ║\n",
      "║       ║ County train ║ 1.730320255873295e-06  ║ 0.0013150664661806734 ║  0.5187091885083269 ║  0.5187091885083269 ║\n",
      "║       ║  County val  ║ 2.0546966868824517e-06 ║  0.001277480666970049 ║ -1.1965082176067843 ║  0.3038188698632824 ║\n",
      "║       ║  Time train  ║ 1.4378985274782743e-06 ║ 0.0011991240667580125 ║  0.4818301171041268 ║  0.4818301171041268 ║\n",
      "║       ║   Time val   ║  3.04081693707832e-06  ║ 0.0017437938344535802 ║ 0.37637376050873006 ║  0.4282829838060229 ║\n",
      "║       ║     Test     ║ 1.5479601544559398e-06 ║ 0.0012441704684069382 ║  0.4313277597396613 ║ 0.43167224390096937 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "alpha=100\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge(alpha=alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.0005\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To save the dictionary\n",
    "joblib.dump(features, \"features.pkl\")\n",
    "\n",
    "# To load it later\n",
    "#features = joblib.load(\"features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "imputed Urban model\n",
      "The top 4 important features in ridge are:\n",
      "uninsured_rate^2\n",
      "home_ownership_rate\n",
      "clearance_rate home_ownership_rate\n",
      "security_vs_social\n",
      "\n",
      "\n",
      "dropna Urban model\n",
      "The top 4 important features in ridge are:\n",
      "dropout_rate\n",
      "clearance_rate\n",
      "security_vs_social\n",
      "home_ownership_rate adj_police_budget\n",
      "\n",
      "\n",
      "imputed Suburban model\n",
      "The top 4 important features in ridge are:\n",
      "public_school_rate\n",
      "uninsured_rate\n",
      "mobile_home_ratio\n",
      "adj_education_budget social_vs_security\n",
      "\n",
      "\n",
      "dropna Suburban model\n",
      "The top 4 important features in ridge are:\n",
      "adj_rehab_budget adj_judiciary_budget\n",
      "renter_ratio security_vs_social\n",
      "security_vs_social\n",
      "security_vs_social^2\n",
      "\n",
      "\n",
      "imputed Rural model\n",
      "The top 4 important features in ridge are:\n",
      "social_vs_security security_vs_social\n",
      "adj_rehab_budget\n",
      "vacancy_rate\n",
      "adj_education_budget^2\n",
      "\n",
      "\n",
      "dropna Rural model\n",
      "The top 4 important features in ridge are:\n",
      "uninsured_rate security_vs_social\n",
      "uninsured_rate\n",
      "mobile_home_ratio adj_prison_budget\n",
      "home_ownership_rate adj_judiciary_budget\n"
     ]
    }
   ],
   "source": [
    "for key1 in [\"Urban\",\"Suburban\",\"Rural\"]:\n",
    "    for key in [\"imputed\",\"dropna\"]:\n",
    "        print('\\n')\n",
    "        print(key+\" \"+key1+\" model\")\n",
    "        # Can set plot=True to visualize the feature importances\n",
    "        # Can modify models_to_use to include/exclude specific models\n",
    "        feature_importance_PCA(fitted_models[(key,key1)],features[(key,key1)],(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: log(y) =Ridge(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Urban model\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "11 ['uninsured_rate', 'adjusted_income', 'log_median_age', 'clearance_rate log_Population', 'log_mobile_home_ratio log_renter_ratio', 'adjusted_income mobile_home_ratio', 'log_poverty_rate log_vacancy_rate', 'security_vs_social', 'home_ownership_rate log_dropout_rate', 'log_clearance_rate^2', 'clearance_rate log_mobile_home_ratio']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║        MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 4.2516394502810894e-07 ║ 0.0006510867024536446 ║  0.8844399536139853 ║ 0.8844399536139853 ║\n",
      "║       ║   Reg val    ║ 4.3386684950407715e-07 ║ 0.0006494442753316565 ║  0.8687199816324668 ║ 0.8802326531221351 ║\n",
      "║       ║ County train ║ 4.053612342863489e-07  ║ 0.0006356257061149141 ║  0.8891771908532872 ║ 0.8891771908532872 ║\n",
      "║       ║  County val  ║ 5.603943869013076e-07  ║ 0.0006290433213542412 ║ -1.8120028501669647 ║ 0.7955594234381759 ║\n",
      "║       ║  Time train  ║ 3.3491707845114216e-07 ║ 0.0005787202073983094 ║  0.8974785963688785 ║ 0.8974785963688785 ║\n",
      "║       ║   Time val   ║ 5.765767264547608e-07  ║ 0.0007593264952935337 ║  0.8747229259970577 ║ 0.8810417485237999 ║\n",
      "║       ║     Test     ║ 6.106277431606741e-07  ║ 0.0007814267356321218 ║  0.8005542257170412 ║ 0.8072704624977401 ║\n",
      "║       ║              ║                        ║                       ║                     ║                    ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "log_median_age\n",
      "uninsured_rate\n",
      "security_vs_social\n",
      "home_ownership_rate log_dropout_rate\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Urban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 8\n",
    "alpha=20\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.002\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "ff=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,min_features=n_components))\n",
    "\n",
    "#ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "    X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models)\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])\n",
    "feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Suburban model\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "15 ['adj_prison_budget log_adj_health_budget', 'log_adj_police_budget log_dropout_rate', 'home_ownership_rate public_school_rate', 'log_home_ownership_rate log_renter_ratio', 'log_adj_health_budget log_social_vs_security', 'security_vs_social^2', 'log_adj_mental_health_budget log_adj_prison_budget', 'log_adj_judiciary_budget log_house_affordability', 'Number_of_Persons_per_HseHld high_school_rate', 'Population log_social_vs_security', 'log_adj_welfare_budget log_adj_rehab_budget', 'median_age log_adj_welfare_budget', 'security_vs_social log_adj_judiciary_budget', 'log_adj_police_budget log_adj_judiciary_budget', 'population_density mobile_home_ratio']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦══════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2          ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬══════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 9.760888953356727e-07  ║ 0.0009865416940819658 ║ 0.48319902582039836 ║  0.4831990258203985  ║\n",
      "║       ║   Reg val    ║ 1.0417245043812286e-06 ║ 0.0010077709479939393 ║ 0.44582564449166123 ║  0.4542816976453185  ║\n",
      "║       ║ County train ║  9.6894244617115e-07   ║ 0.0009831563068736695 ║ 0.48471161998402357 ║  0.4847116199840235  ║\n",
      "║       ║  County val  ║ 1.1156264390944046e-06 ║ 0.0008930895608651774 ║ -3.0576336786437452 ║ -0.09843942703335425 ║\n",
      "║       ║  Time train  ║ 6.834833680912678e-07  ║ 0.0008267305293088358 ║  0.6195247349349808 ║  0.6195247349349808  ║\n",
      "║       ║   Time val   ║ 1.7542826768989676e-06 ║ 0.0013244933661211624 ║ 0.14829397855772852 ║  0.1639910828270894  ║\n",
      "║       ║     Test     ║  9.1516183010003e-07   ║  0.00095664090969393  ║  0.3746089587369449 ║  0.3747243474615527  ║\n",
      "║       ║              ║                        ║                       ║                     ║                      ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩══════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "log_home_ownership_rate log_renter_ratio\n",
      "home_ownership_rate public_school_rate\n",
      "log_adj_health_budget log_social_vs_security\n",
      "adj_prison_budget log_adj_health_budget\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 7\n",
    "alpha=150 #Maybe increase more\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.002\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "ff=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,min_features=n_components))\n",
    "\n",
    "#ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "    X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models)\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])\n",
    "feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Rural model\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "24 ['adj_police_budget log_population_density', 'log_vacancy_rate log_adj_police_budget', 'clearance_rate dropout_rate', 'log_home_ownership_rate^2', 'log_vacancy_rate log_dropout_rate', 'adj_judiciary_budget log_vacancy_rate', 'clearance_rate log_adj_education_budget', 'unemployment_rate', 'log_poverty_rate log_dropout_rate', 'adj_mental_health_budget log_renter_ratio', 'vacancy_rate adj_welfare_budget', 'home_ownership_rate log_dropout_rate', 'clearance_rate security_vs_social', 'population_density adj_mental_health_budget', 'mobile_home_ratio^2', 'mobile_home_ratio adj_police_budget', 'log_mobile_home_ratio log_social_vs_security', 'clearance_rate', 'uninsured_rate', 'log_poverty_rate log_uninsured_rate', 'house_affordability', 'log_median_house_value log_high_school_rate', 'log_unemployment_rate^2', 'log_adjusted_income log_median_house_value']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦══════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2          ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬══════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.4675943042447258e-06 ║ 0.0012099109067676863 ║ 0.43376576256973715 ║ 0.43376576256973703  ║\n",
      "║       ║   Reg val    ║ 1.7361888243170973e-06 ║  0.001308294334604352 ║ 0.32277766202709507 ║  0.3396515652380918  ║\n",
      "║       ║ County train ║ 1.4898880933183188e-06 ║  0.00121981410116937  ║ 0.42424047013367266 ║ 0.42424047013367266  ║\n",
      "║       ║  County val  ║ 2.754633009282122e-06  ║ 0.0013683664080846602 ║  -2.461443779221233 ║ 0.07711332261770426  ║\n",
      "║       ║  Time train  ║ 1.216358683217159e-06  ║  0.001102886523272979 ║  0.4512258105805983 ║  0.4512258105805984  ║\n",
      "║       ║   Time val   ║ 2.662556882374468e-06  ║ 0.0016317343173367618 ║ 0.20507696817992704 ║ 0.25162778500331107  ║\n",
      "║       ║     Test     ║ 5.553738971745641e-06  ║ 0.0023566372168294467 ║ -0.1173995653261859 ║ -0.06359724916315401 ║\n",
      "║       ║              ║                        ║                       ║                     ║                      ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩══════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "mobile_home_ratio^2\n",
      "mobile_home_ratio adj_police_budget\n",
      "log_home_ownership_rate^2\n",
      "clearance_rate security_vs_social\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 7\n",
    "alpha=20\n",
    "models = {\n",
    "    #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "    #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "threshold_addition=0.002\n",
    "threshold_removal=0.002\n",
    "#Uncomment this to perform feature selection again\n",
    "ff=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_clean_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,min_features=n_components))\n",
    "\n",
    "#ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "    X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_clean_dt[(key,key1)],y_test_clean_dt[(key,key1)], **models)\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])\n",
    "feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Rural model\n",
      "n_components 5\n",
      "alpha 100\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "20 ['adj_judiciary_budget uninsured_rate', 'adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'home_ownership_rate log_adj_education_budget', 'poverty_rate log_adj_education_budget', 'adjusted_income median_age', 'median_house_value', 'log_poverty_rate log_dropout_rate', 'vacancy_rate adj_welfare_budget', 'adj_prison_budget log_population_density', 'adjusted_income high_school_rate', 'clearance_rate', 'vacancy_rate adj_health_budget', 'poverty_rate dropout_rate', 'uninsured_rate', 'renter_ratio log_poverty_rate', 'renter_ratio', 'unemployment_rate home_ownership_rate', 'median_age log_clearance_rate', 'mobile_home_ratio']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═══════════════════════╦══════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║        r2 Score       ║         MR2          ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═══════════════════════╬══════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.5856008942093027e-06 ║  0.001258612659985962 ║  0.38743457208449505  ║ 0.38743457208449505  ║\n",
      "║       ║   Reg val    ║ 1.7404923769937803e-06 ║ 0.0013109088013852552 ║  0.32204350869507853  ║  0.3377586665596695  ║\n",
      "║       ║ County train ║ 1.5812432637176225e-06 ║ 0.0012568027498651249 ║  0.38858106838230233  ║ 0.38858106838230233  ║\n",
      "║       ║  County val  ║ 2.793247926527765e-06  ║ 0.0014047610901991266 ║   -2.474682152464038  ║  0.1993864795191198  ║\n",
      "║       ║  Time train  ║ 1.3803071974951614e-06 ║ 0.0011748647571083071 ║   0.377258555468429   ║  0.377258555468429   ║\n",
      "║       ║   Time val   ║ 2.9543157708040334e-06 ║  0.001718812314013381 ║  0.11797052486366155  ║ 0.16962230860414151  ║\n",
      "║       ║     Test     ║ 5.162913340529857e-06  ║ 0.0022722045111586804 ║ -0.038766343156296346 ║ 0.011249816638518984 ║\n",
      "║       ║              ║                        ║                       ║                       ║                      ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═══════════════════════╩══════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "mobile_home_ratio\n",
      "clearance_rate dropout_rate\n",
      "uninsured_rate\n",
      "clearance_rate\n",
      "n_components 6\n",
      "alpha 100\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "13 ['adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'poverty_rate log_Number_of_Persons_per_HseHld', 'security_vs_social log_population_density', 'median_house_value', 'log_adj_education_budget log_dropout_rate', 'log_unemployment_rate log_high_school_rate', 'vacancy_rate adj_welfare_budget', 'adjusted_income median_house_value', 'adj_mental_health_budget dropout_rate', 'adj_prison_budget dropout_rate', 'uninsured_rate log_renter_ratio', 'clearance_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.452808279308953e-06  ║  0.001205194159853501 ║  0.4385824686027779 ║  0.4385824686027779 ║\n",
      "║       ║   Reg val    ║ 1.5068694798328312e-06 ║ 0.0012259830858619351 ║ 0.40462247145693936 ║ 0.41887053306145583 ║\n",
      "║       ║ County train ║  1.40067420901362e-06  ║ 0.0011833333093768776 ║ 0.45848647314493723 ║ 0.45848647314493735 ║\n",
      "║       ║  County val  ║ 1.9817172106086618e-06 ║  0.001223019847492214 ║  -1.597799200597487 ║ 0.30462995357585176 ║\n",
      "║       ║  Time train  ║ 1.3087908920755046e-06 ║ 0.0011440239910401812 ║  0.4095239580001392 ║  0.4095239580001392 ║\n",
      "║       ║   Time val   ║ 2.227992624508157e-06  ║ 0.0014926461819561115 ║  0.3348188488775743 ║  0.3737719609158181 ║\n",
      "║       ║     Test     ║  4.16133683884376e-06  ║ 0.0020399354986968977 ║ 0.16274855578271408 ║ 0.20306185847903646 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "uninsured_rate log_renter_ratio\n",
      "clearance_rate dropout_rate\n",
      "clearance_rate\n",
      "adj_prison_budget dropout_rate\n",
      "n_components 7\n",
      "alpha 100\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "15 ['adjusted_income log_high_school_rate', 'adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'clearance_rate log_house_affordability', 'security_vs_social log_population_density', 'adj_health_budget uninsured_rate', 'adj_judiciary_budget median_house_value', 'log_home_ownership_rate log_adj_education_budget', 'log_poverty_rate log_dropout_rate', 'poverty_rate', 'vacancy_rate adj_welfare_budget', 'median_house_value log_mobile_home_ratio', 'adj_judiciary_budget log_Population', 'adj_mental_health_budget uninsured_rate', 'vacancy_rate log_clearance_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.3403134273800463e-06 ║ 0.0011573210759599003 ║ 0.48217683381222665 ║ 0.48217683381222665 ║\n",
      "║       ║   Reg val    ║ 1.3691255244319874e-06 ║ 0.0011655914946028328 ║  0.4567080784416707 ║ 0.47024686444975117 ║\n",
      "║       ║ County train ║ 1.2958197978464714e-06 ║ 0.0011381315512309564 ║  0.4991091980301296 ║  0.4991091980301296 ║\n",
      "║       ║  County val  ║ 1.610736036926655e-06  ║  0.00114239469315705  ║  -0.987836631360128 ║  0.3621399586475821 ║\n",
      "║       ║  Time train  ║ 1.2577786095655426e-06 ║  0.001121507293585531 ║  0.4325387351140705 ║  0.4325387351140705 ║\n",
      "║       ║   Time val   ║ 2.193381985698989e-06  ║ 0.0014810070849590792 ║  0.3451520718473978 ║  0.3835000687356098 ║\n",
      "║       ║     Test     ║ 4.255677972399297e-06  ║  0.002062929463747924 ║ 0.14376733571392097 ║ 0.18499457612329695 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "clearance_rate dropout_rate\n",
      "adj_prison_budget uninsured_rate\n",
      "vacancy_rate log_clearance_rate\n",
      "adj_mental_health_budget uninsured_rate\n",
      "n_components 8\n",
      "alpha 100\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "19 ['adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'clearance_rate unemployment_rate', 'log_uninsured_rate log_dropout_rate', 'poverty_rate log_adj_education_budget', 'adjusted_income median_age', 'population_density log_uninsured_rate', 'log_clearance_rate log_renter_ratio', 'vacancy_rate log_poverty_rate', 'log_adj_prison_budget log_security_vs_social', 'high_school_rate log_adj_judiciary_budget', 'clearance_rate log_home_ownership_rate', 'median_house_value log_median_age', 'log_poverty_rate log_high_school_rate', 'vacancy_rate adj_rehab_budget', 'adj_prison_budget log_uninsured_rate', 'public_school_rate', 'vacancy_rate log_clearance_rate', 'high_school_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.3524629774279488e-06 ║ 0.0011625507423693284 ║  0.4769265985202968 ║  0.4769265985202968 ║\n",
      "║       ║   Reg val    ║ 1.6636690064687614e-06 ║ 0.0012823438874727498 ║ 0.35138421818064947 ║ 0.36604083494634726 ║\n",
      "║       ║ County train ║ 1.2828251564309543e-06 ║ 0.0011323615365966785 ║  0.5039126711825028 ║  0.5039126711825028 ║\n",
      "║       ║  County val  ║ 2.6870002255046903e-06 ║ 0.0013204215033729642 ║ -2.9146067168325875 ║ 0.20668277615586197 ║\n",
      "║       ║  Time train  ║ 1.375687057671135e-06  ║ 0.0011728968657435891 ║  0.3793429846108497 ║  0.3793429846108498 ║\n",
      "║       ║   Time val   ║ 3.2381162682562708e-06 ║ 0.0017994766651046829 ║ 0.03324010901407115 ║ 0.08985371913232332 ║\n",
      "║       ║     Test     ║ 3.0638631731673535e-06 ║ 0.0017503894347165585 ║  0.3835577445513211 ║  0.4132391782596121 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "clearance_rate dropout_rate\n",
      "vacancy_rate adj_rehab_budget\n",
      "public_school_rate\n",
      "adj_prison_budget uninsured_rate\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "for n_components in [5,6,7,8]:\n",
    "    print(\"n_components\",n_components)\n",
    "    alpha=100\n",
    "    print(\"alpha\",alpha)\n",
    "    models = {\n",
    "        #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "        #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "        \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "        #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "    }\n",
    "\n",
    "    threshold_addition=0.002\n",
    "    threshold_removal=0.002\n",
    "    #Uncomment this to perform feature selection again\n",
    "    ff=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_clean_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,min_features=n_components))\n",
    "\n",
    "    #ff=features[(key,key1)]\n",
    "    print(\"Optimal subset of features:\")\n",
    "    print(len(ff),ff)\n",
    "\n",
    "\n",
    "    fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "        X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_clean_dt[(key,key1)],y_test_clean_dt[(key,key1)], **models)\n",
    "\n",
    "    # Using pretty table\n",
    "    print_table(models_stats[(key,key1)])\n",
    "    feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Rural model\n",
      "n_components 7\n",
      "alpha 70\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "19 ['adj_police_budget log_uninsured_rate', 'adj_police_budget log_population_density', 'adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'clearance_rate log_house_affordability', 'poverty_rate', 'vacancy_rate log_adj_health_budget', 'adj_judiciary_budget log_uninsured_rate', 'median_house_value log_vacancy_rate', 'poverty_rate log_dropout_rate', 'dropout_rate log_public_school_rate', 'clearance_rate high_school_rate', 'unemployment_rate adj_prison_budget', 'unemployment_rate log_social_vs_security', 'renter_ratio log_poverty_rate', 'security_vs_social log_population_density', 'log_adj_education_budget log_dropout_rate', 'mobile_home_ratio', 'median_house_value high_school_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.2212253835040832e-06 ║ 0.0011046365403953179 ║  0.5281829739493912 ║  0.5281829739493912 ║\n",
      "║       ║   Reg val    ║ 1.4638266485397683e-06 ║ 0.0012036708782690582 ║  0.4281076019382054 ║  0.4417176415764468 ║\n",
      "║       ║ County train ║ 1.1916169350627576e-06 ║ 0.0010914182199767946 ║  0.5392856687291142 ║  0.5392856687291141 ║\n",
      "║       ║  County val  ║ 2.0884627444872933e-06 ║ 0.0012174725147689254 ║ -1.8638703490656006 ║ 0.28787062841847527 ║\n",
      "║       ║  Time train  ║ 1.1656801620121343e-06 ║ 0.0010796666902392303 ║  0.4740900074486666 ║  0.4740900074486666 ║\n",
      "║       ║   Time val   ║ 2.2849780063163996e-06 ║ 0.0015116143709016528 ║  0.3178055062608206 ║ 0.35775492229832395 ║\n",
      "║       ║     Test     ║ 4.267047665474238e-06  ║  0.002065683341045824 ║ 0.14147977949918622 ║ 0.18281716477215904 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "dropout_rate log_public_school_rate\n",
      "mobile_home_ratio\n",
      "clearance_rate dropout_rate\n",
      "adj_prison_budget uninsured_rate\n",
      "n_components 7\n",
      "alpha 100\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "15 ['adjusted_income log_high_school_rate', 'adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'clearance_rate log_house_affordability', 'security_vs_social log_population_density', 'adj_health_budget uninsured_rate', 'adj_judiciary_budget median_house_value', 'log_home_ownership_rate log_adj_education_budget', 'log_poverty_rate log_dropout_rate', 'poverty_rate', 'vacancy_rate adj_welfare_budget', 'median_house_value log_mobile_home_ratio', 'adj_judiciary_budget log_Population', 'adj_mental_health_budget uninsured_rate', 'vacancy_rate log_clearance_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.3403134273800463e-06 ║ 0.0011573210759599003 ║ 0.48217683381222665 ║ 0.48217683381222665 ║\n",
      "║       ║   Reg val    ║ 1.3691255244319874e-06 ║ 0.0011655914946028328 ║  0.4567080784416707 ║ 0.47024686444975117 ║\n",
      "║       ║ County train ║ 1.2958197978464714e-06 ║ 0.0011381315512309564 ║  0.4991091980301296 ║  0.4991091980301296 ║\n",
      "║       ║  County val  ║ 1.610736036926655e-06  ║  0.00114239469315705  ║  -0.987836631360128 ║  0.3621399586475821 ║\n",
      "║       ║  Time train  ║ 1.2577786095655426e-06 ║  0.001121507293585531 ║  0.4325387351140705 ║  0.4325387351140705 ║\n",
      "║       ║   Time val   ║ 2.193381985698989e-06  ║ 0.0014810070849590792 ║  0.3451520718473978 ║  0.3835000687356098 ║\n",
      "║       ║     Test     ║ 4.255677972399297e-06  ║  0.002062929463747924 ║ 0.14376733571392097 ║ 0.18499457612329695 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "clearance_rate dropout_rate\n",
      "adj_prison_budget uninsured_rate\n",
      "vacancy_rate log_clearance_rate\n",
      "adj_mental_health_budget uninsured_rate\n",
      "n_components 7\n",
      "alpha 130\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "16 ['clearance_rate dropout_rate', 'clearance_rate unemployment_rate', 'median_age log_house_affordability', 'poverty_rate', 'vacancy_rate adj_welfare_budget', 'clearance_rate', 'log_adj_education_budget log_public_school_rate', 'median_age log_unemployment_rate', 'log_unemployment_rate log_poverty_rate', 'log_median_age', 'high_school_rate log_house_affordability', 'log_poverty_rate log_uninsured_rate', 'clearance_rate log_clearance_rate', 'home_ownership_rate log_vacancy_rate', 'mobile_home_ratio', 'high_school_rate']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦══════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score       ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬══════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.5765493657610401e-06 ║ 0.0012552961900721903 ║ 0.39097184699441395  ║ 0.39097184699441395 ║\n",
      "║       ║   Reg val    ║ 1.6180251523070717e-06 ║ 0.0012685367930256796 ║  0.3639521855848059  ║  0.3792039361536236 ║\n",
      "║       ║ County train ║ 1.526164815534887e-06  ║ 0.0012351056401559916 ║  0.4101860304651887  ║  0.4101860304651887 ║\n",
      "║       ║  County val  ║ 2.1212869384294522e-06 ║ 0.0012678788474897915 ║ -1.7640110534830102  ║  0.2825964689504809 ║\n",
      "║       ║  Time train  ║ 1.4307711364260015e-06 ║ 0.0011961484591914173 ║  0.3544911698577672  ║  0.3544911698577672 ║\n",
      "║       ║   Time val   ║ 2.4516484265973413e-06 ║ 0.0015657740662679725 ║  0.268045008492113   ║  0.310908407046097  ║\n",
      "║       ║     Test     ║ 4.817132702506621e-06  ║  0.00219479673375614  ║ 0.030803929517849604 ║ 0.07747031012703398 ║\n",
      "║       ║              ║                        ║                       ║                      ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩══════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "mobile_home_ratio\n",
      "clearance_rate dropout_rate\n",
      "clearance_rate log_clearance_rate\n",
      "clearance_rate\n",
      "n_components 7\n",
      "alpha 160\n",
      "Processing block 0 to 25\n",
      "Processing block 25 to 50\n",
      "Processing block 50 to 75\n",
      "Processing block 75 to 100\n",
      "Processing block 100 to 125\n",
      "Processing block 125 to 150\n",
      "Processing block 150 to 175\n",
      "Processing block 175 to 200\n",
      "Processing block 200 to 225\n",
      "Processing block 225 to 250\n",
      "Processing block 250 to 275\n",
      "Processing block 275 to 300\n",
      "Processing block 300 to 325\n",
      "Processing block 325 to 350\n",
      "Processing block 350 to 375\n",
      "Processing block 375 to 400\n",
      "Processing block 400 to 425\n",
      "Processing block 425 to 450\n",
      "Processing block 450 to 475\n",
      "Processing block 475 to 500\n",
      "Processing block 500 to 525\n",
      "Processing block 525 to 550\n",
      "Processing block 550 to 575\n",
      "Processing block 575 to 600\n",
      "Processing block 600 to 625\n",
      "Processing block 625 to 650\n",
      "Processing block 650 to 675\n",
      "Processing block 675 to 700\n",
      "Processing block 700 to 725\n",
      "Processing block 725 to 750\n",
      "Processing block 750 to 775\n",
      "Processing block 775 to 800\n",
      "Processing block 800 to 825\n",
      "Processing block 825 to 850\n",
      "Processing block 850 to 875\n",
      "Processing block 875 to 900\n",
      "Processing block 900 to 925\n",
      "Processing block 925 to 950\n",
      "Processing block 950 to 975\n",
      "Processing block 975 to 1000\n",
      "Processing block 1000 to 1025\n",
      "Processing block 1025 to 1050\n",
      "Processing block 1050 to 1075\n",
      "Processing block 1075 to 1100\n",
      "Processing block 1100 to 1125\n",
      "Processing block 1125 to 1150\n",
      "Processing block 1150 to 1175\n",
      "Processing block 1175 to 1200\n",
      "Processing block 1200 to 1225\n",
      "Processing block 1225 to 1250\n",
      "Processing block 1250 to 1275\n",
      "Processing block 1275 to 1300\n",
      "Processing block 1300 to 1325\n",
      "Processing block 1325 to 1350\n",
      "Processing block 1350 to 1375\n",
      "Processing block 1375 to 1400\n",
      "Processing block 1400 to 1425\n",
      "Processing block 1425 to 1450\n",
      "Processing block 1450 to 1475\n",
      "Processing block 1475 to 1500\n",
      "Processing block 1500 to 1525\n",
      "Processing block 1525 to 1550\n",
      "Processing block 1550 to 1575\n",
      "Processing block 1575 to 1600\n",
      "Processing block 1600 to 1625\n",
      "Processing block 1625 to 1650\n",
      "Processing block 1650 to 1675\n",
      "Processing block 1675 to 1700\n",
      "Processing block 1700 to 1725\n",
      "Processing block 1725 to 1750\n",
      "Processing block 1750 to 1775\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "15 ['adjusted_income security_vs_social', 'log_adjusted_income log_uninsured_rate', 'clearance_rate adj_judiciary_budget', 'adj_prison_budget uninsured_rate', 'clearance_rate dropout_rate', 'clearance_rate high_school_rate', 'adj_judiciary_budget log_unemployment_rate', 'log_poverty_rate log_home_ownership_rate', 'log_adj_education_budget log_dropout_rate', 'adj_health_budget log_population_density', 'log_population_density log_uninsured_rate', 'security_vs_social log_adj_judiciary_budget', 'vacancy_rate adj_rehab_budget', 'adj_judiciary_budget log_uninsured_rate', 'log_adjusted_income log_median_house_value']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.528462256353399e-06  ║ 0.0012360974469719345 ║ 0.40936846509164726 ║ 0.40936846509164726 ║\n",
      "║       ║   Reg val    ║ 1.5430570003842798e-06 ║ 0.0012360770260696845 ║  0.3843799672264484 ║  0.3998905311242256 ║\n",
      "║       ║ County train ║ 1.4616547274927105e-06 ║ 0.0012088084009392406 ║  0.4349837087931503 ║  0.4349837087931503 ║\n",
      "║       ║  County val  ║ 1.7692952465399465e-06 ║ 0.0012022992282919056 ║ -1.2196355492965774 ║ 0.31938814248103026 ║\n",
      "║       ║  Time train  ║ 1.4291085512065615e-06 ║ 0.0011954532827369547 ║  0.3552412642737709 ║  0.3552412642737709 ║\n",
      "║       ║   Time val   ║ 2.485958864708998e-06  ║ 0.0015766923811286076 ║ 0.25780141232057485 ║  0.3012646774652932 ║\n",
      "║       ║     Test     ║ 3.825593076774695e-06  ║ 0.0019559123387244874 ║ 0.23029943199521874 ║  0.2673601885908863 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "clearance_rate dropout_rate\n",
      "vacancy_rate adj_rehab_budget\n",
      "adj_prison_budget uninsured_rate\n",
      "security_vs_social log_adj_judiciary_budget\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "for alpha in [70,100,130,160]:\n",
    "    n_components=7\n",
    "    print(\"n_components\",n_components)\n",
    "    print(\"alpha\",alpha)\n",
    "    models = {\n",
    "        #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "        #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "        \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "        #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "    }\n",
    "\n",
    "    threshold_addition=0.002\n",
    "    threshold_removal=0.002\n",
    "    #Uncomment this to perform feature selection again\n",
    "    ff=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_clean_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,dd=25,min_features=n_components))\n",
    "\n",
    "    #ff=features[(key,key1)]\n",
    "    print(\"Optimal subset of features:\")\n",
    "    print(len(ff),ff)\n",
    "\n",
    "\n",
    "    fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "        X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_clean_dt[(key,key1)],y_test_clean_dt[(key,key1)], **models)\n",
    "\n",
    "    # Using pretty table\n",
    "    print_table(models_stats[(key,key1)])\n",
    "    feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Suburban model\n",
      "n_components 7\n",
      "alpha 130\n",
      "Processing block 0 to 50\n",
      "Processing block 50 to 100\n",
      "Processing block 100 to 150\n",
      "Processing block 150 to 200\n",
      "Processing block 200 to 250\n",
      "Processing block 250 to 300\n",
      "Processing block 300 to 350\n",
      "Processing block 350 to 400\n",
      "Processing block 400 to 450\n",
      "Processing block 450 to 500\n",
      "Processing block 500 to 550\n",
      "Processing block 550 to 600\n",
      "Processing block 600 to 650\n",
      "Processing block 650 to 700\n",
      "Processing block 700 to 750\n",
      "Processing block 750 to 800\n",
      "Processing block 800 to 850\n",
      "Processing block 850 to 900\n",
      "Processing block 900 to 950\n",
      "Processing block 950 to 1000\n",
      "Processing block 1000 to 1050\n",
      "Processing block 1050 to 1100\n",
      "Processing block 1100 to 1150\n",
      "Processing block 1150 to 1200\n",
      "Processing block 1200 to 1250\n",
      "Processing block 1250 to 1300\n",
      "Processing block 1300 to 1350\n",
      "Processing block 1350 to 1400\n",
      "Processing block 1400 to 1450\n",
      "Processing block 1450 to 1500\n",
      "Processing block 1500 to 1550\n",
      "Processing block 1550 to 1600\n",
      "Processing block 1600 to 1650\n",
      "Processing block 1650 to 1700\n",
      "Processing block 1700 to 1750\n",
      "Processing block 1750 to 1800\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "13 ['log_home_ownership_rate log_renter_ratio', 'log_adj_education_budget log_adj_health_budget', 'adj_prison_budget security_vs_social', 'log_adj_welfare_budget log_adj_health_budget', 'Number_of_Persons_per_HseHld adj_judiciary_budget', 'adj_police_budget adj_prison_budget', 'log_adj_police_budget log_house_affordability', 'median_age log_adj_welfare_budget', 'vacancy_rate adj_rehab_budget', 'clearance_rate security_vs_social', 'mobile_home_ratio log_adj_health_budget', 'adj_judiciary_budget', 'population_density mobile_home_ratio']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.2441242407210062e-06 ║ 0.0011151053759369855 ║ 0.34033497795572504 ║ 0.34033497795572504 ║\n",
      "║       ║   Reg val    ║ 1.288354074091959e-06  ║ 0.0011294289329466143 ║  0.3066146723636816 ║  0.3173573673309865 ║\n",
      "║       ║ County train ║ 1.2008934238707626e-06 ║ 0.0010948765252509793 ║  0.3619208027296337 ║  0.3619208027296337 ║\n",
      "║       ║  County val  ║ 1.3008660600701665e-06 ║ 0.0009471083164343824 ║ -3.8801551946741766 ║ 0.18270705089051575 ║\n",
      "║       ║  Time train  ║ 9.728962954830924e-07  ║ 0.0009863550554861532 ║  0.4584169956637838 ║  0.4584169956637838 ║\n",
      "║       ║   Time val   ║ 1.9281545001496353e-06 ║ 0.0013885800301565753 ║ 0.06387903176961263 ║ 0.08113191959370492 ║\n",
      "║       ║     Test     ║ 1.036969719993686e-06  ║ 0.0010183171018860904 ║  0.291369513439797  ║ 0.29150026038477606 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "log_home_ownership_rate log_renter_ratio\n",
      "vacancy_rate adj_rehab_budget\n",
      "mobile_home_ratio log_adj_health_budget\n",
      "adj_prison_budget security_vs_social\n",
      "n_components 7\n",
      "alpha 140\n",
      "Processing block 0 to 50\n",
      "Processing block 50 to 100\n",
      "Processing block 100 to 150\n",
      "Processing block 150 to 200\n",
      "Processing block 200 to 250\n",
      "Processing block 250 to 300\n",
      "Processing block 300 to 350\n",
      "Processing block 350 to 400\n",
      "Processing block 400 to 450\n",
      "Processing block 450 to 500\n",
      "Processing block 500 to 550\n",
      "Processing block 550 to 600\n",
      "Processing block 600 to 650\n",
      "Processing block 650 to 700\n",
      "Processing block 700 to 750\n",
      "Processing block 750 to 800\n",
      "Processing block 800 to 850\n",
      "Processing block 850 to 900\n",
      "Processing block 900 to 950\n",
      "Processing block 950 to 1000\n",
      "Processing block 1000 to 1050\n",
      "Processing block 1050 to 1100\n",
      "Processing block 1100 to 1150\n",
      "Processing block 1150 to 1200\n",
      "Processing block 1200 to 1250\n",
      "Processing block 1250 to 1300\n",
      "Processing block 1300 to 1350\n",
      "Processing block 1350 to 1400\n",
      "Processing block 1400 to 1450\n",
      "Processing block 1450 to 1500\n",
      "Processing block 1500 to 1550\n",
      "Processing block 1550 to 1600\n",
      "Processing block 1600 to 1650\n",
      "Processing block 1650 to 1700\n",
      "Processing block 1700 to 1750\n",
      "Processing block 1750 to 1800\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "16 ['Population log_median_house_value', 'log_mobile_home_ratio log_adj_police_budget', 'adj_police_budget adj_judiciary_budget', 'security_vs_social log_rent_burden', 'adj_police_budget log_security_vs_social', 'Population log_social_vs_security', 'log_adj_police_budget log_house_affordability', 'Population log_security_vs_social', 'population_density mobile_home_ratio', 'log_unemployment_rate log_adj_health_budget', 'log_home_ownership_rate log_renter_ratio', 'Population log_adj_prison_budget', 'median_age log_adj_welfare_budget', 'vacancy_rate adj_rehab_budget', 'log_dropout_rate log_social_vs_security', 'adj_judiciary_budget']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.2248148253949128e-06 ║ 0.0011059970083312199 ║  0.3512727409555835 ║  0.3512727409555835 ║\n",
      "║       ║   Reg val    ║ 1.263640178414046e-06  ║ 0.0011153568451794395 ║ 0.32928545116944097 ║  0.3395860730162707 ║\n",
      "║       ║ County train ║ 1.180051506036309e-06  ║ 0.0010850219139629045 ║ 0.37339637560619227 ║ 0.37339637560619227 ║\n",
      "║       ║  County val  ║ 1.4962455502994882e-06 ║ 0.0009877005200578598 ║  -4.881247370027974 ║ 0.21831069021230196 ║\n",
      "║       ║  Time train  ║ 1.0000690668513166e-06 ║   0.0010000345328294  ║ 0.44329070602523957 ║ 0.44329070602523957 ║\n",
      "║       ║   Time val   ║ 1.770585349092667e-06  ║ 0.0013306334390404695 ║  0.1403790146492221 ║  0.1562219932116281 ║\n",
      "║       ║     Test     ║ 1.0512472489816416e-06 ║ 0.0010253034911584186 ║ 0.28161272679642824 ║  0.2817452739321563 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "vacancy_rate adj_rehab_budget\n",
      "log_home_ownership_rate log_renter_ratio\n",
      "adj_police_budget log_security_vs_social\n",
      "adj_judiciary_budget\n",
      "n_components 7\n",
      "alpha 150\n",
      "Processing block 0 to 50\n",
      "Processing block 50 to 100\n",
      "Processing block 100 to 150\n",
      "Processing block 150 to 200\n",
      "Processing block 200 to 250\n",
      "Processing block 250 to 300\n",
      "Processing block 300 to 350\n",
      "Processing block 350 to 400\n",
      "Processing block 400 to 450\n",
      "Processing block 450 to 500\n",
      "Processing block 500 to 550\n",
      "Processing block 550 to 600\n",
      "Processing block 600 to 650\n",
      "Processing block 650 to 700\n",
      "Processing block 700 to 750\n",
      "Processing block 750 to 800\n",
      "Processing block 800 to 850\n",
      "Processing block 850 to 900\n",
      "Processing block 900 to 950\n",
      "Processing block 950 to 1000\n",
      "Processing block 1000 to 1050\n",
      "Processing block 1050 to 1100\n",
      "Processing block 1100 to 1150\n",
      "Processing block 1150 to 1200\n",
      "Processing block 1200 to 1250\n",
      "Processing block 1250 to 1300\n",
      "Processing block 1300 to 1350\n",
      "Processing block 1350 to 1400\n",
      "Processing block 1400 to 1450\n",
      "Processing block 1450 to 1500\n",
      "Processing block 1500 to 1550\n",
      "Processing block 1550 to 1600\n",
      "Processing block 1600 to 1650\n",
      "Processing block 1650 to 1700\n",
      "Processing block 1700 to 1750\n",
      "Processing block 1750 to 1800\n",
      "finished blocks\n",
      "Optimal subset of features:\n",
      "15 ['adj_welfare_budget log_population_density', 'adj_police_budget adj_judiciary_budget', 'log_home_ownership_rate log_renter_ratio', 'adj_police_budget log_security_vs_social', 'log_adj_education_budget log_adj_health_budget', 'vacancy_rate log_adj_judiciary_budget', 'Population log_social_vs_security', 'social_vs_security log_adj_police_budget', 'median_house_value log_adj_mental_health_budget', 'rent_burden log_adj_welfare_budget', 'adj_health_budget log_Number_of_Persons_per_HseHld', 'Number_of_Persons_per_HseHld adj_rehab_budget', 'Number_of_Persons_per_HseHld adj_health_budget', 'log_adj_police_budget log_social_vs_security', 'log_adj_police_budget log_adj_rehab_budget']\n",
      "╔═══════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║ Model ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2         ║\n",
      "╠═══════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║ ridge ║  Reg train   ║ 1.1943344436444236e-06 ║ 0.0010923499575439014 ║  0.3673161827061481 ║  0.3673161827061481 ║\n",
      "║       ║   Reg val    ║ 1.230435955975941e-06  ║ 0.0011028875416489612 ║ 0.34384338021530864 ║  0.353698834384561  ║\n",
      "║       ║ County train ║ 1.1443048947663359e-06 ║ 0.0010687245923307865 ║  0.3921675059141756 ║  0.3921675059141756 ║\n",
      "║       ║  County val  ║ 1.3384421481710399e-06 ║ 0.0009376165955840249 ║  -4.208272129175337 ║  0.2440326552173343 ║\n",
      "║       ║  Time train  ║ 1.0202735978748224e-06 ║ 0.0010100859358860624 ║  0.4320434326378113 ║  0.4320434326378113 ║\n",
      "║       ║   Time val   ║ 1.8188776660520328e-06 ║ 0.0013486577275395092 ║  0.1169330457154143 ║ 0.13320813795294362 ║\n",
      "║       ║     Test     ║ 1.1273764053022295e-06 ║ 0.0010617798290145793 ║ 0.22958860300117945 ║ 0.22973074892694056 ║\n",
      "║       ║              ║                        ║                       ║                     ║                     ║\n",
      "╚═══════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩═════════════════════╝\n",
      "The top 4 important features in ridge are:\n",
      "log_home_ownership_rate log_renter_ratio\n",
      "vacancy_rate log_adj_judiciary_budget\n",
      "adj_police_budget log_security_vs_social\n",
      "Number_of_Persons_per_HseHld adj_rehab_budget\n",
      "n_components 7\n",
      "alpha 160\n",
      "Processing block 0 to 50\n",
      "Processing block 50 to 100\n",
      "Processing block 100 to 150\n",
      "Processing block 150 to 200\n",
      "Processing block 200 to 250\n",
      "Processing block 250 to 300\n",
      "Processing block 300 to 350\n",
      "Processing block 350 to 400\n",
      "Processing block 400 to 450\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m threshold_removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#Uncomment this to perform feature selection again\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m ff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mPoly_feature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_Poly_log_dt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_Poly_log_dt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_dt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mridge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_addition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_addition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_removal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_removal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmin_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#ff=features[(key,key1)]\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal subset of features:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[48], line 47\u001b[0m, in \u001b[0;36mPoly_feature_selection\u001b[1;34m(S, X, y, model, threshold_addition, threshold_removal, dd, min_features)\u001b[0m\n\u001b[0;32m     45\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(ll[i:i\u001b[38;5;241m+\u001b[39mdd])\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Use add_features (DFS) to try to add the features in this block.\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m S0 \u001b[38;5;241m=\u001b[39m \u001b[43madd_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_addition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Then run removal on the updated S0 to prune any redundant features.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m S0 \u001b[38;5;241m=\u001b[39m remove_features(S0, X, y, model, threshold\u001b[38;5;241m=\u001b[39mthreshold_removal,min_features\u001b[38;5;241m=\u001b[39mmin_features)\n",
      "Cell \u001b[1;32mIn[47], line 85\u001b[0m, in \u001b[0;36madd_features\u001b[1;34m(S1, S2, X, y, model, threshold)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_avg \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m current_avg \u001b[38;5;241m+\u001b[39m threshold:\n\u001b[0;32m     84\u001b[0m     remaining \u001b[38;5;241m=\u001b[39m S2 \u001b[38;5;241m-\u001b[39m {feat}\n\u001b[1;32m---> 85\u001b[0m     candidate \u001b[38;5;241m=\u001b[39m \u001b[43madd_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     candidate_avg \u001b[38;5;241m=\u001b[39m compute_avg_MR2_fast(candidate, X, y, model)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m candidate_avg \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m current_avg \u001b[38;5;241m+\u001b[39m threshold:\n",
      "Cell \u001b[1;32mIn[47], line 82\u001b[0m, in \u001b[0;36madd_features\u001b[1;34m(S1, S2, X, y, model, threshold)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(S2):\n\u001b[0;32m     81\u001b[0m     new_set \u001b[38;5;241m=\u001b[39m S1 \u001b[38;5;241m|\u001b[39m {feat}\n\u001b[1;32m---> 82\u001b[0m     new_avg \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_avg_MR2_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_avg \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m current_avg \u001b[38;5;241m+\u001b[39m threshold:\n\u001b[0;32m     84\u001b[0m         remaining \u001b[38;5;241m=\u001b[39m S2 \u001b[38;5;241m-\u001b[39m {feat}\n",
      "Cell \u001b[1;32mIn[16], line 102\u001b[0m, in \u001b[0;36mcompute_avg_MR2_fast\u001b[1;34m(S, X, y, model, n_splits, random_state)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Clone and fit the model on the current training fold\u001b[39;00m\n\u001b[0;32m    101\u001b[0m model_clone \u001b[38;5;241m=\u001b[39m clone(model)\n\u001b[1;32m--> 102\u001b[0m \u001b[43mmodel_clone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_clone\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m    104\u001b[0m mse_model \u001b[38;5;241m=\u001b[39m mean_squared_error(y_val, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\pipeline.py:654\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    651\u001b[0m     )\n\u001b[0;32m    653\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 654\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\pipeline.py:588\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m    582\u001b[0m step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    583\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39mstep_idx,\n\u001b[0;32m    584\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[0;32m    585\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mraw_params,\n\u001b[0;32m    586\u001b[0m )\n\u001b[1;32m--> 588\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\pipeline.py:1551\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1551\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1553\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1554\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1555\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\base.py:921\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1016\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(X)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1016\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_ \u001b[38;5;241m=\u001b[39m \u001b[43m_incremental_mean_and_var\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples_seen_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# missing values)\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mptp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_seen_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1095\u001b[0m, in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[0;32m   1091\u001b[0m     new_sample_count \u001b[38;5;241m=\u001b[39m _safe_accumulator_op(\n\u001b[0;32m   1092\u001b[0m         np\u001b[38;5;241m.\u001b[39msum, sample_weight[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m~\u001b[39mX_nan_mask), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1093\u001b[0m     )\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1095\u001b[0m     new_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_safe_accumulator_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43msum_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1096\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1097\u001b[0m     new_sample_count \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X_nan_mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1017\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1015\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1017\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deepe\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "for alpha in [130,140,150,160,170,180,190,200]:\n",
    "    n_components=7\n",
    "    print(\"n_components\",n_components)\n",
    "    print(\"alpha\",alpha)\n",
    "    models = {\n",
    "        #\"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "        #\"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "        \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components,whiten=True)), (\"ridge\", Ridge(alpha))]),\n",
    "        #\"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "    }\n",
    "\n",
    "    threshold_addition=0.002\n",
    "    threshold_removal=0.002\n",
    "    #Uncomment this to perform feature selection again\n",
    "    ff=list(Poly_feature_selection(set(X_train_Poly_log_dt[(key,key1)].columns), X_train_Poly_log_dt[(key,key1)], np.log(y_train_dt[(key,key1)]), models[\"ridge\"], threshold_addition=threshold_addition, threshold_removal=threshold_removal,dd=50,min_features=n_components))\n",
    "\n",
    "    #ff=features[(key,key1)]\n",
    "    print(\"Optimal subset of features:\")\n",
    "    print(len(ff),ff)\n",
    "\n",
    "\n",
    "    fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = log_fit(\n",
    "        X_train_Poly_log_dt[(key,key1)][ff],X_test_Poly_log_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models)\n",
    "\n",
    "    # Using pretty table\n",
    "    print_table(models_stats[(key,key1)])\n",
    "    feature_importance_PCA(fitted_models[(key,key1)],ff,(3,3), plot=False, models_to_use=['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
