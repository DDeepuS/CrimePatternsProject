{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import altair as alt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from prettytable import PrettyTable, TableStyle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, perform imputation and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(option: str = \"1985-2023\") -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    if option == \"1985-2023\":\n",
    "        df = pd.read_excel(\"../data/tentative_final_with_NaN.xlsx\")\n",
    "    if option == \"2010-2023\":\n",
    "        df = pd.read_excel(\"../data/tentative_final.xlsx\")\n",
    "    return df\n",
    "\n",
    "tentative_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>Population</th>\n",
       "      <th>clearance_rate</th>\n",
       "      <th>population_density</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>adjusted_income</th>\n",
       "      <th>poverty_rate</th>\n",
       "      <th>rent_burden</th>\n",
       "      <th>home_ownership_rate</th>\n",
       "      <th>mobile_home_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>house_affordability</th>\n",
       "      <th>uninsured_rate</th>\n",
       "      <th>high_school_rate</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>public_school_rate</th>\n",
       "      <th>social_vs_security</th>\n",
       "      <th>security_vs_social</th>\n",
       "      <th>Category_Rural</th>\n",
       "      <th>Category_Suburban</th>\n",
       "      <th>Category_Urban</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alameda</th>\n",
       "      <th>1985</th>\n",
       "      <td>0.009809</td>\n",
       "      <td>1185500</td>\n",
       "      <td>0.466890</td>\n",
       "      <td>1606.368564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>0.010353</td>\n",
       "      <td>1206900</td>\n",
       "      <td>0.445778</td>\n",
       "      <td>1635.365854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.009588</td>\n",
       "      <td>1220600</td>\n",
       "      <td>0.538580</td>\n",
       "      <td>1653.929539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.008825</td>\n",
       "      <td>1242300</td>\n",
       "      <td>0.520660</td>\n",
       "      <td>1683.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.008375</td>\n",
       "      <td>1261200</td>\n",
       "      <td>0.497018</td>\n",
       "      <td>1708.943089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              crime_rate  Population  clearance_rate  population_density  \\\n",
       "County  Year                                                               \n",
       "Alameda 1985    0.009809     1185500        0.466890         1606.368564   \n",
       "        1986    0.010353     1206900        0.445778         1635.365854   \n",
       "        1987    0.009588     1220600        0.538580         1653.929539   \n",
       "        1988    0.008825     1242300        0.520660         1683.333333   \n",
       "        1989    0.008375     1261200        0.497018         1708.943089   \n",
       "\n",
       "              unemployment_rate  adjusted_income  poverty_rate  rent_burden  \\\n",
       "County  Year                                                                  \n",
       "Alameda 1985                NaN              NaN           NaN          NaN   \n",
       "        1986                NaN              NaN           NaN          NaN   \n",
       "        1987                NaN              NaN           NaN          NaN   \n",
       "        1988                NaN              NaN           NaN          NaN   \n",
       "        1989                NaN              NaN           NaN          NaN   \n",
       "\n",
       "              home_ownership_rate  mobile_home_ratio  ...  \\\n",
       "County  Year                                          ...   \n",
       "Alameda 1985                  NaN                NaN  ...   \n",
       "        1986                  NaN                NaN  ...   \n",
       "        1987                  NaN                NaN  ...   \n",
       "        1988                  NaN                NaN  ...   \n",
       "        1989                  NaN                NaN  ...   \n",
       "\n",
       "              house_affordability  uninsured_rate  high_school_rate  \\\n",
       "County  Year                                                          \n",
       "Alameda 1985                  NaN             NaN               NaN   \n",
       "        1986                  NaN             NaN               NaN   \n",
       "        1987                  NaN             NaN               NaN   \n",
       "        1988                  NaN             NaN               NaN   \n",
       "        1989                  NaN             NaN               NaN   \n",
       "\n",
       "              dropout_rate  public_school_rate  social_vs_security  \\\n",
       "County  Year                                                         \n",
       "Alameda 1985           NaN                 NaN                 NaN   \n",
       "        1986           NaN                 NaN                 NaN   \n",
       "        1987           NaN                 NaN                 NaN   \n",
       "        1988           NaN                 NaN                 NaN   \n",
       "        1989           NaN                 NaN                 NaN   \n",
       "\n",
       "              security_vs_social  Category_Rural  Category_Suburban  \\\n",
       "County  Year                                                          \n",
       "Alameda 1985                 NaN               0                  0   \n",
       "        1986                 NaN               0                  0   \n",
       "        1987                 NaN               0                  0   \n",
       "        1988                 NaN               0                  0   \n",
       "        1989                 NaN               0                  0   \n",
       "\n",
       "              Category_Urban  \n",
       "County  Year                  \n",
       "Alameda 1985               1  \n",
       "        1986               1  \n",
       "        1987               1  \n",
       "        1988               1  \n",
       "        1989               1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tentative_df[\"social_vs_security\"]=(tentative_df['adj_education_budget']+tentative_df['adj_welfare_budget']+tentative_df['adj_health_budget'])/(tentative_df['adj_police_budget']+tentative_df['adj_judiciary_budget']+tentative_df['adj_prison_budget'])\n",
    "tentative_df[\"security_vs_social\"]=(tentative_df['adj_police_budget']+tentative_df['adj_judiciary_budget']+tentative_df['adj_prison_budget'])/(tentative_df['adj_education_budget']+tentative_df['adj_welfare_budget']+tentative_df['adj_health_budget'])\n",
    "feature_0=['Population','clearance_rate',\n",
    "       'population_density', 'unemployment_rate', 'adjusted_income',\n",
    "       'poverty_rate', 'rent_burden', 'home_ownership_rate',\n",
    "       'mobile_home_ratio', 'vacancy_rate', 'Number_of_Persons_per_HseHld',\n",
    "       'renter_ratio', 'median_age', 'adj_police_budget',\n",
    "       'adj_education_budget', 'adj_welfare_budget',\n",
    "       'adj_mental_health_budget', 'adj_rehab_budget', 'adj_health_budget',\n",
    "       'adj_judiciary_budget', 'adj_prison_budget', 'median_house_value',\n",
    "       'house_affordability', 'uninsured_rate',\n",
    "       'high_school_rate', 'dropout_rate', 'public_school_rate',\n",
    "        \"social_vs_security\", \"security_vs_social\"] #'adherent_rate', 'rdm',\n",
    "feature_cat=['Category_Rural', 'Category_Suburban', 'Category_Urban']\n",
    "crime_dataframe=tentative_df[['County', 'Year',  'crime_rate']+feature_0+feature_cat]\n",
    "crime_dataframe=crime_dataframe.set_index(['County', 'Year'])\n",
    "crime_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 2262 entries, ('Alameda', 1985) to ('Yuba', 2023)\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   crime_rate                    2262 non-null   float64\n",
      " 1   Population                    2262 non-null   int64  \n",
      " 2   clearance_rate                2262 non-null   float64\n",
      " 3   population_density            2262 non-null   float64\n",
      " 4   unemployment_rate             1914 non-null   float64\n",
      " 5   adjusted_income               928 non-null    float64\n",
      " 6   poverty_rate                  870 non-null    float64\n",
      " 7   rent_burden                   812 non-null    float64\n",
      " 8   home_ownership_rate           812 non-null    float64\n",
      " 9   mobile_home_ratio             812 non-null    float64\n",
      " 10  vacancy_rate                  812 non-null    float64\n",
      " 11  Number_of_Persons_per_HseHld  812 non-null    float64\n",
      " 12  renter_ratio                  812 non-null    float64\n",
      " 13  median_age                    812 non-null    float64\n",
      " 14  adj_police_budget             852 non-null    float64\n",
      " 15  adj_education_budget          844 non-null    float64\n",
      " 16  adj_welfare_budget            852 non-null    float64\n",
      " 17  adj_mental_health_budget      834 non-null    float64\n",
      " 18  adj_rehab_budget              779 non-null    float64\n",
      " 19  adj_health_budget             852 non-null    float64\n",
      " 20  adj_judiciary_budget          852 non-null    float64\n",
      " 21  adj_prison_budget             852 non-null    float64\n",
      " 22  median_house_value            798 non-null    float64\n",
      " 23  house_affordability           798 non-null    float64\n",
      " 24  uninsured_rate                776 non-null    float64\n",
      " 25  high_school_rate              812 non-null    float64\n",
      " 26  dropout_rate                  754 non-null    float64\n",
      " 27  public_school_rate            754 non-null    float64\n",
      " 28  social_vs_security            844 non-null    float64\n",
      " 29  security_vs_social            844 non-null    float64\n",
      " 30  Category_Rural                2262 non-null   int64  \n",
      " 31  Category_Suburban             2262 non-null   int64  \n",
      " 32  Category_Urban                2262 non-null   int64  \n",
      "dtypes: float64(29), int64(4)\n",
      "memory usage: 591.5+ KB\n"
     ]
    }
   ],
   "source": [
    "crime_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final={}\n",
    "Final[\"dropna\"]=crime_dataframe.dropna()\n",
    "Final[\"dropna\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Copy your original DataFrame and set a MultiIndex\n",
    "df = crime_dataframe.copy()\n",
    "#df = df.set_index(['County', 'Year'])\n",
    "\n",
    "def fill_missing_with_linear_regression(group):\n",
    "    \"\"\"\n",
    "    For a single county (group), fit a simple linear regression model\n",
    "    Year vs. each numeric column. Use that model to fill missing values.\n",
    "    \"\"\"\n",
    "    # Sort by Year for clarity\n",
    "    group = group.sort_index(level='Year')\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for col in group.columns:\n",
    "        # Only process numeric columns\n",
    "        if pd.api.types.is_numeric_dtype(group[col]):\n",
    "            # Extract the known data points (drop missing)\n",
    "            valid_data = group[col].dropna()\n",
    "            \n",
    "            # If there aren't at least two valid points, we can't fit a regression\n",
    "            if len(valid_data) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Prepare X (Year) and y (column values)\n",
    "            X = valid_data.index.get_level_values('Year').values.reshape(-1, 1)\n",
    "            y = valid_data.values\n",
    "            \n",
    "            # Fit the linear regression model\n",
    "            model = LinearRegression().fit(X, y)\n",
    "            \n",
    "            # Predict for all years in this county\n",
    "            X_all = group.index.get_level_values('Year').values.reshape(-1, 1)\n",
    "            y_pred = model.predict(X_all)\n",
    "            \n",
    "            # Fill only missing values with the predictions\n",
    "            missing_mask = group[col].isna()\n",
    "            group.loc[missing_mask, col] = y_pred[missing_mask]\n",
    "        else:\n",
    "            print(f\"Skipping non-numeric column: {col}\")\n",
    "    \n",
    "    return group\n",
    "\n",
    "# 2. Group by County and apply the regression-based filling\n",
    "df_reg_filled = (\n",
    "    df.groupby(level='County', group_keys=False)\n",
    "      .apply(fill_missing_with_linear_regression)\n",
    ")\n",
    "\n",
    "#df_reg_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2262, 33)\n",
      "(2108, 33)\n"
     ]
    }
   ],
   "source": [
    "final_dataframe = df_reg_filled\n",
    "#print(final_dataframe.isna().sum())\n",
    "print(final_dataframe.shape)\n",
    "final_dataframe=final_dataframe.dropna()\n",
    "print(final_dataframe.shape)\n",
    "Final[\"imputed\"]=final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.163726529166426e-06\n",
      "Average variance of crime_rate by county: 3.7796157807726586e-06\n",
      "Average variance of crime_rate by year: 5.260953083223783e-06\n"
     ]
    }
   ],
   "source": [
    "print(np.var(final_dataframe['crime_rate']))\n",
    "# Group by county and compute the variance of crime_rate for each county,\n",
    "# then compute the average variance across all counties.\n",
    "county_variances = final_dataframe.groupby(level=\"County\")[\"crime_rate\"].var()\n",
    "avg_county_variance = county_variances.mean()\n",
    "print(\"Average variance of crime_rate by county:\", avg_county_variance)\n",
    "\n",
    "# Group by year and compute the variance of crime_rate for each year,\n",
    "# then compute the average variance across all years.\n",
    "year_variances = final_dataframe.groupby(level=\"Year\")[\"crime_rate\"].var()\n",
    "avg_year_variance = year_variances.mean()\n",
    "print(\"Average variance of crime_rate by year:\", avg_year_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poly_df_function(df0):\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    Poly_data = poly.fit_transform(df0)\n",
    "    feature_names = poly.get_feature_names_out(input_features=df0.columns)\n",
    "    Poly_df = pd.DataFrame(Poly_data, columns=feature_names, index=df0.index)\n",
    "    return Poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For these dictionaries, keys are dropna/imputed, All/Urban/Suburban/Rural, and values are the corresponding DataFrames\n",
    "X_train_dt={}\n",
    "X_test_dt={}\n",
    "y_train_dt={}\n",
    "y_test_dt={}\n",
    "X_train_Poly_dt={}\n",
    "X_test_Poly_dt={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Final.keys():\n",
    "    for key1 in [\"All\", \"Urban\", \"Suburban\", \"Rural\"]:\n",
    "        if key1 == \"All\":\n",
    "            df = Final[key]\n",
    "        else:\n",
    "            df = Final[key][Final[key][\"Category_\"+key1] == 1]\n",
    "\n",
    "        # Split the data into features and target\n",
    "        X = df[feature_0]\n",
    "        y = df[\"crime_rate\"]\n",
    "        PolyX=Poly_df_function(X)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test, X_train_Poly, X_test_Poly = train_test_split(X, y, PolyX, test_size=0.15, random_state=42,shuffle=True)\n",
    "\n",
    "        # Store the results in the dictionaries\n",
    "        X_train_dt[(key,key1)] = X_train\n",
    "        X_test_dt[(key,key1)] = X_test\n",
    "        y_train_dt[(key,key1)] = y_train\n",
    "        y_test_dt[(key,key1)] = y_test\n",
    "        X_train_Poly_dt[(key,key1)] = X_train_Poly\n",
    "        X_test_Poly_dt[(key,key1)] = X_test_Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_test_split_by_county(X, y, X_poly, test_size=0.15, random_state=42):\n",
    "    # Extract unique counties from the MultiIndex (assumed to have level \"County\")\n",
    "    counties = np.array(X.index.get_level_values(\"County\").unique())\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle and split counties\n",
    "    n_counties = len(counties)\n",
    "    n_test = int(np.floor(test_size * n_counties))\n",
    "    shuffled = np.random.permutation(counties)\n",
    "    test_counties = shuffled[:n_test]\n",
    "    train_counties = shuffled[n_test:]\n",
    "    \n",
    "    # Create masks for train and test based on counties\n",
    "    train_mask = X.index.get_level_values(\"County\").isin(train_counties)\n",
    "    test_mask = X.index.get_level_values(\"County\").isin(test_counties)\n",
    "    \n",
    "    # Subset the data using the masks\n",
    "    X_train = X[train_mask]\n",
    "    X_test  = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test  = y[test_mask]\n",
    "    X_poly_train = X_poly[train_mask]\n",
    "    X_poly_test  = X_poly[test_mask]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_poly_train, X_poly_test\n",
    "\n",
    "# Now apply the function for each dataset:\n",
    "#X_train_Urban, X_test_Urban, y_train_Urban, y_test_Urban, X_train_Poly_Urban, X_test_Poly_Urban = train_test_split_by_county(\n",
    "#    X_Urban, y_Urban, X_Poly_Urban, test_size=0.15, random_state=42\n",
    "#)\n",
    "\n",
    "#X_train_Suburban, X_test_Suburban, y_train_Suburban, y_test_Suburban, X_train_Poly_Suburban, X_test_Poly_Suburban = train_test_split_by_county(\n",
    "#    X_Suburban, y_Suburban, X_Poly_Suburban, test_size=0.15, random_state=42\n",
    "#)\n",
    "\n",
    "#X_train_Rural, X_test_Rural, y_train_Rural, y_test_Rural, X_train_Poly_Rural, X_test_Poly_Rural = train_test_split_by_county(\n",
    "#    X_Rural, y_Rural, X_Poly_Rural, test_size=0.15, random_state=42\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train_Urban.index.get_level_values('County').unique())\n",
    "#print(X_test_Urban.index.get_level_values('County').unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable, TableStyle\n",
    "\n",
    "def print_table(model_stats):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Model\", \"Type\", \"MSE\", \"RMSE\", \"r2 Score\", \"MR2\"]\n",
    "    \n",
    "    for model_name, stats in model_stats.items():\n",
    "        first_row = True\n",
    "        for cv_type, metrics in stats.items():\n",
    "            if len(metrics) == 3:\n",
    "                mse, rmse, r2 = metrics\n",
    "                mr2 = \"\"\n",
    "            elif len(metrics) == 4:\n",
    "                mse, rmse, r2, mr2 = metrics\n",
    "            else:\n",
    "                mse, rmse, r2, mr2 = metrics[0], metrics[1], metrics[2], metrics[3] if len(metrics) > 3 else \"\"\n",
    "            \n",
    "            if first_row:\n",
    "                table.add_row([model_name, cv_type, mse, rmse, r2, mr2])\n",
    "                first_row = False\n",
    "            else:\n",
    "                table.add_row([\"\", cv_type, mse, rmse, r2, mr2])\n",
    "        # Divider row between models\n",
    "        table.add_row([\"\"] * 6)\n",
    "    \n",
    "    table.set_style(TableStyle.DOUBLE_BORDER)\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def deep_cross_fit1(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    **models\n",
    ") -> tuple[dict, dict, dict]:\n",
    "    \"\"\"\n",
    "    Fit models and compute performance statistics using several cross-validation schemes:\n",
    "      - Regular (KFold) CV on the training set.\n",
    "      - County-based CV using leave-one-county-out (splitting by the 'County' level of the index).\n",
    "      - Time-series CV (using data until 2018 for training and data after 2018 for validation).\n",
    "      - Test set performance (after fitting on the full training data).\n",
    "    \n",
    "    Modified R² (MR2) is defined as:\n",
    "       MR2 = 1 - (MSE on split) / (Var(y) computed on the entire X_train)\n",
    "    \n",
    "    Parameters:\n",
    "      X_train (pd.DataFrame): Training features (MultiIndex with levels \"County\" and \"Year\")\n",
    "      X_test (pd.DataFrame): Test features (MultiIndex with levels \"County\" and \"Year\")\n",
    "      y_train (pd.DataFrame or pd.Series): Training targets (indexed similarly)\n",
    "      y_test (pd.DataFrame or pd.Series): Test targets\n",
    "      models: Keyword arguments mapping model names to scikit-learn estimator instances.\n",
    "      \n",
    "    Returns:\n",
    "      tuple:\n",
    "         fitted_models: dict mapping model name to fitted model (trained on X_train)\n",
    "         model_stats: dict mapping model name to a dictionary with keys:\n",
    "             \"Reg train\", \"Reg val\", \"County train\", \"County val\", \"Time train\", \"Time val\", \"Test\"\n",
    "             For each, the value is a list: [MSE, RMSE, r2, MR2]\n",
    "         predictions: dict mapping model name to a dict with keys:\n",
    "             \"train\": predictions on X_train,\n",
    "             \"test\": predictions on X_test.\n",
    "    \"\"\"\n",
    "    fitted_models = {}\n",
    "    model_stats = {}\n",
    "    predictions = {}\n",
    "    \n",
    "    # Compute the variance of y on the entire training set (sample variance)\n",
    "    global_var = np.var(y_train, ddof=1)\n",
    "    \n",
    "    # For each model provided\n",
    "    for key, model in models.items():\n",
    "        stats = {}  # will hold our metrics for different CV schemes\n",
    "        \n",
    "        # 1. Regular KFold CV on training data\n",
    "        reg_train_mse, reg_train_rmse, reg_train_r2, reg_train_mr2 = [], [], [], []\n",
    "        reg_val_mse, reg_val_rmse, reg_val_r2, reg_val_mr2 = [], [], [], []\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_tt, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tt, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_tt, y_tt)\n",
    "            train_preds = model_clone.predict(X_tt)\n",
    "            val_preds = model_clone.predict(X_val)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_tt, train_preds)\n",
    "            reg_train_mse.append(mse_train)\n",
    "            reg_train_rmse.append(root_mean_squared_error(y_tt, train_preds))\n",
    "            reg_train_r2.append(r2_score(y_tt, train_preds))\n",
    "            reg_train_mr2.append(1 - mse_train / global_var)\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val, val_preds)\n",
    "            reg_val_mse.append(mse_val)\n",
    "            reg_val_rmse.append(root_mean_squared_error(y_val, val_preds))\n",
    "            reg_val_r2.append(r2_score(y_val, val_preds))\n",
    "            reg_val_mr2.append(1 - mse_val / global_var)\n",
    "            \n",
    "        stats[\"Reg train\"] = [np.mean(reg_train_mse), np.mean(reg_train_rmse), np.mean(reg_train_r2), np.mean(reg_train_mr2)]\n",
    "        stats[\"Reg val\"]   = [np.mean(reg_val_mse), np.mean(reg_val_rmse), np.mean(reg_val_r2), np.mean(reg_val_mr2)]\n",
    "        \n",
    "        # 2. County cross-validation using Leave-One-County-Out\n",
    "        logo = LeaveOneGroupOut()\n",
    "        groups = X_train.index.get_level_values(\"County\")\n",
    "        county_train_mse, county_train_rmse, county_train_r2, county_train_mr2 = [], [], [], []\n",
    "        county_val_mse, county_val_rmse, county_val_r2, county_val_mr2 = [], [], [], []\n",
    "        for train_idx, val_idx in logo.split(X_train, y_train, groups):\n",
    "            X_train_county = X_train.iloc[train_idx]\n",
    "            y_train_county = y_train.iloc[train_idx]\n",
    "            X_val_county   = X_train.iloc[val_idx]\n",
    "            y_val_county   = y_train.iloc[val_idx]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_county, y_train_county)\n",
    "            train_preds = model_clone.predict(X_train_county)\n",
    "            val_preds   = model_clone.predict(X_val_county)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_train_county, train_preds)\n",
    "            county_train_mse.append(mse_train)\n",
    "            county_train_rmse.append(root_mean_squared_error(y_train_county, train_preds))\n",
    "            if len(y_train_county) < 2:\n",
    "                county_train_r2.append(np.nan)\n",
    "                county_train_mr2.append(np.nan)\n",
    "            else:\n",
    "                county_train_r2.append(r2_score(y_train_county, train_preds))\n",
    "                county_train_mr2.append(1 - mse_train / global_var)\n",
    "                \n",
    "            mse_val = mean_squared_error(y_val_county, val_preds)\n",
    "            county_val_mse.append(mse_val)\n",
    "            county_val_rmse.append(root_mean_squared_error(y_val_county, val_preds))\n",
    "            if len(y_val_county) < 2:\n",
    "                county_val_r2.append(np.nan)\n",
    "                county_val_mr2.append(np.nan)\n",
    "            else:\n",
    "                county_val_r2.append(r2_score(y_val_county, val_preds))\n",
    "                county_val_mr2.append(1 - mse_val / global_var)\n",
    "                \n",
    "        stats[\"County train\"] = [\n",
    "            np.nanmean(county_train_mse), \n",
    "            np.nanmean(county_train_rmse), \n",
    "            np.nanmean(county_train_r2), \n",
    "            np.nanmean(county_train_mr2)\n",
    "        ]\n",
    "        stats[\"County val\"] = [\n",
    "            np.nanmean(county_val_mse), \n",
    "            np.nanmean(county_val_rmse), \n",
    "            np.nanmean(county_val_r2), \n",
    "            np.nanmean(county_val_mr2)\n",
    "        ]\n",
    "        \n",
    "        # 3. Time series CV using data until 2018 for training and data after 2018 for validation.\n",
    "        cutoff_year = 2018\n",
    "        train_mask = X_train.index.get_level_values(\"Year\") <= cutoff_year\n",
    "        val_mask   = X_train.index.get_level_values(\"Year\") > cutoff_year\n",
    "        if train_mask.sum() > 0 and val_mask.sum() > 0:\n",
    "            X_train_time = X_train[train_mask]\n",
    "            y_train_time = y_train[train_mask]\n",
    "            X_val_time   = X_train[val_mask]\n",
    "            y_val_time   = y_train[val_mask]\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_time, y_train_time)\n",
    "            train_preds = model_clone.predict(X_train_time)\n",
    "            val_preds   = model_clone.predict(X_val_time)\n",
    "            \n",
    "            mse_train = mean_squared_error(y_train_time, train_preds)\n",
    "            time_train_mse = mse_train\n",
    "            time_train_rmse = root_mean_squared_error(y_train_time, train_preds)\n",
    "            time_train_r2 = r2_score(y_train_time, train_preds)\n",
    "            time_train_mr2 = 1 - mse_train / global_var\n",
    "            \n",
    "            mse_val = mean_squared_error(y_val_time, val_preds)\n",
    "            time_val_mse = mse_val\n",
    "            time_val_rmse = root_mean_squared_error(y_val_time, val_preds)\n",
    "            time_val_r2 = r2_score(y_val_time, val_preds)\n",
    "            time_val_mr2 = 1 - mse_val / global_var\n",
    "            \n",
    "            stats[\"Time train\"] = [time_train_mse, time_train_rmse, time_train_r2, time_train_mr2]\n",
    "            stats[\"Time val\"]   = [time_val_mse, time_val_rmse, time_val_r2, time_val_mr2]\n",
    "        else:\n",
    "            stats[\"Time train\"] = [np.nan, np.nan, np.nan, np.nan]\n",
    "            stats[\"Time val\"]   = [np.nan, np.nan, np.nan, np.nan]\n",
    "        \n",
    "        # 4. Fit on full training set and compute test set performance.\n",
    "        model.fit(X_train, y_train)\n",
    "        fitted_models[key] = model\n",
    "        test_preds = model.predict(X_test)\n",
    "        test_mse   = mean_squared_error(y_test, test_preds)\n",
    "        test_rmse  = root_mean_squared_error(y_test, test_preds)\n",
    "        test_r2    = r2_score(y_test, test_preds)\n",
    "        test_mr2   = 1 - test_mse / global_var\n",
    "        stats[\"Test\"] = [test_mse, test_rmse, test_r2, test_mr2]\n",
    "        \n",
    "        model_stats[key] = stats\n",
    "        \n",
    "        # Also store predictions on train and test for inspection.\n",
    "        predictions[key] = {\n",
    "            \"train\": model.predict(X_train),\n",
    "            \"test\": test_preds\n",
    "        }\n",
    "        \n",
    "    return fitted_models, model_stats, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "def compute_avg_MR2(S, X, y, model):\n",
    "    \"\"\"\n",
    "    Computes the average modified R² (MR2) over leave-one-county-out splits.\n",
    "    \n",
    "    MR2 is defined as:\n",
    "         MR2 = 1 - (MSE on validation set) / (Variance of y on the entire X)\n",
    "         \n",
    "    Parameters:\n",
    "      S : set\n",
    "          Set of feature names.\n",
    "      X : pd.DataFrame\n",
    "          DataFrame with a MultiIndex (County, Year) containing features.\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "      float\n",
    "          The average MR2 over all LOCO splits.\n",
    "    \"\"\"\n",
    "    if not S:\n",
    "        return -np.inf  # if no features, MR2 is worst\n",
    "    global_var = np.var(y, ddof=1)\n",
    "    logo = LeaveOneGroupOut()\n",
    "    groups = X.index.get_level_values(\"County\")\n",
    "    mr2_scores = []\n",
    "    XX = X[list(S)]\n",
    "    for train_idx, val_idx in logo.split(X, y, groups):\n",
    "        X_tt, X_val = XX.iloc[train_idx], XX.iloc[val_idx]\n",
    "        y_tt, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_tt, y_tt)\n",
    "        y_pred = model_clone.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mr2 = 1 - mse / global_var\n",
    "        mr2_scores.append(mr2)\n",
    "    return np.mean(mr2_scores)\n",
    "\n",
    "def remove_features(S, X, y, model):\n",
    "    \"\"\"\n",
    "    Recursively removes one feature at a time from set S if doing so improves the average MR2.\n",
    "    \n",
    "    Uses DFS to search through the removal space.\n",
    "    \n",
    "    Parameters:\n",
    "      S : set\n",
    "          Current set of features.\n",
    "      X, y, model : as before.\n",
    "      \n",
    "    Returns:\n",
    "      set\n",
    "          The subset of S that yields a higher MR2.\n",
    "    \"\"\"\n",
    "    current_avg = compute_avg_MR2(S, X, y, model)\n",
    "    best = S.copy()\n",
    "    for feat in list(S):\n",
    "        new_set = S - {feat}\n",
    "        if not new_set:  # skip if empty\n",
    "            continue\n",
    "        new_avg = compute_avg_MR2(new_set, X, y, model)\n",
    "        if new_avg > current_avg:\n",
    "            candidate = remove_features(new_set, X, y, model)\n",
    "            candidate_avg = compute_avg_MR2(candidate, X, y, model)\n",
    "            if candidate_avg > current_avg:\n",
    "                best = candidate\n",
    "                current_avg = candidate_avg\n",
    "    return best\n",
    "\n",
    "def add_features(S1, S2, X, y, model):\n",
    "    \"\"\"\n",
    "    Recursively adds one feature at a time from S2 into S1 if doing so improves the average MR2.\n",
    "    \n",
    "    Uses DFS to search through the addition space.\n",
    "    \n",
    "    Parameters:\n",
    "      S1 : set\n",
    "          Current selected features.\n",
    "      S2 : set\n",
    "          Potential features to add.\n",
    "      X, y, model : as before.\n",
    "      \n",
    "    Returns:\n",
    "      set\n",
    "          The augmented feature set that yields a higher MR2.\n",
    "    \"\"\"\n",
    "    current_avg = compute_avg_MR2(S1, X, y, model)\n",
    "    best = S1.copy()\n",
    "    for feat in list(S2):\n",
    "        new_set = S1 | {feat}\n",
    "        new_avg = compute_avg_MR2(new_set, X, y, model)\n",
    "        if new_avg > current_avg:\n",
    "            remaining = S2 - {feat}\n",
    "            candidate = add_features(new_set, remaining, X, y, model)\n",
    "            candidate_avg = compute_avg_MR2(candidate, X, y, model)\n",
    "            if candidate_avg > current_avg:\n",
    "                best = candidate\n",
    "                current_avg = candidate_avg\n",
    "    return best\n",
    "\n",
    "def Feature_selection(S, X, y, model):\n",
    "    \"\"\"\n",
    "    Selects an optimal subset of features using a three-step DFS process:\n",
    "      1) Removal: Remove features from S if doing so increases MR2.\n",
    "      2) Addition: From the originally removed features, DFS to add features back if they improve MR2.\n",
    "      3) Final Removal: Run the removal process again on the augmented set.\n",
    "    \n",
    "    Parameters:\n",
    "      S : iterable\n",
    "          The initial set (or list) of feature names.\n",
    "      X : pd.DataFrame\n",
    "          Training features with a MultiIndex (County, Year).\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Training target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use for evaluation.\n",
    "    \n",
    "    Returns:\n",
    "      set\n",
    "          The final optimal subset of features.\n",
    "    \"\"\"\n",
    "    # Convert S to a set\n",
    "    S_initial = set(S)\n",
    "    # Step 1: Removal phase\n",
    "    S_removed = remove_features(S_initial, X, y, model)\n",
    "    # Determine the features that were removed\n",
    "    removed_features = S_initial - S_removed\n",
    "    # Step 2: Addition phase\n",
    "    S_added = add_features(S_removed, removed_features, X, y, model)\n",
    "    # Step 3: Final removal phase\n",
    "    #S_final = remove_features(S_added, X, y, model)\n",
    "    return S_added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def PCA_feature_selection(S, X, y, model, max_components=10):\n",
    "    \"\"\"\n",
    "    Finds the optimal number of PCA components and optimal feature subset.\n",
    "    \n",
    "    For each n_components (starting at 1), it creates a pipeline:\n",
    "         Pipeline([(\"scale\", StandardScaler()), (\"pca\", PCA(n_components=n_components)), (\"mod\", model)])\n",
    "    Then it calls Feature_selection(S, X, y, model_pipe) to select the best features\n",
    "    and computes the average MR2 using leave-one-county-out CV (via compute_avg_MR2).\n",
    "    \n",
    "    It increases n_components by 1 until the average MR2 decreases; then, the previous\n",
    "    setting is returned.\n",
    "    \n",
    "    Parameters:\n",
    "      S : iterable\n",
    "          The initial set of feature names.\n",
    "      X : pd.DataFrame\n",
    "          Training features with a MultiIndex (County, Year).\n",
    "      y : pd.Series or pd.DataFrame\n",
    "          Training target values.\n",
    "      model : scikit-learn estimator\n",
    "          The model to use (e.g., LinearRegression()).\n",
    "      max_components : int, optional\n",
    "          Maximum number of PCA components to try (default is 10).\n",
    "    \n",
    "    Returns:\n",
    "      tuple: (best_n_components, best_feature_subset, best_avg_MR2)\n",
    "    \"\"\"\n",
    "    best_mr2 = -np.inf\n",
    "    best_n = None\n",
    "    best_features = None\n",
    "    \n",
    "    # Loop over increasing PCA dimensions.\n",
    "    for n in range(1, max_components + 1):\n",
    "        # Create a pipeline with n_components in the PCA step.\n",
    "        model_pipe = Pipeline([\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=n)),\n",
    "            (\"mod\", model)\n",
    "        ])\n",
    "        \n",
    "        # Run DFS-based feature selection with the current pipeline.\n",
    "        selected_features = Feature_selection(S, X, y, model_pipe)\n",
    "        # Compute average MR2 using leave-one-county-out CV.\n",
    "        avg_mr2 = compute_avg_MR2(selected_features, X, y, model_pipe)\n",
    "        print(f\"n_components = {n}, selected features = {selected_features}, MR2 = {avg_mr2}\")\n",
    "        \n",
    "        # If MR2 improves, update best values; if it drops, stop and return the previous best.\n",
    "        if avg_mr2 > best_mr2:\n",
    "            best_mr2 = avg_mr2\n",
    "            best_n = n\n",
    "            best_features = selected_features\n",
    "        else:\n",
    "            # MR2 has decreased; we assume the previous configuration was optimal.\n",
    "            break\n",
    "            \n",
    "    return best_n, best_features#, best_mr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poly_feature_selection(S, X, y, model):\n",
    "    ll = list(S)\n",
    "    N = len(ll)\n",
    "    S0 = set(feature_0)\n",
    "    # Iterate backward in steps of 10\n",
    "    dd=25\n",
    "    for i in range(0, N, dd):\n",
    "        S0 = S0.union(set(ll[i:i+dd]))\n",
    "        S1 = remove_features(S0, X, y, model)\n",
    "        S0 = S1\n",
    "    S0=S0.union(set(feature_0))\n",
    "    S1=remove_features(S0, X, y, model)\n",
    "    S0=S1\n",
    "    return S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(fitted_models,features,size):\n",
    "    coeffs_mlr = fitted_models[\"mlr\"].named_steps[\"Lin\"].coef_\n",
    "    sorted_indices_mlr = np.argsort(coeffs_mlr)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_mlr], coeffs_mlr[sorted_indices_mlr])\n",
    "    plt.title(\"Linear Regression Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(coeffs_mlr[i]),features[i]) for i in sorted_indices_mlr]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in mlr is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])\n",
    "\n",
    "    coeffs_ridge = fitted_models[\"ridge\"].named_steps['ridge'].coef_\n",
    "    sorted_indices_ridge = np.argsort(coeffs_ridge)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_ridge], coeffs_ridge[sorted_indices_ridge])\n",
    "    plt.title(\"Ridge Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(coeffs_ridge[i]),features[i]) for i in sorted_indices_ridge]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in ridge is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])\n",
    "\n",
    "    importance_xgb = fitted_models[\"xgb\"].feature_importances_\n",
    "    sorted_indices_xgb = np.argsort(importance_xgb)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_xgb], importance_xgb[sorted_indices_xgb])\n",
    "    plt.title(\"XGB Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(importance_xgb[i]),features[i]) for i in sorted_indices_xgb]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in xgb is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])\n",
    "\n",
    "\n",
    "    importance_randomforest = fitted_models[\"random_forest\"].named_steps[\"randomforest\"].feature_importances_\n",
    "    sorted_indices_randomforest = np.argsort(importance_randomforest)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.barh([features[i] for i in sorted_indices_randomforest], importance_randomforest[sorted_indices_randomforest])\n",
    "    plt.title(\"RandomForest Coefficient Infulence\")\n",
    "    plt.xlabel(\"Coefficients\")\n",
    "    plt.show()\n",
    "\n",
    "    ll=[(abs(importance_randomforest[i]),features[i]) for i in sorted_indices_randomforest]\n",
    "    ll.sort(reverse=True)\n",
    "    print('The top 4 important features in randomforest is')\n",
    "    for xx in ll[:4]:\n",
    "        print(xx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_PCA(fitted_models, features, size, plot=True, models_to_use=None):\n",
    "    \"\"\"\n",
    "    Compute and optionally plot feature importances (or effective coefficients) for different models.\n",
    "    \n",
    "    Parameters:\n",
    "      fitted_models (dict): Dictionary containing fitted models.\n",
    "      features (list): List of original feature names.\n",
    "      size (tuple): Figure size for the plots.\n",
    "      plot (bool): If True, plot the bar charts; if False, only print the top features.\n",
    "      models_to_use (iterable): List or set of model names to consider. \n",
    "                                Defaults to all [\"mlr\", \"ridge\", \"xgb\", \"random_forest\"].\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if models_to_use is None:\n",
    "        models_to_use = {\"mlr\", \"ridge\", \"xgb\", \"random_forest\"}\n",
    "    else:\n",
    "        models_to_use = set(models_to_use)\n",
    "        \n",
    "    # For MLR (Linear Regression) with PCA\n",
    "    if \"mlr\" in models_to_use:\n",
    "        scaler_mlr = fitted_models[\"mlr\"].named_steps[\"scale\"]\n",
    "        pca_mlr = fitted_models[\"mlr\"].named_steps[\"pca\"]\n",
    "        lin_mlr = fitted_models[\"mlr\"].named_steps[\"Lin\"]\n",
    "        # Back-transform coefficients: effective_coef = (PCA.components_.T @ coef) / scaler.scale_\n",
    "        eff_coef_mlr = (pca_mlr.components_.T.dot(lin_mlr.coef_)) / scaler_mlr.scale_\n",
    "        sorted_indices_mlr = np.argsort(eff_coef_mlr)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_mlr], eff_coef_mlr[sorted_indices_mlr])\n",
    "            plt.title(\"MLR Effective Coefficients (Original Features)\")\n",
    "            plt.xlabel(\"Coefficient\")\n",
    "            plt.show()\n",
    "        ll = [(abs(eff_coef_mlr[i]), features[i]) for i in sorted_indices_mlr]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in mlr are:\")\n",
    "        for importance, feat in ll[:4]:\n",
    "            print(feat)\n",
    "    \n",
    "    # For Ridge Regression with PCA\n",
    "    if \"ridge\" in models_to_use:\n",
    "        scaler_ridge = fitted_models[\"ridge\"].named_steps[\"scale\"]\n",
    "        pca_ridge = fitted_models[\"ridge\"].named_steps[\"pca\"]\n",
    "        ridge_model = fitted_models[\"ridge\"].named_steps[\"ridge\"]\n",
    "        eff_coef_ridge = (pca_ridge.components_.T.dot(ridge_model.coef_)) / scaler_ridge.scale_\n",
    "        sorted_indices_ridge = np.argsort(eff_coef_ridge)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_ridge], eff_coef_ridge[sorted_indices_ridge])\n",
    "            plt.title(\"Ridge Effective Coefficients (Original Features)\")\n",
    "            plt.xlabel(\"Coefficient\")\n",
    "            plt.show()\n",
    "        ll = [(abs(eff_coef_ridge[i]), features[i]) for i in sorted_indices_ridge]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in ridge are:\")\n",
    "        for importance, feat in ll[:4]:\n",
    "            print(feat)\n",
    "    \n",
    "    # For XGB (assumed to be trained on original features)\n",
    "    if \"xgb\" in models_to_use:\n",
    "        importance_xgb = fitted_models[\"xgb\"].feature_importances_\n",
    "        sorted_indices_xgb = np.argsort(importance_xgb)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_xgb], importance_xgb[sorted_indices_xgb])\n",
    "            plt.title(\"XGB Feature Importance\")\n",
    "            plt.xlabel(\"Importance\")\n",
    "            plt.show()\n",
    "        ll = [(importance_xgb[i], features[i]) for i in sorted_indices_xgb]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in xgb are:\")\n",
    "        for imp, feat in ll[:4]:\n",
    "            print(feat)\n",
    "    \n",
    "    # For RandomForest with PCA in a pipeline:\n",
    "    if \"random_forest\" in models_to_use:\n",
    "        scaler_rf = fitted_models[\"random_forest\"].named_steps[\"scale\"]\n",
    "        pca_rf = fitted_models[\"random_forest\"].named_steps[\"pca\"]\n",
    "        rf_model = fitted_models[\"random_forest\"].named_steps[\"randomforest\"]\n",
    "        # Heuristic: effective importance = abs(PCA.components_.T) dot tree_importances\n",
    "        eff_importance_rf = np.abs(pca_rf.components_.T).dot(rf_model.feature_importances_)\n",
    "        sorted_indices_rf = np.argsort(eff_importance_rf)\n",
    "        if plot:\n",
    "            plt.figure(figsize=size)\n",
    "            plt.barh([features[i] for i in sorted_indices_rf], eff_importance_rf[sorted_indices_rf])\n",
    "            plt.title(\"RandomForest Effective Feature Importance (Original Features)\")\n",
    "            plt.xlabel(\"Importance\")\n",
    "            plt.show()\n",
    "        ll = [(eff_importance_rf[i], features[i]) for i in sorted_indices_rf]\n",
    "        ll.sort(reverse=True)\n",
    "        print(\"The top 4 important features in random forest are:\")\n",
    "        for imp, feat in ll[:4]:\n",
    "            print(feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models={}\n",
    "models_stats={}\n",
    "models_pred={}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features={}\n",
    "\n",
    "#Load selected features:\n",
    "features = joblib.load(\"features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Urban model\n",
      "Optimal subset of features:\n",
      "13 ['adj_police_budget', 'unemployment_rate', 'adj_prison_budget', 'adj_health_budget', 'unemployment_rate vacancy_rate', 'home_ownership_rate', 'dropout_rate', 'Population uninsured_rate', 'adj_judiciary_budget', 'house_affordability', 'clearance_rate median_age', 'home_ownership_rate^2', 'adj_welfare_budget']\n",
      "╔═══════════════╦══════════════╦════════════════════════╦════════════════════════╦══════════════════════╦═════════════════════╗\n",
      "║     Model     ║     Type     ║          MSE           ║          RMSE          ║       r2 Score       ║         MR2         ║\n",
      "╠═══════════════╬══════════════╬════════════════════════╬════════════════════════╬══════════════════════╬═════════════════════╣\n",
      "║      mlr      ║  Reg train   ║ 3.1695718753353804e-06 ║ 0.0017801447172775258  ║  0.6221161718603111  ║  0.6234996902376992 ║\n",
      "║               ║   Reg val    ║ 3.257858438638596e-06  ║  0.001802303835354169  ║  0.6002837039232641  ║  0.6130124952035143 ║\n",
      "║               ║ County train ║ 3.244423213799157e-06  ║ 0.0017992293943326781  ║  0.6117989616286524  ║  0.6146084098925413 ║\n",
      "║               ║  County val  ║ 3.322176525124884e-06  ║ 0.0017343614251487478  ║ -0.09177211469241074 ║  0.6053724162156088 ║\n",
      "║               ║  Time train  ║ 4.367159519423994e-06  ║ 0.0020897749925348407  ║ 0.49997666742348623  ║  0.4812432162717454 ║\n",
      "║               ║   Time val   ║ 3.4427767904810857e-06 ║ 0.0018554721206423678  ║ 0.14226605550293914  ║  0.5910468104082878 ║\n",
      "║               ║     Test     ║ 3.584175336523522e-06  ║ 0.0018931918382782877  ║  0.6076021757166513  ║  0.5742506630171569 ║\n",
      "║               ║              ║                        ║                        ║                      ║                     ║\n",
      "║      xgb      ║  Reg train   ║ 2.6799596891851665e-07 ║ 0.0005175326489531033  ║  0.9680392229628447  ║  0.9681658693093391 ║\n",
      "║               ║   Reg val    ║ 1.0469723097872213e-06 ║  0.001012169466021666  ║  0.8756675009927566  ║  0.8756344975121502 ║\n",
      "║               ║ County train ║ 2.7664549826119956e-07 ║ 0.0005256764938574231  ║  0.9668319943498347  ║  0.967138427558559  ║\n",
      "║               ║  County val  ║ 6.572767249840417e-06  ║  0.002105059789211075  ║  -0.494771205321604  ║ 0.21924821304184045 ║\n",
      "║               ║  Time train  ║ 2.4348807683335503e-07 ║ 0.0004934451102537698  ║  0.9721215313799852  ║  0.9710770602602331 ║\n",
      "║               ║   Time val   ║ 1.8962879662274331e-06 ║ 0.0013770577207319354  ║  0.5275585214610208  ║  0.7747478098733424 ║\n",
      "║               ║     Test     ║ 9.044953492902887e-07  ║ 0.0009510496040114252  ║  0.9009752666061884  ║  0.8925587452878567 ║\n",
      "║               ║              ║                        ║                        ║                      ║                     ║\n",
      "║     ridge     ║  Reg train   ║ 3.1695889399866955e-06 ║ 0.0017801495130734372  ║  0.6221141371696435  ║  0.623497663198478  ║\n",
      "║               ║   Reg val    ║ 3.2577731533645607e-06 ║ 0.0018022705746014503  ║  0.6003210531741953  ║  0.6130226258878323 ║\n",
      "║               ║ County train ║ 3.244435208074196e-06  ║ 0.0017992327340792154  ║  0.6117975372206285  ║  0.6146069851423085 ║\n",
      "║               ║  County val  ║ 3.3231604206855933e-06 ║ 0.0017345912569697243  ║ -0.0920476677628854  ║  0.6052555433387817 ║\n",
      "║               ║  Time train  ║ 4.367170175784149e-06  ║  0.002089777542176236  ║  0.4999754473103454  ║  0.4812419504468778 ║\n",
      "║               ║   Time val   ║ 3.4402622201373914e-06 ║ 0.0018547943875635896  ║ 0.14289253594906481  ║  0.5913455058001441 ║\n",
      "║               ║     Test     ║ 3.5835128075918597e-06 ║ 0.0018930168534885947  ║  0.6076747098108012  ║  0.5743293620837212 ║\n",
      "║               ║              ║                        ║                        ║                      ║                     ║\n",
      "║ random_forest ║  Reg train   ║ 1.3952572033385768e-07 ║ 0.00037317525795925135 ║  0.9833760689325745  ║  0.983426317814627  ║\n",
      "║               ║   Reg val    ║ 8.583767170607144e-07  ║  0.000917719174731333  ║  0.8975973659691234  ║  0.8980369865151238 ║\n",
      "║               ║ County train ║ 1.2065811553738614e-07 ║  0.000346972462022852  ║  0.9855157024544502  ║  0.9856675224093616 ║\n",
      "║               ║  County val  ║ 5.764011421683387e-06  ║  0.002095851139527414  ║ -0.6458267690411756  ║ 0.31531696674093995 ║\n",
      "║               ║  Time train  ║ 1.1494445372621228e-07 ║ 0.0003390345907517584  ║  0.986839292552119   ║  0.9863462246210151 ║\n",
      "║               ║   Time val   ║  2.92594783067806e-06  ║ 0.0017105402160364602  ║ 0.27102890284983794  ║  0.6524387810318841 ║\n",
      "║               ║     Test     ║ 1.2439366829615752e-06 ║  0.001115319094681686  ║  0.8638130107736808  ║  0.8522379157563147 ║\n",
      "║               ║              ║                        ║                        ║                      ║                     ║\n",
      "╚═══════════════╩══════════════╩════════════════════════╩════════════════════════╩══════════════════════╩═════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Urban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "models = {\n",
    "    \"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    \"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge())]),\n",
    "    \"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "#Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"mlr\"]))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Suburban model\n",
      "Optimal subset of features:\n",
      "25 ['rent_burden', 'adjusted_income', 'population_density uninsured_rate', 'adjusted_income public_school_rate', 'Population adj_welfare_budget', 'renter_ratio', 'rent_burden house_affordability', 'adj_rehab_budget', 'adjusted_income^2', 'median_age security_vs_social', 'unemployment_rate mobile_home_ratio', 'adj_health_budget', 'rent_burden^2', 'public_school_rate', 'adj_welfare_budget', 'mobile_home_ratio renter_ratio', 'unemployment_rate dropout_rate', 'house_affordability', 'clearance_rate adj_judiciary_budget', 'Population renter_ratio', 'adj_judiciary_budget', 'mobile_home_ratio social_vs_security', 'high_school_rate', 'adj_education_budget uninsured_rate', 'uninsured_rate security_vs_social']\n",
      "╔═══════════════╦══════════════╦════════════════════════╦════════════════════════╦═════════════════════╦══════════════════════╗\n",
      "║     Model     ║     Type     ║          MSE           ║          RMSE          ║       r2 Score      ║         MR2          ║\n",
      "╠═══════════════╬══════════════╬════════════════════════╬════════════════════════╬═════════════════════╬══════════════════════╣\n",
      "║      mlr      ║  Reg train   ║ 1.6243217006840433e-06 ║  0.001274308032783939  ║  0.4856933060013692 ║  0.4867705946431352  ║\n",
      "║               ║   Reg val    ║ 1.668838315391737e-06  ║ 0.0012891097405069577  ║  0.4685588852124125 ║  0.4727048860551696  ║\n",
      "║               ║ County train ║ 1.6378358408582741e-06 ║ 0.0012796214408858867  ║ 0.48017336811740124 ║  0.4825005943577181  ║\n",
      "║               ║  County val  ║ 1.8536826727889616e-06 ║  0.00130625388660621   ║ -0.3567062138569068 ║  0.4143004704824427  ║\n",
      "║               ║  Time train  ║  1.6012465231543e-06   ║ 0.0012654036996762338  ║ 0.49543181885727006 ║ 0.49406155162358234  ║\n",
      "║               ║   Time val   ║ 1.9888149815727717e-06 ║ 0.0014102535167737648  ║ 0.20207633742276687 ║  0.3716033406882594  ║\n",
      "║               ║     Test     ║ 1.4243033432927204e-06 ║ 0.0011934418055744153  ║  0.5343065542676944 ║  0.5499694687215734  ║\n",
      "║               ║              ║                        ║                        ║                     ║                      ║\n",
      "║      xgb      ║  Reg train   ║ 2.8060947492407665e-07 ║  0.00052956008174326   ║  0.9111577216136532 ║  0.9113371237408595  ║\n",
      "║               ║   Reg val    ║ 9.077347274543852e-07  ║  0.000950319627852118  ║  0.7089824105126961 ║  0.7131872619832651  ║\n",
      "║               ║ County train ║ 2.9093322978331943e-07 ║ 0.0005392941180159771  ║  0.9076459858733699 ║  0.9080751747284024  ║\n",
      "║               ║  County val  ║ 3.077388518699956e-06  ║ 0.0016218267629046176  ║  -1.137899810041344 ║ 0.027651801463162515 ║\n",
      "║               ║  Time train  ║  2.82977670102513e-07  ║ 0.0005319564550811588  ║  0.9108310143110464 ║  0.9105888560776952  ║\n",
      "║               ║   Time val   ║ 1.904027491250232e-06  ║ 0.0013798650264610058  ║ 0.23609355141488553 ║  0.3983932513454972  ║\n",
      "║               ║     Test     ║ 5.951446135627546e-07  ║ 0.0007714561643818491  ║  0.8054101697477374 ║  0.8119549126312092  ║\n",
      "║               ║              ║                        ║                        ║                     ║                      ║\n",
      "║     ridge     ║  Reg train   ║ 1.6243223047009952e-06 ║ 0.0012743082696517888  ║ 0.48569311504613866 ║  0.4867704037946961  ║\n",
      "║               ║   Reg val    ║ 1.6688074293216016e-06 ║ 0.0012890965530635602  ║ 0.46857466976101236 ║ 0.47271464498371357  ║\n",
      "║               ║ County train ║ 1.6378362515020791e-06 ║ 0.0012796216013592448  ║  0.4801732379468775 ║  0.4825004646084969  ║\n",
      "║               ║  County val  ║ 1.8538545267364356e-06 ║ 0.0013063248372792609  ║ -0.3567413223639993 ║  0.4142461705865334  ║\n",
      "║               ║  Time train  ║ 1.6012471302374321e-06 ║  0.001265403939553466  ║ 0.49543162755953596 ║  0.4940613598063366  ║\n",
      "║               ║   Time val   ║ 1.9875904379806187e-06 ║ 0.0014098192926686097  ║ 0.20256763114143317 ║  0.3719902540560791  ║\n",
      "║               ║     Test     ║ 1.4243643278639664e-06 ║ 0.0011934673551731384  ║  0.5342866146142113 ║  0.5499501997090228  ║\n",
      "║               ║              ║                        ║                        ║                     ║                      ║\n",
      "║ random_forest ║  Reg train   ║ 1.1753573490274798e-07 ║ 0.0003427171072619249  ║  0.9627994289645635 ║  0.9628627781633922  ║\n",
      "║               ║   Reg val    ║ 9.074597055845319e-07  ║ 0.0009482252307133054  ║  0.7113675553764377 ║  0.7132741593698267  ║\n",
      "║               ║ County train ║ 1.1082967157760895e-07 ║ 0.00033269033722321015 ║  0.9648183767413329 ║  0.9649816619357369  ║\n",
      "║               ║  County val  ║ 2.349092162503903e-06  ║ 0.0014666005474306867  ║ -0.9706161081453817 ║ 0.25776822831177393  ║\n",
      "║               ║  Time train  ║ 1.0035381165310506e-07 ║ 0.00031678669740553355 ║  0.9683775486882553 ║  0.9682916708812497  ║\n",
      "║               ║   Time val   ║ 2.0778633824090174e-06 ║ 0.0014414795809892756  ║ 0.16634962236870332 ║  0.3434671298687403  ║\n",
      "║               ║     Test     ║ 4.177240715915769e-07  ║ 0.0006463157677107815  ║  0.863419991829065  ║  0.8680136596242548  ║\n",
      "║               ║              ║                        ║                        ║                     ║                      ║\n",
      "╚═══════════════╩══════════════╩════════════════════════╩════════════════════════╩═════════════════════╩══════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "models = {\n",
    "    \"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    \"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge())]),\n",
    "    \"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"mlr\"]))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed Rural model\n",
      "Optimal subset of features:\n",
      "28 ['adj_education_budget', 'poverty_rate Number_of_Persons_per_HseHld', 'adj_welfare_budget adj_rehab_budget', 'median_age', 'home_ownership_rate', 'median_house_value', 'vacancy_rate', 'unemployment_rate median_house_value', 'mobile_home_ratio^2', 'vacancy_rate adj_welfare_budget', 'poverty_rate adj_rehab_budget', 'clearance_rate', 'median_age adj_rehab_budget', 'uninsured_rate', 'vacancy_rate house_affordability', 'adj_mental_health_budget^2', 'adj_health_budget', 'unemployment_rate uninsured_rate', 'adj_police_budget adj_mental_health_budget', 'unemployment_rate dropout_rate', 'mobile_home_ratio renter_ratio', 'adj_judiciary_budget', 'Number_of_Persons_per_HseHld', 'house_affordability', 'adj_judiciary_budget uninsured_rate', 'mobile_home_ratio social_vs_security', 'high_school_rate', 'adj_education_budget uninsured_rate']\n",
      "╔═══════════════╦══════════════╦════════════════════════╦═══════════════════════╦═══════════════════════╦════════════════════════╗\n",
      "║     Model     ║     Type     ║          MSE           ║          RMSE         ║        r2 Score       ║          MR2           ║\n",
      "╠═══════════════╬══════════════╬════════════════════════╬═══════════════════════╬═══════════════════════╬════════════════════════╣\n",
      "║      mlr      ║  Reg train   ║ 5.196797904303844e-06  ║ 0.0022789127852587123 ║  0.23288770618005109  ║  0.23468382901411902   ║\n",
      "║               ║   Reg val    ║ 5.4271000555968406e-06 ║  0.002318667797428377 ║  0.18817549248113827  ║   0.2007679516136532   ║\n",
      "║               ║ County train ║  5.21039660042721e-06  ║ 0.0022816526791021325 ║   0.2306856651989121  ║  0.23268119157483827   ║\n",
      "║               ║  County val  ║ 5.263804950548146e-06  ║ 0.0020152509379882107 ║  -0.27419604965310707 ║   0.1801185691158115   ║\n",
      "║               ║  Time train  ║ 5.256307167084685e-06  ║  0.002292663771049886 ║  0.23485364623144378  ║  0.22592008603848635   ║\n",
      "║               ║   Time val   ║ 6.197337171099391e-06  ║ 0.0024894451532619455 ║  -0.01211480604195514 ║  0.08733754103343139   ║\n",
      "║               ║     Test     ║ 3.4179821566977758e-06 ║ 0.0018487785580479279 ║   0.2161504408767856  ║   0.4966444597555658   ║\n",
      "║               ║              ║                        ║                       ║                       ║                        ║\n",
      "║      xgb      ║  Reg train   ║ 5.266097985946202e-07  ║  0.000725042655165253 ║   0.9219479619027586  ║   0.9224478222771934   ║\n",
      "║               ║   Reg val    ║ 2.7767197650227463e-06 ║  0.00165644383554146  ║   0.5813053766383747  ║   0.5910811662104274   ║\n",
      "║               ║ County train ║ 5.366119738711406e-07  ║ 0.0007322911883750693 ║   0.9205384374443276  ║   0.9209748332125588   ║\n",
      "║               ║  County val  ║  6.49135229745884e-06  ║ 0.0022160822823196424 ║  -0.5018312964406234  ║ -9.248157105234966e-06 ║\n",
      "║               ║  Time train  ║ 5.410678591597914e-07  ║ 0.0007355731501079898 ║   0.9212382217367467  ║   0.9203186289247917   ║\n",
      "║               ║   Time val   ║ 3.362085328851906e-06  ║ 0.0018335990098306406 ║   0.4509228324100044  ║   0.5048762107385759   ║\n",
      "║               ║     Test     ║ 1.7047445061541607e-06 ║ 0.0013056586484047662 ║   0.6090490914505919  ║   0.7489476092809713   ║\n",
      "║               ║              ║                        ║                       ║                       ║                        ║\n",
      "║     ridge     ║  Reg train   ║ 5.196798182347798e-06  ║ 0.0022789128462442905 ║  0.23288766515786383  ║   0.2346837880674558   ║\n",
      "║               ║   Reg val    ║  5.42692174902246e-06  ║  0.002318626127424919 ║  0.18821233651363378  ║  0.20079421026509198   ║\n",
      "║               ║ County train ║ 5.210396787489342e-06  ║ 0.0022816527200411234 ║   0.2306856376926797  ║   0.2326811640267832   ║\n",
      "║               ║  County val  ║ 5.264020467881554e-06  ║ 0.0020152980555211493 ║  -0.2742448130961995  ║  0.18009072376383017   ║\n",
      "║               ║  Time train  ║ 5.256307348573215e-06  ║  0.002292663810630162 ║  0.23485361981265152  ║  0.22592005931123826   ║\n",
      "║               ║   Time val   ║ 6.196960676922328e-06  ║ 0.0024893695340230883 ║ -0.012053319096760218 ║  0.08739298615315594   ║\n",
      "║               ║     Test     ║ 3.4180374305985797e-06 ║ 0.0018487935067493556 ║  0.21613776485309977  ║   0.4966363197410997   ║\n",
      "║               ║              ║                        ║                       ║                       ║                        ║\n",
      "║ random_forest ║  Reg train   ║  4.57753803057069e-07  ║ 0.0006761293395664361 ║   0.9324733228704787  ║   0.9325880293478932   ║\n",
      "║               ║   Reg val    ║ 3.109614885747635e-06  ║  0.001747731428453601 ║   0.542231716944627   ║   0.5420567431282712   ║\n",
      "║               ║ County train ║ 4.110535179146007e-07  ║ 0.0006402860863412645 ║   0.9394340164630341  ║   0.9394654342551695   ║\n",
      "║               ║  County val  ║ 6.293042776232608e-06  ║  0.002133199524422284 ║  -0.5217493748897585  ║  0.001945989108246134  ║\n",
      "║               ║  Time train  ║ 3.9918832069483596e-07 ║ 0.0006318135173410236 ║   0.9418912406871283  ║   0.9412127847335674   ║\n",
      "║               ║   Time val   ║ 3.873776345506921e-06  ║ 0.0019681911354101056 ║   0.3673562876542461  ║   0.4295210753637767   ║\n",
      "║               ║     Test     ║ 1.5776448602119099e-06 ║ 0.0012560433353240284 ║   0.6381969912549615  ║   0.7676651765516991   ║\n",
      "║               ║              ║                        ║                       ║                       ║                        ║\n",
      "╚═══════════════╩══════════════╩════════════════════════╩═══════════════════════╩═══════════════════════╩════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"imputed\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "models = {\n",
    "    \"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    \"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge())]),\n",
    "    \"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"mlr\"]))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Urban model\n",
      "Optimal subset of features:\n",
      "16 ['Population', 'adjusted_income', 'adjusted_income public_school_rate', 'adj_mental_health_budget public_school_rate', 'mobile_home_ratio', 'clearance_rate', 'adjusted_income^2', 'dropout_rate public_school_rate', 'public_school_rate', 'adjusted_income home_ownership_rate', 'uninsured_rate^2', 'adj_judiciary_budget', 'adj_mental_health_budget', 'Population mobile_home_ratio', 'high_school_rate', 'adj_welfare_budget']\n",
      "╔═══════════════╦══════════════╦════════════════════════╦════════════════════════╦═════════════════════╦═════════════════════╗\n",
      "║     Model     ║     Type     ║          MSE           ║          RMSE          ║       r2 Score      ║         MR2         ║\n",
      "╠═══════════════╬══════════════╬════════════════════════╬════════════════════════╬═════════════════════╬═════════════════════╣\n",
      "║      mlr      ║  Reg train   ║ 3.643181985849938e-07  ║ 0.0006033870706262298  ║  0.8919727752446152 ║  0.8929567762803625 ║\n",
      "║               ║   Reg val    ║ 3.9258907003494414e-07 ║ 0.0006248214238175714  ║  0.8819064549412481 ║  0.8846502869830399 ║\n",
      "║               ║ County train ║ 3.6507054939509747e-07 ║ 0.0006034251948857538  ║  0.8905440708870019 ║  0.8927357221128948 ║\n",
      "║               ║  County val  ║ 5.538245262712858e-07  ║ 0.0006682801064933068  ║  -5.973353213444057 ║  0.8372764168868468 ║\n",
      "║               ║  Time train  ║ 3.6129121436881025e-07 ║ 0.0006010750488656223  ║  0.8996022478962875 ║  0.8938461585563708 ║\n",
      "║               ║   Time val   ║  3.69497156247623e-07  ║ 0.0006078627774815817  ║  0.8634073881073692 ║  0.8914351055928468 ║\n",
      "║               ║     Test     ║ 1.812352061336591e-06  ║ 0.0013462362576221868  ║  0.6195310756308534 ║ 0.46749844527698103 ║\n",
      "║               ║              ║                        ║                        ║                     ║                     ║\n",
      "║      xgb      ║  Reg train   ║ 9.172157793068396e-08  ║ 0.00030276445731132836 ║  0.9728077011846279 ║  0.9730505546401854 ║\n",
      "║               ║   Reg val    ║ 4.744279624633619e-07  ║ 0.0006799741299303187  ║  0.8566331698602884 ║  0.8606045519491949 ║\n",
      "║               ║ County train ║ 8.972787614183925e-08  ║ 0.0002991715633527349  ║  0.9726226830200047 ║  0.9736363399988155 ║\n",
      "║               ║  County val  ║ 2.3655100217860947e-06 ║ 0.0013621067263528022  ║ -29.634395761605468 ║ 0.30497071116248353 ║\n",
      "║               ║  Time train  ║ 7.959766236352746e-08  ║  0.000282130576796503  ║  0.9778809280265235 ║  0.9766127785736965 ║\n",
      "║               ║   Time val   ║ 5.334861676972806e-07  ║ 0.0007304013743807445  ║  0.8027853047791071 ║  0.8432521915678352 ║\n",
      "║               ║     Test     ║ 1.9099472939442017e-06 ║  0.001382008427595216  ║  0.5990428084967129 ║  0.438823214781875  ║\n",
      "║               ║              ║                        ║                        ║                     ║                     ║\n",
      "║     ridge     ║  Reg train   ║ 3.643721969768215e-07  ║ 0.0006034318028508413  ║  0.8919567596949672 ║  0.8929409105839483 ║\n",
      "║               ║   Reg val    ║ 3.928279094023756e-07  ║ 0.0006249935089964684  ║  0.881843722041082  ║  0.8845801116913845 ║\n",
      "║               ║ County train ║ 3.651103677857398e-07  ║ 0.0006034582915451247  ║  0.8905320406451808 ║  0.8927240227552613 ║\n",
      "║               ║  County val  ║ 5.550438103882583e-07  ║ 0.0006679292643507573  ║  -5.949767910554892 ║  0.8369181693356188 ║\n",
      "║               ║  Time train  ║ 3.6135479183265245e-07 ║ 0.0006011279329998337  ║  0.8995845806123892 ║  0.8938274783567212 ║\n",
      "║               ║   Time val   ║ 3.6703958991138387e-07 ║ 0.0006058379237975978  ║  0.864315880633199  ║  0.8921571826786405 ║\n",
      "║               ║     Test     ║ 1.8134193139918128e-06 ║ 0.0013466325831464991  ║  0.6193070261879086 ║  0.4671848672971217 ║\n",
      "║               ║              ║                        ║                        ║                     ║                     ║\n",
      "║ random_forest ║  Reg train   ║ 5.6272889540782585e-08 ║ 0.00023691637983542946 ║  0.9833130071517955 ║  0.9834660153463096 ║\n",
      "║               ║   Reg val    ║ 3.722636418954524e-07  ║ 0.0006070935500802875  ║  0.8871776064813535 ║  0.8906222624703567 ║\n",
      "║               ║ County train ║ 4.5208260373143914e-08 ║ 0.00021231789769670685 ║  0.9863717137945568 ║  0.9867170019288258 ║\n",
      "║               ║  County val  ║ 1.9443704554156908e-06 ║  0.001276127633017023  ║ -18.769435137606457 ║ 0.42870907228544913 ║\n",
      "║               ║  Time train  ║ 4.606834961497015e-08  ║  0.000214635387611107  ║  0.987198252931361  ║  0.9864642922769633 ║\n",
      "║               ║   Time val   ║ 6.738721054795641e-07  ║ 0.0008208971345299995  ║  0.7508886079021557 ║  0.8020042840971512 ║\n",
      "║               ║     Test     ║ 1.902820363129243e-06  ║ 0.0013794275490685412  ║  0.6005389723817921 ║ 0.44091723493410195 ║\n",
      "║               ║              ║                        ║                        ║                     ║                     ║\n",
      "╚═══════════════╩══════════════╩════════════════════════╩════════════════════════╩═════════════════════╩═════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Urban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "models = {\n",
    "    \"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    \"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge())]),\n",
    "    \"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"mlr\"]))\n",
    "\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Note that Test MR2 score is low because of one outlier point:\n",
    "key=\"dropna\"\n",
    "key1=\"Urban\"\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(y_test_dt[(key,key1)],models_pred[(key,key1)]['mlr']['test'], label=\"mlr\",c=\"blue\")\n",
    "plt.scatter(y_test_dt[(key,key1)],models_pred[(key,key1)]['xgb']['test'], label=\"xgb\",c=\"green\")\n",
    "#for x, y, label in zip(preda, ya, ya.index):\n",
    "#    plt.annotate(label, (x, y), textcoords=\"offset points\", xytext=(5,5), ha=\"center\", fontsize=8)\n",
    "\n",
    "\n",
    "# Plot the line y = x\n",
    "x = np.linspace(min(y_test_dt[(key,key1)].min(), models_pred[(key,key1)]['mlr']['test'].min()), max(y_test_dt[(key,key1)].max(), models_pred[(key,key1)]['mlr']['test'].max()), 100)\n",
    "plt.plot(x, x, color='red', linestyle='--', label=\"y = x\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual Values on test set\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Suburban model\n",
      "Optimal subset of features:\n",
      "13 ['adj_police_budget', 'Population', 'adj_health_budget', 'median_age adj_welfare_budget', 'adjusted_income median_house_value', 'dropout_rate', 'adj_judiciary_budget', 'median_house_value dropout_rate', 'adj_welfare_budget security_vs_social', 'dropout_rate social_vs_security', 'high_school_rate', 'adj_welfare_budget', 'renter_ratio adj_health_budget']\n",
      "╔═══════════════╦══════════════╦════════════════════════╦════════════════════════╦═════════════════════╦═══════════════════════╗\n",
      "║     Model     ║     Type     ║          MSE           ║          RMSE          ║       r2 Score      ║          MR2          ║\n",
      "╠═══════════════╬══════════════╬════════════════════════╬════════════════════════╬═════════════════════╬═══════════════════════╣\n",
      "║      mlr      ║  Reg train   ║ 1.1493032223766095e-06 ║  0.001071527504792154  ║  0.3781222912229464 ║   0.3835681865226568  ║\n",
      "║               ║   Reg val    ║ 1.1987320058835956e-06 ║ 0.0010870152844011968  ║ 0.30505711831651344 ║   0.3570569281689357  ║\n",
      "║               ║ County train ║ 1.1430492637883797e-06 ║ 0.0010682137383568261  ║ 0.38062873182948537 ║   0.3869225137001118  ║\n",
      "║               ║  County val  ║ 1.4339234621189363e-06 ║ 0.0010942316594126909  ║ -3.9777212211331943 ║  0.19125499602227042  ║\n",
      "║               ║  Time train  ║ 8.857997150208708e-07  ║ 0.0009411693338718972  ║  0.4783170846562166 ║   0.5248989874239631  ║\n",
      "║               ║   Time val   ║ 1.8424415281760677e-06 ║ 0.0013573656575057687  ║ 0.17132418640781044 ║  0.01180162873729762  ║\n",
      "║               ║     Test     ║ 1.0989246991287142e-06 ║  0.001048296093252624  ║ 0.33717157693748034 ║   0.410588840290418   ║\n",
      "║               ║              ║                        ║                        ║                     ║                       ║\n",
      "║      xgb      ║  Reg train   ║ 2.1128146221912992e-07 ║ 0.0004590814740469039  ║  0.8860841502001128 ║   0.8866786306919401  ║\n",
      "║               ║   Reg val    ║ 8.304136816783616e-07  ║ 0.0008714266022885576  ║  0.5227495527870742 ║   0.554605432433348   ║\n",
      "║               ║ County train ║ 2.0988372310803625e-07 ║ 0.0004579014661695014  ║  0.8855883738641224 ║   0.887428311749336   ║\n",
      "║               ║  County val  ║ 2.5683102533220227e-06 ║ 0.0014345582001902579  ║  -9.674022569447416 ║  -0.46212781365993044 ║\n",
      "║               ║  Time train  ║ 1.4789442971611578e-07 ║ 0.00038457044831359023 ║  0.9128990493572334 ║   0.9206764326958193  ║\n",
      "║               ║   Time val   ║ 1.3707988107532956e-06 ║ 0.0011708111763872498  ║  0.3834551586031991 ║  0.26476844372029074  ║\n",
      "║               ║     Test     ║ 5.678903411914064e-07  ║ 0.0007535849926792639  ║  0.6574707442440988 ║   0.6954105182503574  ║\n",
      "║               ║              ║                        ║                        ║                     ║                       ║\n",
      "║     ridge     ║  Reg train   ║ 1.1493098944893852e-06 ║ 0.0010715306235066276  ║ 0.37811867941550725 ║  0.38356460791737834  ║\n",
      "║               ║   Reg val    ║ 1.1987107781242155e-06 ║ 0.0010870012475750913  ║  0.3051794839980312 ║  0.35706831373364667  ║\n",
      "║               ║ County train ║ 1.1430541668568902e-06 ║ 0.0010682160353831054  ║ 0.38062607582648694 ║  0.38691988392638926  ║\n",
      "║               ║  County val  ║ 1.4341312633364573e-06 ║  0.001094357667343496  ║  -3.980283311716281 ║  0.19124240207379758  ║\n",
      "║               ║  Time train  ║ 8.858102045063846e-07  ║ 0.0009411749064368347  ║ 0.47831090697824874 ║   0.5248933613607522  ║\n",
      "║               ║   Time val   ║ 1.8399190564281208e-06 ║ 0.0013564361601004747  ║ 0.17245871974090488 ║  0.01315456310984453  ║\n",
      "║               ║     Test     ║ 1.0984451139053764e-06 ║ 0.0010480673231741252  ║ 0.33746084399787235 ║   0.410846067089389   ║\n",
      "║               ║              ║                        ║                        ║                     ║                       ║\n",
      "║ random_forest ║  Reg train   ║ 1.2953435612315165e-07 ║ 0.0003585864072043864  ║  0.9294328217674147 ║   0.9305239065740224  ║\n",
      "║               ║   Reg val    ║ 7.811483929200101e-07  ║  0.000876491284570291  ║  0.5285990313447491 ║   0.5810289999475824  ║\n",
      "║               ║ County train ║ 1.1080787977640462e-07 ║ 0.0003317853119596573  ║  0.9399531931043652 ║   0.9405679015352435  ║\n",
      "║               ║  County val  ║ 1.871672429961998e-06  ║ 0.0011832351760697204  ║  -6.06206424853092  ║  -0.06435032612021375 ║\n",
      "║               ║  Time train  ║ 7.305151798573268e-08  ║ 0.00027028044321728624 ║  0.9569770364261316 ║   0.9608186257268999  ║\n",
      "║               ║   Time val   ║ 1.9480040265364486e-06 ║ 0.0013957091482599262  ║ 0.12384529067307781 ║ -0.044817095575445665 ║\n",
      "║               ║     Test     ║ 5.047669404638833e-07  ║ 0.0007104695211364688  ║  0.6955443121562047 ║   0.7292669206563827  ║\n",
      "║               ║              ║                        ║                        ║                     ║                       ║\n",
      "╚═══════════════╩══════════════╩════════════════════════╩════════════════════════╩═════════════════════╩═══════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Suburban\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "models = {\n",
    "    \"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    \"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge())]),\n",
    "    \"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"mlr\"]))\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropna Rural model\n",
      "Optimal subset of features:\n",
      "14 ['poverty_rate^2', 'rent_burden house_affordability', 'adj_rehab_budget', 'uninsured_rate', 'median_age', 'median_age security_vs_social', 'adj_education_budget adj_prison_budget', 'vacancy_rate', 'mobile_home_ratio renter_ratio', 'poverty_rate', 'unemployment_rate dropout_rate', 'adj_judiciary_budget', 'house_affordability', 'uninsured_rate security_vs_social']\n",
      "╔═══════════════╦══════════════╦════════════════════════╦═══════════════════════╦═════════════════════╦══════════════════════╗\n",
      "║     Model     ║     Type     ║          MSE           ║          RMSE         ║       r2 Score      ║         MR2          ║\n",
      "╠═══════════════╬══════════════╬════════════════════════╬═══════════════════════╬═════════════════════╬══════════════════════╣\n",
      "║      mlr      ║  Reg train   ║ 1.959867666485674e-06  ║ 0.0013984854484549306 ║  0.4339689859621466 ║  0.4374643702249891  ║\n",
      "║               ║   Reg val    ║ 2.138422121849968e-06  ║ 0.0014463525026965395 ║ 0.35443531152639923 ║ 0.38621435742305527  ║\n",
      "║               ║ County train ║ 1.9682361345331946e-06 ║ 0.0014025680124430948 ║ 0.43076133297602054 ║ 0.43506239098737803  ║\n",
      "║               ║  County val  ║ 2.4644142465192086e-06 ║ 0.0013791598681566458 ║ -1.3428244489399772 ║ 0.28451487555466387  ║\n",
      "║               ║  Time train  ║ 1.4593500022794106e-06 ║ 0.0012080355964454899 ║  0.4327683230794126 ║  0.5811266308268306  ║\n",
      "║               ║   Time val   ║ 3.206051724036444e-06  ║ 0.0017905450913161735 ║  0.3517648274692018 ║ 0.07977545805117081  ║\n",
      "║               ║     Test     ║ 1.8444149837426265e-06 ║ 0.0013580924061869378 ║  0.4776231895960492 ║ 0.47060244822212904  ║\n",
      "║               ║              ║                        ║                       ║                     ║                      ║\n",
      "║      xgb      ║  Reg train   ║ 3.2381720993899355e-07 ║ 0.0005688194251053059 ║  0.9060841676191457 ║  0.9070556031715877  ║\n",
      "║               ║   Reg val    ║ 1.816782122340817e-06  ║ 0.0013170046961928795 ║  0.4598809013474091 ║  0.4785338353034957  ║\n",
      "║               ║ County train ║ 3.355780539314152e-07  ║ 0.0005790499492115066 ║  0.902853920175987  ║  0.903679919243996   ║\n",
      "║               ║  County val  ║ 4.408612787152908e-06  ║ 0.0017802300123325632 ║  -3.122438180028263 ║ -0.2695423080829795  ║\n",
      "║               ║  Time train  ║ 3.028718696679699e-07  ║ 0.0005503379595012231 ║  0.8822773712574106 ║  0.913067488760445   ║\n",
      "║               ║   Time val   ║ 3.1878793075234587e-06 ║ 0.0017854633313298424 ║ 0.35543912862450733 ║ 0.08499143867194225  ║\n",
      "║               ║     Test     ║ 1.8738051307179599e-06 ║ 0.0013688700196578052 ║  0.4692992866948027 ║  0.462166672113023   ║\n",
      "║               ║              ║                        ║                       ║                     ║                      ║\n",
      "║     ridge     ║  Reg train   ║ 1.959882728496527e-06  ║  0.001398490842898467 ║ 0.43396462342637443 ║  0.4374600470158737  ║\n",
      "║               ║   Reg val    ║ 2.138486544704853e-06  ║ 0.0014463554580628345 ║  0.354498213972545  ║ 0.38619586630150443  ║\n",
      "║               ║ County train ║ 1.968246634989998e-06  ║ 0.0014025717510205177 ║  0.4307583173106888 ║  0.4350593770690498  ║\n",
      "║               ║  County val  ║ 2.465342327757184e-06  ║ 0.0013793265018171865 ║  -1.344601785287546 ║  0.2843284254973938  ║\n",
      "║               ║  Time train  ║ 1.4593668485199562e-06 ║  0.001208042569001588 ║ 0.43276177514967706 ║  0.5811217954949882  ║\n",
      "║               ║   Time val   ║ 3.2109550282300814e-06 ║ 0.0017919137892850989 ║  0.3507734229275645 ║  0.0783680756244316  ║\n",
      "║               ║     Test     ║ 1.8438386599337744e-06 ║ 0.0013578802082414244 ║  0.4777864165247403 ║  0.4707678689198175  ║\n",
      "║               ║              ║                        ║                       ║                     ║                      ║\n",
      "║ random_forest ║  Reg train   ║ 2.850548650402916e-07  ║ 0.0005325921264557764 ║  0.9180240980473038 ║  0.9181814564483284  ║\n",
      "║               ║   Reg val    ║ 1.953602213455714e-06  ║  0.001373821966732308 ║  0.4173992508860057 ║ 0.43926272662746724  ║\n",
      "║               ║ County train ║ 2.681617292755882e-07  ║ 0.0005165080434178098 ║  0.9228260294904009 ║  0.9230302485013716  ║\n",
      "║               ║  County val  ║ 3.6586251865231895e-06 ║  0.001539781407742775 ║  -1.868400912066112 ║ -0.08575163386378863 ║\n",
      "║               ║  Time train  ║ 1.8698972080830697e-07 ║ 0.0004324230807997036 ║  0.9273193594851548 ║  0.9463288352805104  ║\n",
      "║               ║   Time val   ║ 3.099334690741162e-06  ║  0.001760492740894197 ║ 0.37334206341068776 ║ 0.11040616570508532  ║\n",
      "║               ║     Test     ║ 1.325023964129128e-06  ║ 0.0011510968526275832 ║  0.624725564370519  ║  0.6196818780806144  ║\n",
      "║               ║              ║                        ║                       ║                     ║                      ║\n",
      "╚═══════════════╩══════════════╩════════════════════════╩═══════════════════════╩═════════════════════╩══════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "key=\"dropna\"\n",
    "key1=\"Rural\"\n",
    "print(key+\" \"+key1+\" model\")\n",
    "\n",
    "n_components = 5\n",
    "models = {\n",
    "    \"mlr\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"Lin\", LinearRegression())]),\n",
    "    \"xgb\": xgb.XGBRegressor(random_state=42,max_depth=3, n_estimators=100),\n",
    "    \"ridge\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"ridge\", Ridge())]),\n",
    "    \"random_forest\": Pipeline([(\"scale\", StandardScaler()),('pca',PCA(n_components=n_components)), (\"randomforest\", RandomForestRegressor())]),\n",
    "}\n",
    "\n",
    "# Uncomment this to perform feature selection again\n",
    "#features[(key,key1)]=list(Poly_feature_selection(set(X_train_Poly_dt[(key,key1)].columns), X_train_Poly_dt[(key,key1)], y_train_dt[(key,key1)], models[\"mlr\"]))\n",
    "ff=features[(key,key1)]\n",
    "print(\"Optimal subset of features:\")\n",
    "print(len(ff),ff)\n",
    "\n",
    "\n",
    "fitted_models[(key,key1)], models_stats[(key,key1)], models_pred[(key,key1)] = deep_cross_fit1(\n",
    "    X_train_Poly_dt[(key,key1)][ff],X_test_Poly_dt[(key,key1)][ff], y_train_dt[(key,key1)],y_test_dt[(key,key1)], **models\n",
    ")\n",
    "\n",
    "# Using pretty table\n",
    "print_table(models_stats[(key,key1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the dictionary\n",
    "#joblib.dump(features, \"features.pkl\")\n",
    "\n",
    "# To load it later\n",
    "#features = joblib.load(\"features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "imputed Urban model\n",
      "The top 4 important features in mlr are:\n",
      "dropout_rate\n",
      "adj_judiciary_budget\n",
      "home_ownership_rate\n",
      "home_ownership_rate^2\n",
      "\n",
      "\n",
      "dropna Urban model\n",
      "The top 4 important features in mlr are:\n",
      "dropout_rate public_school_rate\n",
      "mobile_home_ratio\n",
      "uninsured_rate^2\n",
      "clearance_rate\n",
      "\n",
      "\n",
      "imputed Suburban model\n",
      "The top 4 important features in mlr are:\n",
      "adj_education_budget uninsured_rate\n",
      "mobile_home_ratio renter_ratio\n",
      "public_school_rate\n",
      "renter_ratio\n",
      "\n",
      "\n",
      "dropna Suburban model\n",
      "The top 4 important features in mlr are:\n",
      "dropout_rate\n",
      "dropout_rate social_vs_security\n",
      "adj_welfare_budget security_vs_social\n",
      "adj_judiciary_budget\n",
      "\n",
      "\n",
      "imputed Rural model\n",
      "The top 4 important features in mlr are:\n",
      "mobile_home_ratio^2\n",
      "mobile_home_ratio renter_ratio\n",
      "mobile_home_ratio social_vs_security\n",
      "home_ownership_rate\n",
      "\n",
      "\n",
      "dropna Rural model\n",
      "The top 4 important features in mlr are:\n",
      "mobile_home_ratio renter_ratio\n",
      "uninsured_rate security_vs_social\n",
      "uninsured_rate\n",
      "adj_rehab_budget\n"
     ]
    }
   ],
   "source": [
    "for key1 in [\"Urban\",\"Suburban\",\"Rural\"]:\n",
    "    for key in [\"imputed\",\"dropna\"]:\n",
    "        print('\\n')\n",
    "        print(key+\" \"+key1+\" model\")\n",
    "        # Can set plot=True to visualize the feature importances\n",
    "        # Can modify models_to_use to include/exclude specific models\n",
    "        feature_importance_PCA(fitted_models[(key,key1)],features[(key,key1)],(3,3), plot=False, models_to_use=['mlr'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
